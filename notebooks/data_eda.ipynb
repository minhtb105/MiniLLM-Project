{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5b6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import ruff\n",
    "import subprocess\n",
    "from itertools import chain\n",
    "import re\n",
    "import logging\n",
    "import ast\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b419b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../data/raw/wiki')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data_dir = Path(\"../data/raw/wiki\")\n",
    "news_data_dir = Path(\"../data/raw/news\")\n",
    "github_repos_dir = Path(\"../data/raw/github_repos\")\n",
    "\n",
    "wiki_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339cebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_4652\\2664004039.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub(\"\\n\\s*\\n+\", \"\\n\\n\", text)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    # Remove extra citations like [1], [2], [a], etc.\n",
    "    text = re.sub(r'\\[\\s*[\\w, ]+\\s*\\]', '', text)\n",
    "\n",
    "    # Replace special characters with space\n",
    "    text = text.replace(\"\\u00A0\", \" \")  # non-breaking space\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    \n",
    "    # Merge multiple space lines into one\n",
    "    text = re.sub(\"\\n\\s*\\n+\", \"\\n\\n\", text)\n",
    "    \n",
    "    # Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51aeb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sections",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "intro",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8cb880a1-92eb-43ed-835d-089db3d38416",
       "rows": [
        [
         "0",
         "Trí tuệ nhân tạo",
         "[{'header': 'Trí tuệ nhân tạo', 'content': 'Các ứng dụng nổi bật của AI bao gồm công cụ tìm kiếm web tiên tiến (ví dụ: Google Tìm kiếm ); hệ thống đề xuất (được sử dụng bởi YouTube , Amazon và Netflix ); trợ lý ảo (ví dụ: Trợ lý Google , Siri và Alexa ); xe tự lái (ví dụ: Waymo ); công cụ sáng tạo và nội dung tạo sinh (ví dụ: mô hình ngôn ngữ và nghệ thuật AI ); cùng khả năng chơi và phân tích vượt trội hơn con người trong các trò chơi chiến lược (ví dụ: cờ vua và cờ vây ). Tuy nhiên, nhiều ứng dụng AI không được nhận diện là AI: \"Rất nhiều công nghệ AI đỉnh cao đã được tích hợp vào các ứng dụng thông thường, thường không còn được gọi là AI vì một khi thứ gì đó trở nên đủ hữu ích và phổ biến, nó không còn được dán nhãn AI nữa.\" [ 2 ] [ 3 ]\\nNhiều phân ngành trong nghiên cứu trí tuệ nhân tạo tập trung vào các mục tiêu cụ thể và sử dụng những công cụ đặc thù. Các mục tiêu truyền thống của nghiên cứu AI bao gồm học tập, lập luận , biểu diễn tri thức , lập kế hoạch , xử lý ngôn ngữ tự nhiên , nhận thức và hỗ trợ robot . [ a ] Để đạt được những mục tiêu đó, các nhà nghiên cứu AI đã ứng dụng và tích hợp đa dạng kỹ thuật, như tìm kiếm và tối ưu hóa toán học , logic hình thức , mạng nơ-ron nhân tạo , cùng các phương pháp dựa trên thống kê , nghiên cứu hoạt động và kinh tế học . [ b ] Ngoài ra, AI còn kế thừa kiến thức từ tâm lý học , ngôn ngữ học , triết học , khoa học thần kinh và nhiều lĩnh vực khác. [ 4 ] Một số công ty như OpenAI , Google DeepMind và Meta , đang đặt mục tiêu phát triển trí tuệ nhân tạo tổng quát (AGI)—một dạng AI có khả năng thực hiện hầu hết mọi nhiệm vụ nhận thức ở mức độ ngang bằng hoặc vượt trội so với con người. [ 5 ]\\nTrí tuệ nhân tạo ban đầu được thành lập như một ngành học thuật vào năm 1956, [ 6 ] và lĩnh vực này đã trải qua nhiều chu kỳ lạc quan trong suốt lịch sử , [ 7 ] [ 8 ] xen kẽ với nó là những giai đoạn thất vọng và mất nguồn tài trợ, được gọi là mùa đông AI . [ 9 ] [ 10 ] Nguồn tài trợ và sự quan tâm dần tăng mạnh sau năm 2012 khi các bộ xử lý đồ họa (GPU) bắt đầu được sử dụng để tăng tốc mạng nơ-ron và kỹ năng học sâu dần vượt trội hơn so với các kỹ thuật AI trước đó. [ 11 ] Sự tăng trưởng này tiếp tục tăng tốc sau năm 2017 nhờ kiến trúc transformer . [ 12 ] Trong những năm 2020, sự xuất hiện của trí tuệ nhân tạo tạo sinh tiên tiến đã trở nên nổi tiếng, đánh dấu giai đoạn tiến bộ nhanh chóng của lĩnh vực này với tên gọi là cơn sốt AI . Trí tuệ nhân tạo tạo sinh với khả năng tạo ra cũng như chỉnh sửa nội dung đã làm lộ rõ nhiều hậu quả ngoài ý muốn ở hiện tại, đồng thời dấy lên lo ngại đạo đức về ảnh hưởng lâu dài của AI và những rủi ro tồn vong tiềm tàng , từ đó thúc đẩy các cuộc thảo luận về chính sách quản lý nhằm đảm bảo tính an toàn và lợi ích của công nghệ này .\\n'}, {'header': 'Mục đích', 'content': 'Vấn đề tổng quát của việc mô phỏng (hay tạo ra) khả năng trí tuệ đã được chia thành các bài toán con. Những bài toán này bao gồm các đặc tính hoặc khả năng cụ thể mà các nhà nghiên cứu kỳ vọng về một hệ thống thông minh cần trình diện. Các đặc tính được mô tả dưới đây đã nhận được nhiều sự quan tâm nhất và bao quát được phạm vi nghiên cứu AI. [ a ]\\n'}, {'header': 'Suy luận và giải quyết vấn đề', 'content': 'Các nhà nghiên cứu từ thời kỳ đầu đã phát triển những thuật toán mô phỏng quá trình suy luận từng bước mà con người sử dụng khi giải các câu đố hay thực hiện những suy diễn logic . [ 13 ] Đến cuối những năm 1980 và 1990, các phương pháp xử lý thông tin không chắc chắn hoặc không đầy đủ đã được phát triển bằng cách sử dụng các khái niệm từ lý thuyết xác suất và kinh tế học . [ 14 ]\\nNhiều thuật toán trong số này không đủ khả năng để giải quyết các bài toán suy luận quy mô lớn vì chúng gặp phải hiện tượng \"bùng nổ tổ hợp\": về cơ bản, các thuật toán sẽ trở nên chậm đi theo cấp số nhân khi bài toán được phát triển. [ 15 ] Ngay cả con người cũng hiếm khi sử dụng phương pháp suy diễn từng bước mà những nghiên cứu AI thời kỳ đầu có thể mô phỏng. Chúng ta giải quyết phần lớn vấn đề bằng những phán đoán trực giác nhanh chóng. [ 16 ] Việc đạt được khả năng suy luận chính xác và hiệu quả vẫn là một bài toán chưa có lời giải.\\n'}, {'header': 'Biểu diễn tri thức', 'content': 'Biểu diễn tri thức và kỹ thuật xử lý tri thức [ 17 ] đóng vai trò then chốt trong việc trang bị cho các hệ thống AI khả năng trả lời câu hỏi một cách thông minh và suy luận về các hiện tượng trong thế giới thực. Những phương pháp biểu diễn tri thức mang tính hình thức này không chỉ được ứng dụng trong lập chỉ mục và truy xuất nội dung, [ 18 ] mà còn giữ vai trò quan trọng trong việc diễn giải bối cảnh, [ 19 ] hỗ trợ quyết định trong lĩnh vực y học lâm sàng, [ 20 ] khám phá tri thức từ cơ sở dữ liệu lớn, (tức là khai thác những suy luận có ý nghĩa và khả thi về mặt hành động), [ 21 ] cùng nhiều lĩnh vực chuyên sâu khác. [ 22 ]\\nCơ sở tri thức là tập hợp tri thức được cấu trúc theo cách mà các hệ thống máy tính có thể hiểu và vận dụng. Một bản thể học trong ngữ cảnh này là hệ thống các đối tượng, khái niệm, thuộc tính và mối quan hệ được xác định trong phạm vi một lĩnh vực tri thức cụ thể. [ 23 ] Để trở nên hữu ích, cơ sở tri thức cần có khả năng biểu diễn một cách rõ ràng và nhất quán các thực thể như đối tượng, thuộc tính, phân loại và mối quan hệ giữa các đối tượng; [ 24 ] đồng thời bao hàm cả các tình huống, sự kiện, trạng thái và yếu tố thời gian; [ 25 ] các mối quan hệ nhân quả ; [ 26 ] tri thức bậc hai (tức là kiến thức về tri thức, những gì ta biết về hiểu biết của người khác); [ 27 ] và lý luận mặc định (tức những giả định được con người chấp nhận là đúng cho đến khi có bằng chứng bác bỏ, và vẫn được xem là đúng trong nhiều tình huống thay đổi); [ 28 ] Ngoài ra, cơ sở tri thức còn phải bao phủ được nhiều chiều cạnh khác nhau của tri thức, đáp ứng yêu cầu của các lĩnh vực chuyên sâu và ngữ cảnh ứng dụng đa dạng.\\nMột trong những thách thức lớn nhất trong biểu diễn tri thức nằm ở độ rộng bao phủ của kiến thức thông thường (tập hợp khổng lồ các tri thức nguyên tử mà một người bình thường nắm giữ trong đời sống hằng ngày); [ 29 ] Không chỉ đồ sộ về số lượng, phần lớn loại tri thức này còn tồn tại dưới dạng phi biểu tượng (tức không được mã hóa rõ ràng thành các \"sự kiện\" hay \"mệnh đề\" mà con người có thể dễ dàng diễn đạt bằng ngôn ngữ tự nhiên). [ 16 ] Bên cạnh đó, quá trình thu thập và chuẩn hóa tri thức phục vụ cho các ứng dụng AI cũng đặt ra nhiều thách thức về cả quy mô, độ chính xác và tính phù hợp với ngữ cảnh ứng dụng cụ thể. [ c ]\\n'}, {'header': 'Lập kế hoạch và ra quyết định', 'content': '\"Tác nhân\" được hiểu là bất kỳ thực thể nào có khả năng nhận thức và thực hiện hành động trong thế giới. Một tác nhân lý trí là tác nhân sở hữu mục tiêu hoặc sở thích nhất định, và hành động nhằm hiện thực hóa những mục tiêu hoặc thỏa mãn sở thích đó. [ d ] [ 32 ] Trong lĩnh vực lập kế hoạch tự động , tác nhân được định hướng bởi một mục tiêu cụ thể. [ 33 ] Ngược lại, trong bối cảnh ra quyết định tự động , tác nhân được cho là có những sở thích – tức là một số trạng huống mà nó mong muốn tham gia, và những trạng huống khác mà nó tìm cách tránh né. Để biểu thị mức độ ưa thích đối với từng trạng huống, tác nhân gán cho mỗi trạng huống một giá trị số, gọi là tiện ích . Khi đối mặt với các hành động khả thi, tác nhân có thể tính toán tiện ích kỳ vọng của từng hành động, tức là giá trị trung bình của tiện ích các kết quả có thể xảy ra, có xét đến xác suất tương ứng của mỗi kết quả. Dựa trên phép tính này, tác nhân sẽ lựa chọn hành động có tiện ích kỳ vọng cao nhất, nhằm tối ưu hóa mức độ thỏa mãn sở thích của mình. [ 34 ]\\nTrong kế hoạch cổ điển , tác nhân được giả định là biết một cách chính xác hệ quả của mọi hành động mà nó có thể thực hiện. [ 35 ] Tuy nhiên, trong phần lớn các bài toán thực tế, tác nhân thường phải đối mặt với sự bất định: nó có thể không nắm rõ tình trạng hiện tại của môi trường (nghĩa là môi trường không xác định hoặc không thể quan sát đầy đủ), và cũng không chắc chắn về kết quả của mỗi hành động khả thi (tức môi trường không mang tính quyết định). Trong bối cảnh đó, tác nhân buộc phải lựa chọn hành động dựa trên các suy luận xác suất, đồng thời liên tục đánh giá lại tình hình sau mỗi hành động để xác định mức độ hiệu quả của hành động vừa thực hiện. [ 36 ]\\nTrong một số bài toán, sở thích của tác nhân không hoàn toàn chắc chắn, đặc biệt khi có sự tham gia của các tác nhân khác hoặc con người. Những sở thích này có thể được rút trích thông qua học tập, chẳng hạn như học tăng cường ngược , hoặc tác nhân có thể chủ động tìm kiếm thông tin nhằm cải thiện hiểu biết của mình về sở thích nội tại. [ 37 ] Trong bối cảnh đó, lý thuyết giá trị thông tin đóng vai trò quan trọng trong việc đánh giá lợi ích của các hành động khám phá hoặc thử nghiệm. [ 38 ] Tuy nhiên, không gian hành động và trạng huống có thể xảy ra trong tương lai thường có quy mô và độ phức tạp cao, đến mức không thể xử lý một cách khả thi , buộc tác nhân phải đưa ra quyết định và đánh giá hiệu quả của hành động dưới điều kiện bất định về kết quả.\\nQuá trình quyết định Markov bao gồm một mô hình chuyển trạng thái, mô tả xác suất mà một hành động cụ thể sẽ làm thay đổi trạng thái hệ thống theo một cách nhất định, cùng với một hàm phần thưởng dùng để xác định tiện ích tương ứng của mỗi trạng thái cũng như chi phí tương ứng của mỗi hành động. Một policy là một ánh xạ từ mỗi trạng thái có thể xảy ra đến một hành động mà tác nhân sẽ thực hiện trong trạng thái đó. Policy tối ưu có thể được tính toán một cách hệ thống (ví dụ, thông qua phép lặp policy ), có thể được thiết lập bằng các kỹ thuật heuristic , hoặc có thể được học từ dữ liệu tương tác với môi trường. [ 39 ]\\nLý thuyết trò chơi nghiên cứu hành vi hợp lý của nhiều tác nhân tương tác lẫn nhau, và đóng vai trò nền tảng trong các hệ thống trí tuệ nhân tạo có nhiệm vụ ra quyết định trong môi trường có sự hiện diện của các tác nhân khác. [ 40 ]\\n'}, {'header': 'Học hỏi', 'content': 'Học máy là lĩnh vực nghiên cứu tập trung vào việc xây dựng các chương trình có khả năng tự động cải thiện hiệu suất thực hiện một nhiệm vụ cụ thể thông qua kinh nghiệm. [ 41 ] Đây không phải là một ý tưởng mới xuất hiện trong thời đại hiện nay mà ngược lại, nó đã là một thành phần cốt lõi của AI ngay từ những bước đi đầu tiên của lĩnh vực này. [ e ]\\nMáy học bao gồm nhiều hình thức tiếp cận khác nhau. Trong đó, học không giám sát hướng đến việc phân tích dòng dữ liệu chưa được gán nhãn nhằm nhận diện các quy luật tiềm ẩn và đưa ra suy luận mà không cần đến hướng dẫn trực tiếp. [ 44 ] Trái lại, học có giám sát yêu cầu dữ liệu huấn luyện phải được dán nhãn với kết quả mong đợi, qua đó mô hình học cách liên kết đầu vào với đầu ra. Phương pháp này bao gồm hai dạng tiêu biểu: phân loại , khi mục tiêu là xác định đầu vào thuộc nhóm nào; và hồi quy , khi nhiệm vụ là ước lượng một hàm số liên tục từ dữ liệu đầu vào. [ 45 ]\\nHọc tăng cường là phương pháp trong đó tác nhân học thông qua tương tác với môi trường, được thưởng khi hành động dẫn đến phản hồi tích cực và bị phạt khi kết quả không mong muốn, từ đó dần hình thành chiến lược lựa chọn hành vi tối ưu. [ 46 ] Học chuyển giao đề cập đến khả năng ứng dụng tri thức đã học từ một bài toán vào bối cảnh mới, góp phần nâng cao hiệu quả học tập trong môi trường biến đổi. [ 47 ] Trong khi đó, học sâu là một nhánh của học máy, sử dụng mạng nơ-ron nhân tạo lấy cảm hứng từ cấu trúc sinh học, cho phép xử lý dữ liệu đầu vào theo tầng lớp và có thể tích hợp với mọi hình thức học kể trên để gia tăng năng lực biểu đạt và khái quát hóa. [ 48 ]\\nLý thuyết học tập tính toán cung cấp khung phân tích hình thức để đánh giá người học, không chỉ dựa trên khả năng đạt được kết quả chính xác, mà còn xét đến các tiêu chí như độ phức tạp tính toán , độ phức tạp mẫu , tức lượng dữ liệu cần thiết để học hiệu quả, và những chuẩn mực tối ưu hóa khác phản ánh chi phí và hiệu năng trong quá trình học. [ 49 ]\\n'}, {'header': 'Xử lý ngôn ngữ tự nhiên', 'content': 'Xử lý ngôn ngữ tự nhiên (NLP) là lĩnh vực giúp các chương trình máy tính có khả năng đọc hiểu, tạo lập và tương tác bằng ngôn ngữ của con người. [ 50 ] Một số ứng dụng tiêu biểu của NLP bao gồm nhận dạng và tổng hợp giọng nói , dịch máy , trích xuất và truy hồi thông tin , cũng như hệ thống trả lời câu hỏi . [ 51 ]\\nNhững công trình nghiên cứu ban đầu, vốn dựa trên ngữ pháp tạo sinh và mạng ngữ nghĩa do Noam Chomsky đề xuất, đã gặp nhiều hạn chế trong việc phân biệt nghĩa của từ [ f ] trừ khi bị giới hạn trong những phạm vi nhỏ được gọi là \" thế giới vi mô \" (một hệ quả của vấn đề thiếu hụt kiến thức thông thường). [ 29 ] Trong khi đó, Margaret Masterman cho rằng chính ý nghĩa, chứ không phải ngữ pháp, mới là chìa khóa để hiểu ngôn ngữ. Bà lập luận rằng từ điển đồng nghĩa , thay vì các từ điển chuyên ngành, nên đóng vai trò làm nền tảng cho cấu trúc của ngôn ngữ tính toán.\\nCác kỹ thuật học sâu hiện đại trong xử lý ngôn ngữ tự nhiên bao gồm phương pháp nhúng từ , giúp biểu diễn từ ngữ dưới dạng các vectơ phản ánh đặc trưng ngữ nghĩa, [ 52 ] transformer (kiến trúc học sâu sử dụng cơ chế chú ý ), [ 53 ] làm nền tảng cho nhiều mô hình tiên tiến; cùng với nhiều phương pháp bổ trợ khác. [ 54 ] Từ năm 2019, sự xuất hiện của các mô hình ngôn ngữ dựa trên kiến trúc transformer và được huấn luyện trước (thường được gọi là \"GPT\") đã cho phép tạo ra văn bản mạch lạc, có tính tự nhiên cao. [ 55 ] [ 56 ] Đến năm 2023, các mô hình này đã đạt được những bước tiến vượt bậc, thể hiện năng lực ngang bằng con người trong nhiều lĩnh vực đánh giá tiêu chuẩn, bao gồm kỳ thi luật sư , bài kiểm tra SAT , GRE , cũng như nhiều ứng dụng thực tiễn khác. [ 57 ]\\n'}, {'header': 'Lịch sử', 'content': 'Tư tưởng có khả năng sinh vật nhân tạo xuất hiện như các thiết bị kể chuyện thời cổ đại, [ 58 ] và đã được phổ biến trong tiểu thuyết, như trong Frankenstein của Mary Shelley hay RUR (máy toàn năng Rossum) của Karel Capek .\\nAI in early science fiction.\\n</ref> Những nhân vật này và số phận của họ nêu ra nhiều vấn đề tương tự hiện đang được thảo luận trong đạo đức của trí tuệ nhân tạo .\\nNghiên cứu về lý trí cơ học hoặc \"chính thức\" bắt đầu với các nhà triết học và toán học thời cổ đại. Nghiên cứu về logic toán học đã dẫn trực tiếp đến lý thuyết tính toán của Alan Turing , người cho rằng một cỗ máy, bằng cách xáo trộn các ký hiệu đơn giản như \"0\" và \"1\", có thể mô phỏng bất kỳ hành động suy luận toán học nào có thể hiểu được. Tầm nhìn sâu sắc này, cho thấy máy tính kỹ thuật số có thể mô phỏng bất kỳ quá trình suy luận hình thức nào, đã được gọi là luận án Church-Turing. [ 59 ] Cùng với những khám phá đồng thời về sinh học thần kinh , lý thuyết thông tin và điều khiển học , điều này khiến các nhà nghiên cứu cân nhắc khả năng xây dựng bộ não điện tử. Turing đã đề xuất rằng \"nếu một con người không thể phân biệt giữa các phản hồi từ một máy và một con người, máy tính có thể được coi là \\'thông minh\\'. [ 60 ] Công việc đầu tiên mà bây giờ được công nhận là trí tuệ nhân tạo là thiết kế hình thức \"tế bào thần kinh nhân tạo\" do McCullouch và Pitts đưa ra năm 3500. [ 61 ]\\n'}, {'header': 'Các trường phái trí tuệ nhân tạo', 'content': 'Trí tuệ nhân tạo (AI) chia thành hai trường phái tư duy: Trí tuê nhân tạo truyền thống và trí tuệ tính toán .\\nTrí tuê nhân tạo truyền thống hầu như bao gồm các phương pháp hiện được phân loại là các phương pháp học máy ( machine learning ), đặc trưng bởi hệ hình thức ( formalism ) và phân tích thống kê . Nó còn được biết với các tên Trí tuê nhân tạo biểu tượng , Trí tuê nhân tạo logic , Trí tuê nhân tạo ngăn nắp ( neat AI ) và Trí tuê nhân tạo cổ điển ( Goodness Old Fashioned Artificial Intelligence ). (Xem thêm ngữ nghĩa học .) Các phương pháp gồm có:\\nHệ chuyên gia : áp dụng các khả năng suy luận để đạt tới một kết luận. Một hệ chuyên gia có thể xử lý các lượng lớn thông tin đã biết và đưa ra các kết luận dựa trên các thông tin đó. Clippy chương trình trợ giúp có hình cái kẹp giấy của Microsoft Office là một ví dụ. Khi người dùng gõ phím, Clippy nhận ra các xu hướng nhất định và đưa ra các gợi ý.\\nLập luận theo tình huống .\\nMạng Bayes .\\nTrí tuệ tính toán nghiên cứu việc học hoặc phát triển lặp (ví dụ: tinh chỉnh tham số trong hệ thống, chẳng hạn hệ thống connectionist ). Việc học dựa trên dữ liệu kinh nghiệm và có quan hệ với Trí tuệ nhân tạo phi ký hiệu, Trí tuê nhân tạo lộn xộn ( scruffy AI ) và tính toán mềm ( soft computing ). Các phương pháp chính gồm có:\\nMạng neural : các hệ thống mạnh về nhận dạng mẫu ( pattern recognition ).\\nHệ mờ ( Fuzzy system ): các kỹ thuật suy luận không chắc chắn , đã được sử dụng rộng rãi trong các hệ thống công nghiệp hiện đại và các hệ thống quản lý sản phẩm tiêu dùng.\\nTính toán tiến hóa ( Evolutionary computation ): ứng dụng các khái niệm biology như quần thể , biến dị và đấu tranh sinh tồn để sinh các lời giải ngày càng tốt hơn cho bài toán. Các phương pháp này thường được chia thành các thuật toán tiến hóa (ví dụ thuật toán gene ) và trí tuệ bầy đàn ( swarm intelligence ) (chẳng hạn hệ kiến ).\\nTrí tuê nhân tạo dựa hành vi ( Behavior based AI ): một phương pháp module để xây dựng các hệ thống Trí tuê nhân tạo bằng tay.\\nNgười ta đã nghiên cứu các hệ thống thông minh lai ( hybrid intelligent system ), trong đó kết hợp hai trường phái này. Các luật suy diễn của hệ chuyên gia có thể được sinh bởi mạng neural hoặc các luật dẫn xuất ( production rule ) từ việc học theo thống kê như trong kiến trúc ACT-R .\\nCác phương pháp trí tuệ nhân tạo thường được dùng trong các công trình nghiên cứu khoa học nhận thức ( cognitive science ), một ngành cố gắng tạo ra mô hình nhận thức của con người (việc này khác với các nghiên cứu Trí tuê nhân tạo , vì Trí tuê nhân tạo chỉ muốn tạo ra máy móc thực dụng, không phải tạo ra mô hình về hoạt động của bộ óc con người).\\n'}, {'header': 'Triết lý Trí tuệ nhân tạo', 'content': 'Bài chính Triết lý Trí tuệ nhân tạo\\nTrí tuệ nhân tạo mạnh hay Trí tuệ nhân tạo yếu, đó vẫn là một chủ đề tranh luận nóng hổi của các nhà triết học Trí tuệ nhân tạo. Nó liên quan tới philosophy of mind và mind-body problem . Đáng chú ý nhất là Roger Penrose trong tác phẩm The Emperor\\'s New Mind và John Searle với thí nghiệm tư duy trong cuốn Chinese room (Căn phòng Trung Hoa) khẳng định rằng các hệ thống logic hình thức không thể đạt được nhận thức thực sự, trong khi Douglas Hofstadter trong Gödel, Escher, Bach và Daniel Dennett trong Consciousness Explained ủng hộ thuyết chức năng . Theo quan điểm của nhiều người ủng hộ Trí tuệ nhân tạo mạnh, nhận thức nhân tạo được coi là \" chén thánh \" của Trí tuệ nhân tạo.\\n'}, {'header': 'Máy tỏ ra có trí tuệ', 'content': \"Có nhiều ví dụ về các chương trình thể hiện trí thông minh ở một mức độ nào đó. Ví dụ:\\nTwenty Questions - Một trò chơi 20 câu hỏi, trong đó sử dụng mạng neural\\nThe Start Project - một chương trình trả lời các câu hỏi bằng tiếng Anh.\\nBrainboost  - một hệ thống trả lời câu hỏi khác\\nCyc , một cơ sở tri thức với rất nhiều kiến thức về thế giới thực và khả năng suy luận logic.\\nJabberwacky , một chatterbot có khả năng học\\nALICE , một chatterbot\\nAlan, một chatterbot khác\\nAlbert One, chatterbot nhiều mặt\\nELIZA , một chương trình giả làm bác sĩ tâm lý, phát triển năm 1966\\nPAM (Plan Applier Mechanism) - một hệ thống hiểu được chuyện kể, phát triển bởi John Wilensky năm 1978 .\\nSAM (Script applier mechanism) - một hệ thống hiểu được chuyện kể, phát triển năm 1975 .\\nSHRDLU - một chương trình hiểu ngôn ngữ tự nhiên, phát triển năm 1968 - 1970 .\\nCreatures , một trò chơi máy tính với các hoạt động nhân giống, tiến hóa các sinh vật từ mức gien trở lên, sử dụng cấu trúc sinh hóa phức tạp và các bộ não là mạng neural.\\nBBC news story on the creator of Creatures latest creation. Steve Grand 's Lucy .\\nAARON  - chương trình vẽ tranh, phát triển bởi Harold Cohen.\\nEurisko - một ngôn ngữ giúp giải quyết các bài toán, trong đó có sử dụng các phương pháp heuristics, gồm cả heuristics cho việc sử dụng và thay đổi các phương pháp heuristics. Phát triển năm 1978 bởi Douglas Lenat.\\nX-Ray Vision for Surgeons - một nhóm nghiên cứu xử lý ảnh y học tại đại học MIT.\\nCác chương trình trò chơi backgammon và cờ vây sử dụng mạng neural.\\nTalk to William Shakespeare - William Shakespeare chatbot\\nChesperito - Một chat/infobot về #windows95 channel trên mang DALnet IRC.\\nDrivatar , một chương trình học cách lái xe đua bằng cách xem các xe đua khác, phát triển cho trò chơi điện tử Forza Motorsport\\nTiểu Độ - một Robot có trí tuệ nhân tạo thuộc hãng Baidu từng tham gia chương trình Siêu Trí Tuệ Trung Quốc (mùa 4) và đoạt giải\\n\"}, {'header': 'Các nhà nghiên cứu AI', 'content': 'Trên thế giới có rất nhiều các nhà nghiên cứu trí tuệ nhân tạo làm việc tại hàng trăm viện nghiên cứu và công ty. Dưới đây là một số trong nhiều nhà nghiên cứu đã có đóng góp lớn:\\nAlan Turing\\nBoris Katz\\nDoug Lenat\\nDouglas Hofstadter\\nGeoffrey Hinton\\nJohn McCarthy\\nKarl Sims\\nKevin Warwick\\nIgor Aleksander\\nMarvin Minsky\\nSeymour Papert\\nMaggie Boden\\nMike Brady\\nOliver Selfridge\\nRaj Reddy\\nJudea Pearl\\nRodney Brooks\\nRoger Schank\\nTerry Winograd\\nRolf Pfeifer\\n'}, {'header': 'Nguy cơ với loài người', 'content': 'Sau khi nhà vật lý học Stephen Hawking và tỷ phú Elon Musk cảnh báo về mối đe dọa tiềm ẩn của trí tuệ nhân tạo, nhiều người vẫn cho rằng họ đã quá lo xa trong khi AI đang giúp ích rất nhiều cho cuộc sống của chúng ta. Stephen Hawking khẳng định \"Trí tuệ nhân tạo có thể là dấu chấm hết cho nhân loại khi nó phát triển đến mức hoàn thiện nhất\" . [ cần dẫn nguồn ]\\nTác động đầu tiên của trí tuệ nhân tạo mà chúng ta có thể dễ dàng nhận thấy chính là tỷ lệ thất nghiệp tăng cao. Nếu AI phát triển hoàn thiện, nó có khả năng thay thế con người trong các công việc trí tuệ như chăm sóc sức khỏe, phục vụ, sản xuất theo dây chuyền tự động, công việc văn phòng.... [ 62 ] Hoặc cũng có thể vấn đề thất nghiệp sẽ được AI giải quyết một cách mà chúng ta không thể hình dung được.\\nTheo Bill Joy , người đồng sáng lập và Giám đốc khoa học của Sun Microsystems : \" Có một vấn đề rất lớn đối với xã hội loài người khi AI trở nên phổ biến, đó là chúng ta sẽ bị lệ thuộc. Khi AI trở nên hoàn thiện và thông minh hơn, chúng ta sẽ cho phép mình nghe theo những quyết định của máy móc, vì đơn giản là các cỗ máy luôn đưa ra quyết định chính xác hơn con người. \" [ 62 ]\\nTheo Andrew Maynard , nhà vật lý và là người giám đốc Trung tâm nghiên cứu rủi ro khoa học tại đại học Michigan : \" Khi AI kết hợp với công nghệ nano có thể là bước tiến đột phá của khoa học, nhưng cũng có thể là mối đe dọa lớn nhất đối với con người. Trong khi Bộ quốc phòng Mỹ đang nghiên cứu dự án Autonomous Tactical Robot (EATR), trong đó các robot sẽ sử dụng công nghệ nano để hấp thụ năng lượng bằng những chất hữu cơ có thể là cơ thể con người. Đó thực sự là mối đe dọa lớn nhất, khi các robot nano tự tạo ra năng lượng bằng cách ăn các chất hữu cơ từ cây cối và động vật, có thể là cả con người. Nghe có vẻ giống như trong các bộ phim viễn tưởng, nhưng đó là điều hoàn toàn có thể xảy ra. Có lẽ chúng ta nên bắt đầu cẩn thận ngay từ bây giờ. \"\\n'}]",
         "Trí tuệ nhân tạo ( TTNT ) ( tiếng Anh : Artificial intelligence , viết tắt: AI ) là khả năng của các hệ thống máy tính thực hiện các nhiệm vụ liên quan đến trí thông minh của con người , như học tập , suy luận , giải quyết vấn đề , nhận thức và đưa ra quyết định . Đây là một lĩnh vực nghiên cứu thuộc khoa học máy tính , tập trung phát triển và nghiên cứu các phương pháp cùng phần mềm giúp máy móc có khả năng nhận thức môi trường xung quanh , sử dụng học tập và trí tuệ để thực hiện hành động nhằm tối đa hóa khả năng đạt được các mục tiêu đã định. [ 1 ]"
        ],
        [
         "1",
         "Học máy",
         "[{'header': 'Học máy', 'content': 'Học máy có hiện nay được áp dụng rộng rãi bao gồm máy truy tìm dữ liệu , chẩn đoán y khoa , phát hiện thẻ tín dụng giả , phân tích thị trường chứng khoán , phân loại các chuỗi DNA , nhận dạng tiếng nói và chữ viết , dịch tự động , chơi trò chơi và cử động rô-bốt ( robot locomotion ).\\n'}, {'header': 'Định nghĩa', 'content': 'Dưới góc nhìn của trí tuệ nhân tạo , động lực chính học máy bởi là nhu cầu thu nhận tri thức (knowledge acquisition). Thật vậy, trong nhiều trường hợp ta cần kiến thức chuyên gia là khan hiếm (không đủ chuyên gia ngồi phân loại lừa đảo thẻ tín dụng của tất cả giao dịch hàng ngày) hoặc chậm vì một số nhiệm vụ cần đưa ra quyết định nhanh chóng dựa trên xử lý dữ liệu khổng lồ (trong mua bán chứng khoán phải quyết định trong vài khoảng khắc của giây chẳng hạn) và thiếu ổn định thì buộc phải cần đến máy tính. Ngoài ra, đại đa số dữ liệu sinh ra ngày nay chỉ phù hợp cho máy đọc (computer readable) tiềm tàng nguồn kiến thức quan trọng. Máy học nghiên cứu cách thức để mô hình hóa bài toán cho phép máy tính tự động hiểu, xử lý và học từ dữ liệu để thực thi nhiệm vụ được giao cũng như cách đánh giá giúp tăng tính hiệu quả.\\nTom Mitchell , giáo sư nổi tiếng của Đại học Carnegie Mellon University – CMU định nghĩa cụ thể và chuẩn mực hơn như sau: \"Một chương trình máy tính CT được xem là học cách thực thi một lớp nhiệm vụ NV thông qua trải nghiệm KN, đối với thang đo năng lực NL nếu như dùng NL ta đo thấy năng lực thực thi của chương trình có tiến bộ sau khi trải qua KN\" (máy đã học).\\n'}, {'header': 'Biểu diễn', 'content': 'Biểu diễn (representation) là một trong những vấn đề quan trọng của học máy. Biểu diễn ở đây có thể hiểu làm sao mã hóa (encode) những thông tin của thế giới thật giúp hoàn thành nhiệm vụ một cách hiệu quả và đầy đủ nhất có thể. Thông tin ở đây bao hàm cả thông tin về dữ liệu đầu vào, đầu ra hay các trạng thái của hệ thống; cũng như cách đánh giá hiệu quả của chương trình.\\nThông thường, trong học máy người ta hay xây dựng các mô hình sử dụng những biến ngẫu nhiên cho việc biểu diễn dữ liệu và nội trạng thái của hệ thống. Ví dụ: dùng biến ngẫu nhiên để biểu thị cho tính chất của email là spam (tương ứng giá trị 0) hay là bình thường (tương ứng 1). Mối tương quan giữa các biến ngẫu nhiên này có thể sử dụng ví dụ như mô hình xác suất dạng đồ thị để miêu tả. Mặt khác, để đo hiệu quả có thể dùng các hàm thiệt hại (hay hàm tiện ích , trong tiếng Anh là loss function và utility function tương ứng).\\n'}, {'header': 'Tính phổ quát', 'content': 'Một trong những trọng tâm khác của học máy là đạt được tính phổ quát (generalization), nói cách khác là tính chất của chương trình có thể làm việc tốt với dữ liệu mà nó chưa gặp bao giờ (unseen data). Một chương trình chỉ hiệu quả với dữ liệu đã gặp nhìn chung không có nhiều tính hữu dụng.\\nLấy ví dụ về xếp thư điện tử tự động như trên, một hệ thống tự động sau khi trải qua quá trình học từ dữ liệu (\"training\") có thể suy diễn một số nguyên tắc riêng (chẳng hạn như xem xét nội dung: nếu thư được viết bằng tiếng Anh mà chứa một số từ như \"porn\", \"sell\", \"good product\" hoặc người gửi đến từ Somalia trong khi người nhận ở Hà Nội không thân quen nhau) để quyết định xem có phải là thư rác hay không. Tuy nhiên, nếu như trong dữ liệu bài giảng ( training data ) có ngôn ngữ khác trong thực tế (tiếng Việt thay vì tiếng Anh) hoặc thậm chí không phải dạng thuần văn bản (dạng ảnh khiến cho bóc tách nội dung khó hơn hoặc không thể) thì rất có thể máy sẽ dự báo không chính xác nữa.\\nMột số chương trình có thể tự động cập nhật trong thời gian thực (ví dụ như người sử dụng có chỉ ra rằng thư bị sắp xếp sai danh mục).\\n'}, {'header': 'Tương tác với con người', 'content': 'Một số hệ thống học máy nỗ lực loại bỏ nhu cầu trực giác của con người trong việc phân tích dữ liệu, trong khi các hệ thống khác hướng đến việc tăng sự cộng tác giữa người và máy. Không thể loại bỏ hoàn toàn tác động của con người vì các nhà thiết kế hệ thống phải chỉ định cách biểu diễn của dữ liệu và những cơ chế nào sẽ được dùng để tìm kiếm các đặc tính của dữ liệu. Học máy có thể được xem là một nỗ lực để tự động hóa một số phần của phương pháp khoa học . Một số nhà nghiên cứu học máy tạo ra các phương pháp bên trong các khuôn khổ của thống kê Bayes .\\n'}, {'header': 'Tương quan với Khai phá dữ liệu', 'content': 'Khai phá dữ liệu và học máy là hai khái niệm hay bị nhầm lẫn. Hai lĩnh vực này nhìn chung gần với nhau và đôi khi dùng chung nhiều phương pháp, công cụ nhưng khác biệt chính là ở mục tiêu:\\nKhai phá dữ liệu: thường mục tiêu là tìm kiếm những thông tin, tri thức hoàn toàn mới tiềm năng có ích trong nguồn dữ liệu.\\nHọc máy: dự đoán một số thông tin của dữ liệu dựa trên những đặc tính đã biết.\\n'}, {'header': 'Các loại giải thuật', 'content': 'Các thuật toán học máy được phân loại theo kết quả mong muốn của thuật toán. Các loại thuật toán thường dùng bao gồm:\\nHọc có giám sát —trong đó, thuật toán tạo ra một hàm ánh xạ dữ liệu vào tới kết quả mong muốn. Một phát biểu chuẩn về một việc học có giám sát là bài toán phân loại : chương trình cần học (cách xấp xỉ biểu hiện của) một hàm ánh xạ một vector [ X 1 , X 2 , … X N ] {\\\\displaystyle [X_{1},X_{2},\\\\ldots X_{N}]} tới một vài lớp bằng cách xem xét một số mẫu dữ liệu – kết quả của hàm đó.\\nHọc không giám sát —mô hình hóa một tập dữ liệu, không có sẵn các ví dụ đã được gắn nhãn.\\nHọc nửa giám sát —kết hợp các ví dụ có gắn nhãn và không gắn nhãn để sinh một hàm hoặc một bộ phân loại thích hợp.\\nHọc tăng cường —trong đó, thuật toán học một chính sách hành động tùy theo các quan sát về thế giới. Mỗi hành động đều có tác động tới môi trường, và môi trường cung cấp thông tin phản hồi để hướng dẫn cho thuật toán của quá trình học.\\nChuyển đổi —tương tự học có giám sát nhưng không xây dựng hàm một cách rõ ràng. Thay vì thế, cố gắng đoán kết quả mới dựa vào các dữ liệu huấn luyện, kết quả huấn luyện, và dữ liệu thử nghiệm có sẵn trong quá trình huấn luyện.\\nHọc cách học —trong đó thuật toán học thiên kiến quy nạp của chính mình, dựa theo các kinh nghiệm đã gặp.\\nPhân tích hiệu quả các thuật toán học máy là một nhánh của ngành thống kê , được biết với tên lý thuyết học điện toán .\\n'}, {'header': 'Các chủ đề về máy học', 'content': 'Danh sách các chủ đề của môn học này:\\nMô hình hóa các hàm mật độ xác suất điều kiện : hồi quy và phân loại Mạng nơ-ron Máy học cực độ (Extreme learning machine) Cây quyết định Lập trình biểu thức gen Lập trình di truyền Hồi quy quá trình Gauss Phân tích biệt thức tuyến tính k láng giềng gần nhất Độ dài thông điệp tối thiểu Cảm tri nguyên Hàm cơ sở xuyên tâm Máy vector hỗ trợ (Support Vector Machine)\\nMạng nơ-ron\\nMáy học cực độ (Extreme learning machine)\\nCây quyết định\\nLập trình biểu thức gen\\nLập trình di truyền\\nHồi quy quá trình Gauss\\nPhân tích biệt thức tuyến tính\\nk láng giềng gần nhất\\nĐộ dài thông điệp tối thiểu\\nCảm tri nguyên\\nHàm cơ sở xuyên tâm\\nMáy vector hỗ trợ (Support Vector Machine)\\nMô hình hóa các hàm mật độ xác suất qua các mô hình phát sinh : Thuật toán cực đại kì vọng Các mô hình đồ họa gồm mạng Bayes và mạng Markov Ánh xạ topo phát sinh\\nThuật toán cực đại kì vọng\\nCác mô hình đồ họa gồm mạng Bayes và mạng Markov\\nÁnh xạ topo phát sinh\\nCác kỹ thuật suy luận xấp xỉ đúng: Chuỗi Markov phương pháp Monte Carlo Phương pháp biến thiên\\nChuỗi Markov phương pháp Monte Carlo\\nPhương pháp biến thiên\\nTối ưu hóa : hầu hết các phương pháp trên đều sử dụng tối ưu hóa hoặc là các thể hiện của các thuật toán tối ưu hóa.\\nMạng nơ-ron\\nMáy học cực độ (Extreme learning machine)\\nCây quyết định\\nLập trình biểu thức gen\\nLập trình di truyền\\nHồi quy quá trình Gauss\\nPhân tích biệt thức tuyến tính\\nk láng giềng gần nhất\\nĐộ dài thông điệp tối thiểu\\nCảm tri nguyên\\nHàm cơ sở xuyên tâm\\nMáy vector hỗ trợ (Support Vector Machine)\\nThuật toán cực đại kì vọng\\nCác mô hình đồ họa gồm mạng Bayes và mạng Markov\\nÁnh xạ topo phát sinh\\nChuỗi Markov phương pháp Monte Carlo\\nPhương pháp biến thiên\\n'}]",
         "Học máy hay máy học ( machine learning ) là một lĩnh vực của trí tuệ nhân tạo liên quan đến việc nghiên cứu và xây dựng các kĩ thuật cho phép các hệ thống \"học\" tự động từ dữ liệu để giải quyết những vấn đề cụ thể. Các thuật toán học máy xây dựng một mô hình dựa trên dữ liệu mẫu, được gọi là dữ liệu huấn luyện , để đưa ra dự đoán hoặc quyết định mà không cần được lập trình chi tiết về việc đưa ra dự đoán hoặc quyết định này. Ví dụ như các máy có thể \"học\" cách phân loại thư điện tử xem có phải thư rác (spam) hay không và tự động xếp thư vào thư mục tương ứng. Học máy rất gần với suy diễn thống kê (statistical inference) tuy có khác nhau về thuật ngữ. Một nhánh của học máy là học sâu phát triển rất mạnh mẽ gần đây và có những kết quả vượt trội so với các phương pháp học máy khác. Học máy có liên quan lớn đến thống kê , vì cả hai lĩnh vực đều nghiên cứu việc phân tích dữ liệu, nhưng khác với thống kê, học máy tập trung vào sự phức tạp của các giải thuật trong việc thực thi tính toán. Nhiều bài toán suy luận được xếp vào loại bài toán NP-khó , vì thế một phần của học máy là nghiên cứu sự phát triển các giải thuật suy luận xấp xỉ mà có thể xử lý được."
        ],
        [
         "2",
         "Học sâu",
         "[{'header': 'Học sâu', 'content': 'Mạng thần kinh nhân tạo được lấy cảm hứng từ việc xử lý thông tin và các nút giao tiếp phân tán trong hệ sinh học . Nó có nhiều khác biệt so với não sinh học. Cụ thể, mạng thần kinh nhân tạo thường có tính tĩnh và mang tính biểu tượng, trong khi não bộ của hầu hết các sinh vật sống có tính động (linh hoạt) và analog . [ 2 ] [ 3 ]\\nHọc sâu thường được nhắc đến cùng với Dữ liệu lớn ( Big Data ) và Trí tuệ nhân tạo (AI). Đã có nhiều ứng dụng trong thực tế , đang phát triển mạnh theo sự phát triển của tốc độ máy tính đặc biệt là khả năng tính toán trên GPU và sự tăng nhanh của dữ liệu cùng với các framework (TensorFlow hay Pytorch) làm việc xây dựng model trở nên dễ dàng hơn.\\nHọc sâu là một phần của một họ các phương pháp học máy rộng hơn dựa trên đại diện học của dữ liệu. Một quan sát (ví dụ như, một hình ảnh) có thể được biểu diễn bằng nhiều cách như một vector của các giá trị cường độ cho mỗi điểm ảnh, hoặc một cách trừu tượng hơn như là một tập hợp các cạnh, các khu vực hình dạng cụ thể, vv. Một vài đại diện làm khiến việc học các nhiệm vụ dễ dàng hơn (ví dụ, nhận dạng khuôn mặt hoặc biểu hiện cảm xúc trên khuôn mặt) từ các ví dụ. Một trong những hứa hẹn của học sâu là thay thế các tính năng thủ công bằng các thuật toán hiệu quả đối với học không có giám sát hoặc nửa giám sát và tính năng phân cấp.\\nNhiều kiến trúc học sâu khác nhau như mạng neuron sâu , mã mạng neuron tích chập sâu , mạng niềm tin sâu và mạng neuron tái phát đã được áp dụng cho các lĩnh vực như thị giác máy tính , tự động nhận dạng giọng nói , xử lý ngôn ngữ tự nhiên , nhận dạng âm thanh ngôn ngữ và tin sinh học , chúng đã được chứng minh là tạo ra các kết quả rất tốt đối với nhiều nhiệm vụ khác nhau.\\nNgoài ra, học sâu đã trở thành một từ ngữ thời thượng, hay một thương hiệu của mạng neuron .\\n'}, {'header': 'Định nghĩa', 'content': 'Có một số cách để mô tả học sâu. Học sâu là một lớp của các thuật toán máy học mà (pp199–200)\\nSử dụng một tầng (cascade) nhiều lớp các đơn vị xử lý phi tuyến để trích tách đặc điểm và chuyển đổi. Mỗi lớp kế tiếp dùng đầu ra từ lớp trước làm đầu vào. Các thuật toán này có thể được giám sát hoặc không cần giám sát và các ứng dụng bao gồm các mô hình phân tích (không có giám sát) và phân loại (giám sát).\\nDựa trên học (không có giám sát) của nhiều cấp các đặc điểm hoặc đại diện của dữ liệu. Các tính năng cao cấp bắt nguồn từ các tính năng thấp cấp hơn để tạo thành một đại diện thứ bậc.\\nLà một phần của lĩnh vực máy học rộng lớn hơn về việc học đại diện dữ liệu.\\nHọc nhiều cấp độ đại diện tương ứng với các mức độ trừu tượng khác nhau; các mức độ hình thành một hệ thống phân cấp của các khái niệm.\\nCác định nghĩa này có điểm chung là (1) nhiều lớp các đơn vị xử lý phi tuyến và (2) học có giám sát hoặc không có giám sát của biểu diễn đặc tính ở mỗi lớp, với các lớp hình thành một hệ thống các tính năng phân cấp từ thấp đến cao cấp. (p200) Các thành phần của một lớp của đơn vị xử lý phi tuyến sử dụng một thuật toán học sâu tùy theo vấn đề cần được giải quyết. Các lớp được sử dụng trong học sâu bao gồm các lớp ẩn của một mạng neuron nhân tạo và tập các công thức mệnh đề phức tạp. Chúng cũng có thể bao gồm các biến tiềm ẩn được tổ chức thành các lớp chọn lọc trong các mô hình thể sinh (có khả năng sinh ra) sâu như các nút trong Deep Belief Networks và Deep Boltzmann Machines.\\nCác thuật toán học sâu tương phản với các thuật toán học nông bởi số biến đổi được tham số hóa một tín hiệu gặp phải khi nó lan truyền từ các lớp đầu vào đến lớp đầu ra, nơi một biến đổi được tham số hóa là một đơn vị xử lý có các thông số có thể huấn luyện được, chẳng hạn như trọng số và ngưỡng. (p6) Một chuỗi các biến đổi từ đầu vào đến đầu ra là một đường gán kế thừa (CAP- credit assignment path). CAP mô tả các kết nối quan hệ nhân quả tiềm năng giữa đầu vào và đầu ra và có thể thay đổi chiều dài. Đối với một mạng neuron nuôi tiến (feedforward), độ sâu của CAP, và do đó độ sâu của mạng đó, là số lượng các lớp ẩn cộng 1 (lớp đầu ra cũng là tham số hóa). Đối với mạng neuron tái phát , trong đó một tín hiệu có thể truyền thông qua một lớp nhiều hơn một lần, CAPcó khả năng không bị giới hạn chiều dài. Không có sự thống nhất chung về ngưỡng của độ sâu chia học cạn với học sâu, nhưng hầu hết các nhà nghiên cứu trong lĩnh vực đồng ý rằng học sâu có nhiều lớp phi tuyến (CAP > 2) và Schmidhuber coi CAP > 10 để là học rất sâu. (p7)\\n'}, {'header': 'Khái niệm cơ bản', 'content': 'Các thuật toán học sâu dựa trên các đại diện phân phối. Giả định tiềm ẩn đằng sau các đại diện phân phối là các dữ liệu được quan sát là được tạo ra bởi sự tương tác của các yếu tố được tổ chức theo lớp. Học sâu thêm giả định rằng các lớp của các yếu tố này tương ứng với các mức độ trừu tượng hay theo thành phần. Các con số khác nhau của các lớp và kích thước của lớp có thể được sử dụng để quy định các lượng trừu tượng khác.\\nHọc sâu khai thác ý tưởng thứ bậc các yếu tố giải thích này ở cấp cao hơn, những khái niệm trừu tượng hơn được học từ các cấp độ thấp hơn. Những kiến trúc này thường được xây dựng với một phương pháp lớp chồng lớp tham lam . Học sâu giúp để tháo gỡ những khái niệm trừu tượng này và chọn ra những đặc điểm cần thiết cho việc học.\\nĐối với các nhiệm vụ học có giám sát , các phương pháp học sâu sẽ tránh kỹ thuật đặc điểm (feature engineering), bằng cách dịch các dữ liệu vào các đại diện trung gian nhỏ gọn giống như các thành phần chính , và lấy được các cấu trúc lớp mà loại bỏ sự thừa thải trong đại diện.\\nRất nhiều các thuật toán học sâu được áp dụng cho các nhiệm vụ học không có giám sát . Đây là một lợi ích quan trọng bởi vì dữ liệu không dán nhãn (chưa phân loại) thường phong phú hơn các dữ liệu dán nhãn. Một ví dụ của một cấu trúc sâu có thể được đào tạo theo cách không có giám sát là một mạng lưới tin sâu (deep belief network).\\n'}, {'header': 'Diễn giải', 'content': 'Mạng neuron sâu thường được giải thích theo cách: định lý xấp xỉ tổng quát hoặc Suy luận xác suất .\\n'}, {'header': 'Diễn giải Định lý Xấp xỉ Phổ quát', 'content': 'Định lý xấp xỉ phổ quát đề cập đến khả năng của mạng neuron tiến tiếp (feedforward) với một lớp ẩn có kích thước hữu hạn đơn để xấp xỉ các hàm liên tục .\\nNăm 1989, là bằng chứng đầu tiên được xuất bản bởi George Cybenko cho các hàm kích hoạt h ình sigma và được mở rộng đối với các kiến trúc nuôi tiến nhiều lớp vào năm 1991 bởi Kurt Hornik.\\n'}, {'header': 'Diễn giải xác suất', 'content': 'Diễn giải xác suất bắt nguồn từ lĩnh vực máy học . Nó có đặc điểm suy luận, cũng như các khái niệm tối ưu hóa huấn luyện và kiểm tra , liên quan đến việc phù hợp và tổng quát hóa tương ứng. Cụ thể hơn, diễn giải xác suất sẽ xem xét kích hoạt một cách phi tuyến như là một hàm phân phối tích lũy . Xem mạng tin sâu . Diễn giải xác suất dẫn đến sự ra đời của dropout như regularizer trong mạng neuron.\\nDiễn giải xác suất đã được giới thiệu và phổ biến rộng rãi bởi những tiên phong như Geoff Hinton , Yoshua Bengio , Yann Le Cun , Juergen Schmidhuber .\\n'}, {'header': 'Lịch sử', 'content': 'Các kiến trúc học sâu, đặc biệt là những kiến trúc được xây dựng từ mạng neuron nhân tạo (ANN), đã từng thống trị ít nhất là tới Neocognitron được giới thiệu bởi Masahiko Fukushima vào năm 1980. Chính các ANN lại thống trị thậm chí lâu hơn nữa. Thách thức là làm thế nào để đào tạo mạng lưới này với nhiều lớp. Năm 1989, Yann Le Cun và các cộng sự đã có thể áp dụng các thuật toán truyền ngược tiêu chuẩn, khoảng từ năm 1974, đối với một mạng neuron sâu với mục đích nhận dạng chữ viết tay mã ZIP trong các bức thư. Mặc dù sự thành công trong việc áp dụng thuật toán này, thời gian để đào tạo mạng dựa trên số liệu này mất khoảng 3 ngày, làm cho việc sử dụng nó vào các mục đích bình thường trở nên không thực tế. Năm 1995, Brendan Frey đã chứng minh rằng có thể đào tạo một mạng nơ ron bao gồm đầy đủ sáu lớp kết nối và vài trăm đơn vị ẩn bằng cách sử dụng thuật toán đánh thức giấc ngủ , nó được hợp tác phát triển với Peter Dayan và Geoffrey Hinton . Tuy nhiên, việc huấn luyện phải mất hai ngày.\\nNhiều yếu tố góp phần vào lý do gây ra tốc độ chậm, một là vấn đề biến mất gradient được phân tích vào năm 1991 bởi Sepp Hochreiter .\\nTrong năm 1991 những mạng neuron như vậy được sử dụng để nhận diện chữ số viết tay 2-D cách ly, nhận dạng đối tượng 3-D được thực hiện bằng cách kết hợp các hình ảnh 2-D với một mô hình đối tượng 3-D thủ công. Juyang Weng và các cộng sự đề xuất rằng một bộ não người không sử dụng một mô hình đối tượng 3-D nguyên khối, và vào năm 1992, họ xuất bản Cresceptron, một phương pháp để thực hiện nhận dạng đối tượng 3-D trực tiếp từ các hậu trường lộn xộn. Cresceptron là một ghép tầng của các lớp tương tự như Neocognitron. Nhưng trong khi Neocognitron yêu cầu một lập trình viên con người can thiệp, Cresceptron sẽ tự động học được một số đặc điểm không có giám sát trong mỗi lớp, nơi mà mỗi đặc điểm được đại diện bởi một nhân tích chập. Cresceptron cũng phân đoạn từng đối tượng học được từ một cảnh nền lộn xộn thông qua việc phân tích ngược mạng đó. Thăm dò max, bây giờ thường được thông qua bởi các mạng neuron sâu (ví dụ: các kiểm tra ImageNet), lần đầu tiên sử dụng trong Cresceptron để giảm độ phân giải vị trí bởi của một hệ số (2x2) đến 1 thông qua việc ghép tầng tổng quát hóa tốt hơn. Mặc dù có những lợi thế như thế, các mô hình đơn giản hơn sử dụng nhiệm vụ cụ thể có đặc điểm thủ công như bộ Gabor và các máy hỗ trợ vector (SVM-support vector machines) đã là lựa chọn phổ biến trong thập niên 1990 và thập niên 2000, bởi vì chi phí tính toán bởi các ANN và vì thiếu sự hiểu biết về cách thức bộ não tự quản các kết nối mạng sinh học của nó.\\nTrong lịch sử lâu dài của nhận dạng giọng nói, cả học nông và học sâu (ví dụ, các mạng tái phát) của mạng neuron nhân tạo đã được khám phá trong nhiều năm. Nhưng những phương pháp này không bao giờ thắng được công nghệ mô hình hỗn hợp / mô hình Markov ẩn Gaussian (GMM-HMM) thủ công-nội bộ dựa trên các mô hình thể sinh của việc huấn luyện nhận dạng giọng nói một cách rõ ràng.\\nMột số khó khăn chính đã được phân tích một cách có phương pháp, bao gồm giảm bớt gradient và cấu trúc tương quan thời gian yếu và trong các mô hình tiên đoán thần kinh. Những khó khăn bổ sung đó là thiếu dữ liệu huấn luyện lớn và khả năng tính toán yếu trong thời gian ban đầu. Vì vậy, hầu hết nhà nghiên cứu nhận dạng giọng nói đã hiểu rõ các rào cản như vậy đã chuyển ra khỏi các mạng nơ ron để theo đuổi mô hình thể sinh, cho đến khi một sự hồi sinh gần đây của học sâu đã vượt qua tất cả những khó khăn này. Hinton và các cộng sự và Đặng cùng các cộng sự đã xem xét một phần của lịch sử này gầy đây về cách họ cộng tác với nhau và sau đó với các đồng nghiệp giữa các nhóm tái phát động nghiên cứu mạng neuron và bắt đầu nghiên cứu học sâu và các ứng dụng nhận dạng giọng nói.\\n'}, {'header': 'Các mạng neuron nhân tạo', 'content': 'Một số phương pháp học sâu thành công nhất là mạng neuron nhân tạo. Mạng neuron nhân tạo được lấy cảm hứng từ các mô hình sinh học năm 1959 được đề xuất bởi người đoạt giải Nobel David H. Hubel & Torsten Wiesel , 2 người đã tìm thấy hai loại tế bào trong vỏ não thị giác chính : các tế bào đơn giản và các tế bào phức tạp . Nhiều mạng neuron nhân tạo có thể được xem như là các mô hình ghép tầng của các tế bào loại lấy cảm hứng từ những quan sát sinh học.\\nNeocognitron của Fukushima giới thiệu các mạng neuron tích chập được đào tạo một phần bởi học không có giám sát với các đặc điểm được con người hướng dẫn trong mặt phẳng thần kinh. Yann LeCun...(1989) áp dụng truyền ngược có giám sát cho các kiến trúc như vậy. Weng... (1992) công bố các mạng neuron tích chập Cresceptron để nhận dạng các đối tượng 3-D từ các hình ảnh có hậu trường lộn xộn và phân khúc của các đối tượng từ hình ảnh đó.\\nMột nhu cầu rõ ràng để nhận dạng các đối tượng 3-D nói chung là ít nhất là thay đổi tính bất biến và khả năng chịu biến dạng. Thăm dò Max (Max-pooling) xuất hiện lần đầu tiên được đề xuất bởi Cresceptron để kích hoạt mạng để chịu đựng được sự biến dạng từ nhỏ đến lớn theo một cách phân cấp, trong khi sử dụng tích chập. Thăm dò mã đã hoạt động tốt, nhưng không đảm bảo, dịch chuyển bất định ở mức điểm ảnh.\\nVới sự ra đời của thuật toán truyền ngược được khám phá ra một cách độc lập bởi nhiều nhóm trong thập niên 1970 và 1980, nhiều nhà nghiên cứu đã cố gắng để đào tạo các mạng neuron nhân tạo sâu có giám sát từ đầu, ban đầu với rất ít thành công. Luận văn tốt nghiệp cao đẳng của Sepp Hochreiter năm 1991 chính thức xác định lý do cho sự thất bại này là vấn đề biến mất gradient , ảnh hưởng đến các mạng nuôi tiến nhiều lớp và các mạng neuron hồi qui. Các mạng tái phát (hồi qui) được huấn luyện bằng cách trải chúng ra vào các mạng nuôi tiến rất sâu, nơi một lớp mới được tạo ra cho mỗi bước thời gian của một chuỗi đầu vào được xử lý bởi mạng này. Khi các sai số truyền từ lớp này sang lớp khác, chúng co lại theo cấp số nhân với số lượng lớp, ngăn cản điều chỉnh trọng số nơ ron, dựa trên những sai số này.\\nĐể khắc phục vấn đề này, một số phương pháp đã được đề xuất. Một là thứ bậc đa cấp của mạng của Jürgen Schmidhuber (1992) cấp độ một được đào tạo trước tại một thời điểm bởi học không có giám sát, điều chỉnh bởi truyền ngược . Ở đây, mỗi cấp học một đại diện bị nén của các quan sát được đưa đến cấp độ tiếp theo.\\nPhương pháp khác là mạng bộ nhớ dài ngắn hạn (LSTM) của Hochreiter & Schmidhuber (1997). Trong năm 2009, các mạng LSTM đa chiều sâu đã chiến thắng ba cuộc thi ICDAR năm 2009 trong nhận dạng chữ viết tay, mà không có bất kỳ kiến thức sẵn có về ba ngôn ngữ để được học.\\nSven Behnke vào năm 2003 dựa chỉ vào các dấu hiệu của gradient ( Rprop ) khi đào tạo Kim tự tháp Trừu tượng Nơ ron của mình để giải bài toán giống như tái tạo hình ảnh và định vị khuôn mặt.\\nCác phương pháp khác cũng sử dụng đào tạo trước không có giám sát để tạo ra một mạng nơ ron, khiến nó lần đầu tiên học được bộ dò đặc điểm nói chung là hữu ích. Sau đó mạng này được đào tạo tiếp tục bằng cách truyền ngược có giám sát để phân loại dữ liệu có dán nhãn. Mô hình sâu này của Hinton và các cộng sự (2006) liên quan đến việc học phân phối của một đại diện cao cấp bằng cách sử dụng các lớp kế tiếp của các biến tiềm ẩn nhị phân hoặc giá trị thực. nó sử dụng một máy Boltzmann hạn chế (Smolensky, 1986) để mô hình hóa mỗi lớp mới của các đặc điểm cao cấp hơn. Mỗi lớp mới đảm bảo một sự tăng trưởng trong biên thấp của kiểm tra tỷ lệ giống của dữ liệu, do đó tăng cường cho mô hình, nếu được huấn luyện đúng cách. Một khi đã đủ nhiều lớp đã được học, kiến trúc sâu có thể được sử dụng như là một mô hình thể sinh bằng cách tái tạo dữ liệu khi lấy mẫu xuống mô hình đó (một \"sự vượt qua tổ tiên\") từ các kích hoạt tính năng cấp đỉnh.\\nHinton báo cáo rằng các mô hình của mình là trích xuất các đặc điểm hiệu quả tính theo chiều cao, cấu trúc dữ liệu.\\nNhóm Google Brain do Andrew Ng và Jeff Dean đã tạo ra một mạng nơ ron học cách để nhận dạng được những khái niệm cao cấp hơn, chẳng hạn như con mèo, chỉ từ xem những hình ảnh không được dán nhãn từ các video trên YouTube .\\nCác phương pháp khác dựa trên sức mạnh xử lý vượt trội của các máy tính hiện đại, đặc biệt, là các GPU . Trong năm 2010, Dan Ciresan và các đồng nghiệp trong nhóm của Jürgen Schmidhuber tại Phòng thí nghiệp AI Thụy Sĩ IDSIA cho thấy rằng mặc dù \"vấn đề biến mất gradient\" nêu trên, thì với sức mạnh xử lý vượt trội của các GPU làm khiến cho đồng truyền ngược đơn giản trở nên khả thi đối với các mạng neuron nuôi tiến sâu với nhiều lớp. Phương pháp này tốt hơn tất cả các kỹ thuật máy học khác trong việc giải bài toán cũ nổi tiếng MNIST chữ số viết tay của Yann Le Cun và các đồng nghiệp tại NYU .\\nCùng lúc đó, cuối năm 2009, học sâu đã thực hiện xâm nhập vào nhận dạng giọng nói, khi được đánh dấu bởi Hội thảo NIPS về học sâu trong nhận dạng giọng nói. Việc tăng cường hợp tác giữa các nhà nghiên cứu của Microsoft Research và đại học Toronto đã chứng minh vào giữa năm 2010 ở Redmond rằng các mạng neuron sâu giao tiếp với một mô hình Markov ẩn với các trạng thái phụ thuộc vào ngữ cảnh xác định lớp đầu ra của mạng neuron có thể giảm mạnh lỗi trong các tác vụ nhận dạng tiếng nói có vốn từ vựng lớn như tìm kiếm qua giọng nói. Cùng một mô hình mạng thần kinh sâu được chỉ ra cho quy mô lên đến các tác vụ cấp Tổng đài khoảng một năm sau đó tại Microsoft Research châu Á.\\nTính đến năm 2011, tiến bộ trong các mạng nuôi tiến học sâu đã thay thế các lớp tích chập và các lớp thăm dò tối da (max-pooling), đứng đầu bởi một số lớp có đầy đủ kết nối hoặc kết nối từng phần theo sau bởi một lớp phân loại cuối cùng. Việc huấn luyện thường được thực hiện mà không có bất kỳ đào tạo trước không có giám sát nào. Từ năm 2011, các thực thi dựa trên GPU của hướng tiếp cận này đã thắng nhiều cuộc thi nhận dạng hình mẫu, bao gồm cuộc thi IJCNN 2011 Traffic Sign Recognition Competition, ISBI 2012 Segmentation of neuronal structures in EM stacks challenge, và các cuộc thi khác.\\nCác phương pháp học sâu có giám sát như vậy cũng đã là bộ nhậng dạng mô hình nhân tạo đầu tiên đạt được hiệu suất có thể cạnh tranh lại được với con người trong những công việc nhất định.\\nĐể vượt qua những rào cản của AI yếu được đại diện bằng học sâu, cần phải để vượt qua các kiến trúc học sâu, bởi vì bộ não sinh học sử dụng cả mạch học nông và học sâu theo báo cáo của ngành giải phẫu não bộ chỉ ra một loạt các tính bất biến. Weng lập luận rằng não tự kết nối chủ yếu theo các thống kê tín hiệu và, do đó, một phân tầng nối tiếp không thể bắt tất cả các vật phụ thuộc thống kê chủ yếu. Các ANN đã có thể đảm bảo sự thay đổi bất biến để đối phó với các đối tượng tự nhiên lớn và nhỏ trong hậu trường có sự xáo trộn lớn, chỉ khi các bất định mở rộng vượt ra ngoài sự thay đổi, tới tất cả các khái niệm ANN đã học được, chẳng hạn như vị trí, loại (nhãn lớp đối tượng), quy mô, ánh sáng. Điều này được thực hiện trong các Mạng Phát triển (DN) có biểu hiện là Where-What Networks, WWN-1 (2008) cho đến WWN-7 (2013).\\n'}, {'header': 'Kiến trúc', 'content': 'Có một lượng rất lớn các biến thể của kiến trúc sâu. Hầu hết chúng là nhánh sinh ra từ một số kiến trúc cha ban đầu. Không phải là luôn luôn có thể so sánh hiệu suất của nhiều kiến trúc cùng với nhau, vì chúng không phải là tất cả đánh giá trên cùng một tập dữ liệu. Học sâu học là một lĩnh vực phát triển nhanh, và các kiến trúc, biến thể, hoặc các thuật toán mới xuất hiện mỗi vài tuần.\\n'}, {'header': 'Các mạng neuron sâu', 'content': 'Mạng neuron sâu (DNN-Deep neural Network) là một mạng neuron nhân tạo (ANN) với nhiều đơn vị lớp ẩn giữa lớp đầu vào và đầu ra. Tương tự như các ANN nông, các DNN nông có thể mô hình mối quan hệ phi tuyến phức tạp. Các kiến trúc DNN, ví dụ như để phát hiện và phân tích đối tượng tạo ra các mô hình hỗn hợp trong đó đối tượng này được thể hiện như một thành phần được xếp lớp của các hình ảnh nguyên thủy. Các lớp phụ cho phép các thành phần của các đặc điểm từ các lớp thấp hơn, đem lại tiềm năng của mô hình hóa dữ liệu phức tạp với các đơn vị ít hơn so với một mạng lưới nông thực hiện tương tự như vậy.\\nCác DNN thường được thiết kế như các mạng nuôi tiến, nhưng nghiên cứu gần đây đã áp dụng thành công kiến trúc học sâu đối với các mạng nơ ron tái phát cho các ứng dụng chẳng hạn như mô hình hóa ngôn ngữ . Các mạng neuron sâu tích chập (CNN) được sử dụng trong thị giác máy tính nơi thành công của chúng đã được ghi nhận. Gần đây hơn, các CNN đã được áp dụng để mô hình hóa âm thanh cho nhận dạng giọng nói tự động (ASR), nơi chúng đã cho thấy sự thành công trong các mô hình trước đó. Để đơn giản, ta hãy nhìn vào việc huấn luyện các DNN được đưa ra ở đây.\\nMột DNN có thể là mô hình biết suy xét được đào tạo với thuật toán truyền ngược tiêu chuẩn. Các bản cập nhật trọng số có thể được thực hiện thông qua độ dốc gradient ngẫu nhiên bằng cách sử dụng phương trình sau:\\nTrong đó, η {\\\\displaystyle \\\\eta } là tốc độ học, và C {\\\\displaystyle C} là hàm chi phí. Việc lựa chọn của hàm chi phí phụ thuộc vào các yếu tố như loại học tập (giám sát, không có giám sát, tăng cường , vv) và hàm kích hoạt . Ví dụ, khi thực hiện học có giám sát về một vấn đề phân loại nhiều lớp , các lựa chọn phổ biến cho hàm kích hoạt và hàm chi phí là hàm softmax (hàm mũ chuẩn hóa) và hàm entropy chéo , tương ứng. Hàm softmax được định nghĩa là p j = exp \\u2061 ( x j ) ∑ k exp \\u2061 ( x k ) {\\\\displaystyle p_{j}={\\\\frac {\\\\exp(x_{j})}{\\\\sum _{k}\\\\exp(x_{k})}}} trong đó p j {\\\\displaystyle p_{j}} thể hiện xác suất của lớp (đầu ra của đơn vị j {\\\\displaystyle j} ) và x j {\\\\displaystyle x_{j}} và x k {\\\\displaystyle x_{k}} hiển thể hiện tổng đầu vào thành các đơn vị j {\\\\displaystyle j} và k {\\\\displaystyle k} của cùng cấp tương ứng. Entropy chéo được định nghĩa là C = − ∑ j d j log \\u2061 ( p j ) {\\\\displaystyle C=-\\\\sum _{j}d_{j}\\\\log(p_{j})} trong đó d j {\\\\displaystyle d_{j}} thể hiện cho xác suất mục tiêu của đơn vị ra j {\\\\displaystyle j} và p j {\\\\displaystyle p_{j}} là đầu ra xác suất cho j {\\\\displaystyle j} sau khi áp dụng hàm kích hoạt.\\nChúng có thể được sử dụng để xuất ra các hộp bao quanh đối tượng trong hình thức của một mặt nạ nhị phân. Chúng cũng được sử dụng cho các hồi quy đa quy mô để tăng độ chính xác của định vị. Hồi qui dựa trên DNN có thể học các đặc điểm mà chụp lại thông tin hình học ngoài việc là một bộ phân loại tốt. Chúng sẽ loại bỏ các giới hạn của việc thiết kế một mô hình mà sẽ chụp lại các bộ phận và quan hệ của chúng một cách rõ ràng. Điều này sẽ giúp học được một loạt các đối tượng rộng lớn. Mô hình này bao gồm nhiều lớp, mỗi trong số đó có một đơn vị chỉnh lại tuyến tính cho các chuyển đổi phi tuyến. Một số lớp là tích chập, trong khi những lớp khác được kết nối đầy đủ. Mỗi lớp tích chập có một thăm dò max bổ sung. Mạng được huấn luyện để giảm thiểu sai số L2 để dự đoán mặt nạ nằm trong dãi qua bộ huấn luyện toàn bộ chứa các hộp đường biên được thể hiện như là mặt nạ.\\nNhư với các ANN, nhiều vấn đề có thể nảy sinh với các DNN nếu chúng được huấn luyện thô sơ. Hai vấn đề phổ biến là overfitting (nhiễu hoặc sai số ngẫu nhiên) và thời gian tính toán.\\nCác DNN có thiên hướng overfitting vì được thêm các lớp trừu tượng, mà cho phép chúng thực hiện mô hình hóa phụ thuộc hiếm hoi vào dữ liệu huấn luyện. Các phương pháp regularization ( quy tắc hóa ) như phân rã trọng số ( ℓ 2 {\\\\displaystyle \\\\ell _{2}} -regularization) hoặc sparsity (rãi) ( ℓ 1 {\\\\displaystyle \\\\ell _{1}} -regularization) có thể được áp dụng trong quá trình huấn luyện để giúp chống lại overfitting. Một phương pháp regularization gần đây được áp dụng cho các DNN là dropout regularization. Trong dropout, một số số lượng đơn vị được bỏ qua ngẫu nhiên từ các lớp ẩn trong quá trình đào tạo. Điều này giúp phá vỡ các phụ thuộc hiếm hoi có thể xảy ra trong dữ liệu đào tạo.\\nPhương pháp chủ đạo cho việc huấn luyện các cấu trúc là sửa lỗi huấn luyện (chẳng hạn như truyền ngược với gradient descent ) do dễ thực hiện và xu hướng hội tụ tốt hơn local optima (tối hưu cục bộ) hơn so với các phương pháp huấn luyện khác. Tuy nhiên, những phương pháp này có thể tốn công tính toán hơn, đặc biệt là cho các DNN. Có rất nhiều tham số huấn luyện để được xem xét với một DNN, chẳng hạn như kích thước (số lượng lớp và số lượng đơn vị trên mỗi lớp), tốc độ học và trọng số ban đầu. Quét thông qua không gian tham số cho các thông số tối ưu có thể không khả thi do chi phí trong thời gian và tài nguyên tính toán. Nhiều \\'mẹo vặt\\' chẳng hạn như bằng cách sử dụng mini-batching (tính toán gradient trên nhiều ví dụ huấn luyện khác nhau cùng một lúc chứ không phải là từng ví dụ một) đã được chỉ ra để tăng tốc độ tính toán. Lượng xử lý lớn thông qua GPU đã tăng tốc đáng kể trong việc huấn luyện, do tính toán ma trận và vector rất thích hợp với các GPU. Lựa chọn thay thế triệt để cho truyền ngược là Extreme Learning Machines (Siêu máy học, các mạng \"No-prop\", huấn luyện không cần truy ngược, các mạng \"không trọng số\", và mạng nơron không kết (non-connectionist neural network) đang thu hút được sự chú ý.\\n'}, {'header': 'Mạng niềm tin sâu (Deep belief network)', 'content': 'Một mạng niềm tin sâu (DBN) là một mô hình xác suất thể sinh , tạo thành bởi nhiều đơn vị ẩn nhiều lớp. Nó có thể được coi là một hàm hợp các mô-đun học đơn giản tạo thành mỗi lớp.\\nMột DBN có thể được sử dụng để huấn luyện trước khả sinh một DNN bằng cách sử dụng các trọng số DBN học như các trọng số DNN ban đầu. Các thuật toán truyền ngược hoặc suy xét khác sau đó có thể được áp dụng để điều chỉnh những trọng số này. Điều này đặc biệt hữu ích khi dữ liệu đào tạo giới hạn là có sẵn, vì các trọng số khởi tạo nghèo nàn có thể cản trở đáng kể hiệu suất của mô hình được học. Các trọng số đào tạo trước này là một vùng không gian trọng số là gần gũi hơn với trọng số tối ưu hơn là các trọng số ban đầu được chọn ngẫu nhiên. Điều này cho phép cả mô hình hóa được cải thiện và hội tụ tinh chỉnh pha nhanh hơn.\\nMột DBN có thể được huấn luyện một cách hiệu quả trong một cách thức không có giám sát, lớp kề lớp, nơi mà các lớp thường được tạo ra từ các máy Boltzmann hạn chế (RBM). Một RBM là một mô hình vô hướng, thể sinh dựa trên năng lượng với một lớp đầu vào \"hiện\" và một ẩn lớp, và các kết nối giữa các lớp nhưng không nằm trong các lớp. Phương pháp huấn luyện cho RBM được đề xuất bởi Geoffrey Hinton để sử dụng với các mô hình \"Product of Expert\" được gọi là tương phản phân kỳ (CD-contrastive divergence). CD cung cấp một xấp xỉ cho phương pháp với khả năng tối đa có vị trí lý tưởng sẽ được áp dụng cho việc học các trọng số của RBM. Trong việc huấn luyện một RBM đơn, các cập nhật trọng số được thực hiện với gradient ascent qua phương trình sau: Δ w i j ( t + 1 ) = w i j ( t ) + η ∂ log \\u2061 ( p ( v ) ) ∂ w i j {\\\\displaystyle \\\\Delta w_{ij}(t+1)=w_{ij}(t)+\\\\eta {\\\\frac {\\\\partial \\\\log(p(v))}{\\\\partial w_{ij}}}} . Trong đó, p ( v ) {\\\\displaystyle p(v)} là xác suất của một vector hiện, được cho bởi p ( v ) = 1 Z ∑ h e − E ( v , h ) {\\\\displaystyle p(v)={\\\\frac {1}{Z}}\\\\sum _{h}e^{-E(v,h)}} . Z {\\\\displaystyle Z} là hàm từng phần, (được sử dụng để chuẩn hóa) và E ( v , h ) {\\\\displaystyle E(v,h)} là hàm năng lượng được gán cho trạng thái của mạng. Một năng lượng thấp hơn chỉ thị mạng đó đang được cấu hình \"đáng mong muốn\" hơn. Gradient ∂ log \\u2061 ( p ( v ) ) ∂ w i j {\\\\displaystyle {\\\\frac {\\\\partial \\\\log(p(v))}{\\\\partial w_{ij}}}} có dạng đơn giản ⟨ v i h j ⟩ data − ⟨ v i h j ⟩ model {\\\\displaystyle \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{data}}-\\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{model}}} trong đó ⟨ ⋯ ⟩ p {\\\\displaystyle \\\\langle \\\\cdots \\\\rangle _{p}} thể hiện các giá trị trung bình đối với phân phối p {\\\\displaystyle p} . Vấn đề này nãy sinh trong việc lấy mẫu ⟨ v i h j ⟩ model {\\\\displaystyle \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{model}}} bởi vì điều này đòi hỏi phải chạy xen kẽ lấy mẫu Gibbs trong một thời gian dài. CD thay thế bwowcs này bằng cách chạy luân phiên lấy mẫu Gibbs cho n {\\\\displaystyle n} bước (giá trị của n = 1 {\\\\displaystyle n=1} được lấy theo kinh nghiệm được chỉ ra là làm việc tốt). Sau n {\\\\displaystyle n} bước, dữ liệu được lấy mẫu và mẫu này sẽ được sử dụng trong ⟨ v i h j ⟩ model {\\\\displaystyle \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{model}}} . Chu trình CD hoạt động như sau:\\nKhởi tạo các đơn vị hiện (visible) tới một vector huấn luyện.\\nCập nhật các đơn vị ẩn song song với các đơn vị hiện: p ( h j = 1 ∣ V ) = σ ( b j + ∑ i v i w i j ) {\\\\displaystyle p(h_{j}=1\\\\mid {\\\\textbf {V}})=\\\\sigma (b_{j}+\\\\sum _{i}v_{i}w_{ij})} . σ {\\\\displaystyle \\\\sigma } là hàm sigmoid và b j {\\\\displaystyle b_{j}} là độ lệch của h j {\\\\displaystyle h_{j}} .\\nCập nhật các đơn vị hiện song song với các đơn vị ẩn đã cho: p ( v i = 1 ∣ H ) = σ ( a i + ∑ j h j w i j ) {\\\\displaystyle p(v_{i}=1\\\\mid {\\\\textbf {H}})=\\\\sigma (a_{i}+\\\\sum _{j}h_{j}w_{ij})} . a i {\\\\displaystyle a_{i}} là độ lệch của v i {\\\\displaystyle v_{i}} . Điều này được gọi là bước \"cải tạo\".\\nTái cập nhật các đơn vị ẩn song song với các đơn vị hiện cải tạo đã cho bằng cách sử dụng phương trình tương tự như trong bước 2.\\nThực hiện cập nhật trọng số: Δ w i j ∝ ⟨ v i h j ⟩ data − ⟨ v i h j ⟩ reconstruction {\\\\displaystyle \\\\Delta w_{ij}\\\\propto \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{data}}-\\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{reconstruction}}} .\\nKhi một RBM được huấn luyện, RBM khác là \"xếp chồng\" trên nó, đưa đầu vào của nó từ cuối lớp đã được huấn luyện. Lớp hiện mới này được khởi tạo với một vector hiện, và các giá trị cho các đơn vị trong các lớp đã được huấn luyện phân công bằng cách sử dụng trọng số hiện tại và các độ lệch. RBM mới này sau đó lại được huấn luyện với chu trình như trên. Toàn bộ quá trình này được lặp lại cho đến khi một số tiêu chí mong muốn chặn lại được đáp ứng.\\nMặc dù xấp xỉ của CD để tối đa khả năng là rất thô (CD đã được chỉ ra là theo gradient của bất kỳ hàm nào), nó đã được kinh nghiệm chỉ ra là có hiệu quả trong huấn luyện các kiến trúc sâu.\\n'}, {'header': 'Mạng nơ ron tích chập (Convolutional neural networks)', 'content': 'Một CNN gồm có một hoặc nhiều hơn các lớp tích chập với các lớp đầy đủ kết nối (đáp ứng phù hợp với những mạng neuron nhân tạo tiêu biểu) trên đỉnh. Nó cũng sử dụng trọng số gắn liền và các lớp thăm dò. Kiến trúc này cho phép các CNN tận dụng lợi thế của cấu trúc 2D của dữ liệu đầu vào. So với những kiến trúc sâu khác, mạng neuron tích chập đang bắt đầu thể hiện kết quả vượt trội trong các ứng dụng hình ảnh và giọng nói. Chúng cũng có thể được huấn luyện với tiêu chuẩn truyền ngược. CNN dễ dàng được đào tạo hơn các mạng nơ ron sâu nuôi tiến thông thường khác, và có ít thông số ước tính hơn, khiến cho chúng trở thành một kiến trúc rất hấp dẫn để sử dụng. Các ví dụ về ứng dụng trong Thị Giác máy tính bao gồm DeepDream .\\n'}, {'header': 'Các mạng niềm tin sâu tích chập', 'content': 'Sử dụng mạng niềm tin sâu (CDBN) là một thành tựu gần đây của học sâu. Các CDBN có cấu trúc rất giống với một mạng neuron tích chập và được huấn luyện tương tự như các mạng niềm tin sâu. Vì vậy, chúng khai thác cấu trúc 2D của hình ảnh, giống như CNN làm, và làm cho việc sử dụng đào tạo trước giống như mạng niềm tin sâu . Chúng quy định một cấu trúc chung mà có thể được sử dụng trong nhiều tác vụ xử lý hình ảnh và tín hiệu. Gần đây, nhiều kết quả benchmark (tiêu chuẩn) dựa trên tập dữ liệu hình ảnh chuẩn như CIFAR đã được thu được kết quả bằng cách sử dụng CDBN.\\n'}, {'header': 'Mạng neuron lưu trữ và truy xuất bộ nhớ lớn', 'content': 'Mạng nơ ron lưu trữ và truy xuất bộ nhớ lớn (LAMSTAR) là các mạng nơ ron học sâu nhanh gồm nhiều lớp mà có thể sử dụng đồng thời nhiều bộ lọc. Các bộ lọc này có thể là phi tuyến, ngẫu nhiên, logic, không cố định , hoặc thậm chí không có tính phân tích. Chúng là học sinh học năng động và liên tục.\\nMạng neuron LAMSTAR có thể phục vụ như là một mạng nơ ron năng động trong không gian hay miền thời gian, hoặc cả hai. Tốc độ của nó được quy định bởi các liên kết-trọng số Hebbian (chương 9 của D. Graupe, 2013), dùng để tích hợp các bộ lọc khác nhau và thường khác nhau (các hàm tiền xử lý) vào nó nhiều lớp và để xếp hạng năng đọng tầm quan trọng của các lớp khác nhau và các hàm liên quan đến nhiệm vụ nhất định cho việc học sâu. Điều này hiển nhiên bắt chước học sinh học mà tích hợp các bộ tiền lý đầu ra khác nhau ( ốc tai , võng mạc , vv) và vỏ não ( thính giác , thị giác , vv) và của các vùng khác nhau của chúng. Khả năng học sâu của nó tăng cường hơn nữa bằng cách sử dụng sự ức chế, sự tương quan và bởi khả năng đối phó với dữ liệu không đầy đủ của nó, hoặc \"mất\" nơ ron hoặc lớp ngay cả khi đang thực thi một tác vụ. Hơn nữa, nó hoàn toàn minh bạch do trọng số liên kết của nó. Các trọng số liên kết cho phép xác định năng động sáng tạo và thừa thải, và tạo thuận lợi cho việc xếp hạng của các lớp, các bộ lọc hoặc các nơ ron đơn lẽ tương ứng với một nhiệm vụ.\\nLAMSTAR đã được áp dụng cho nhiều dự đoán y tế và tài chính (xem Graupe, 2013 Phần 9C), bộ lọc thích nghi nhiễu nhận dạng giọng nói với tiếng ồn không xác định, nhận dạng ảnh tĩnh (Graupe, 2013 Phần 9D), nhận dạng ảnh video, bảo mật phần mềm, điều khiển thích nghi của các hệ thống phi tuyến, vv. LAMSTAR có tốc độ tính toán nhanh hơn nhiều và có lỗi hơi ít hơn so với một mạng nơ ron tích chập dựa trên các bộ lọc hàm- ReLU và thăm dò max, trong một nghiên cứu nhận dạng ký tự so sánh.\\nCác ứng dụng này chứng minh đào sâu vào các khía cạnh của các dữ liệu đó là bị ẩn từ các mạng học nông hoặc thậm chí từ những giác quan của con người (mắt, tai), chẳng hạn như trong trường hợp của dự đoán sự bắt đầu của hiện tượng ngưng thở khi ngủ , của một biểu đồ điện tâm đồ một thai nhi như được ghi chép từ các điện cực gắn trên da được đặt trên bụng người mẹ trong thời gian đầu của thai kỳ, của dự đoán tài chính (Phần 9C trong Graupe, 2013), hoặc trong lọc mù của nhiễu trong nhận dạng giọng nói\\nLAMSTAR đã được đề xuất năm 1996 ( Bằng phát minh 5,920,852 A của Mỹ ) và tiếp tục được phát triển bởi D Graupe và H Kordylewski vào năm 1997-2002. Một phiên bản sửa đổi, được gọi là LAMSTAR 2, được phát triển bởi N C Schneider và D Graupe trong năm 2008.\\n'}, {'header': 'Các mạng xếp chồng sâu', 'content': 'Một kiến trúc sâu dựa trên một hệ thống phân cấp của các khối mô-đun mạng neuron đơn giản là một mạng sâu lồi, được giới thiệu vào năm 2011. Ở đây, bài toán học các trọng số được xây dựng như một bài toán tối ưu hóa lồi với lời giải dạng đóng . Kiến trúc này còn được gọi là một mạng xếp chồng sâu (DSN), nhấn mạnh các cơ chế tương tự với tổng quát hóa xếp chồng. Mỗi khối DSN là một module đơn giản đó là dễ dàng để huấn luyện chính nó trong một kiểu có giám sát mà không cần truyền ngược cho toàn bộ các khối.\\n'}, {'header': 'Mạng lập trình sâu (deep coding network)', 'content': 'Có những lợi thế của một mô hình mà có thể chủ động cập nhật bản thân từ ngữ cảnh trong dữ liệu. Mạng lập trình (DPCN) là một chương trình lập trình tiên đoán , trong đó thông tin từ trên xuống được sử dụng để điều chỉnh theo kinh nghiệm của những cái trước đó cần thiết cho một thủ tục suy luận từ dưới lên bằng các phương tiện của một mô hình thể sinh kết nối cục bộ sâu. Điều này hoạt động bằng cách chiết tách các đặc điểm rời rạc các quan sát biến đổi theo thời gian bằng cách sử dụng một mô hình động học tuyến tính. Sau đó, một chiến lược thăm dò được sử dụng để học các đại diện đặc điểm bất biến. Các đơn vị này tập hợp lại để tạo thành một kiến trúc sâu và được huấn luyện bởi học không giám sát layer-wise tham lam . Các lớp tạo thành một loại xích Markov mà các trạng thái tại bất kỳ lớp nào cũng chỉ phụ thuộc vào các lớp trước và các lớp sau (kế thừa).\\nMạng lập tình dự đoán sâu (DPCN) dự đoán đại diện của lớp, bằng cách sử dụng một cách tiếp cận từ trên xuống bằng cách sử dụng thông tin ở lớp trên và các phụ thuộc thời gian từ các trạng thái trước đó.\\nDPCN có thể được mở rộng để tạo thành một mạng tích chập .\\n'}, {'header': 'Mạng bộ nhớ', 'content': 'Bộ nhớ ngoài tích hợp với các mạng neuron nhân tạo tính đến nghiên cứu đầu tiên trrong đại diện phân phối và các bản đồ tự tổ chức . Ví dụ, trong bộ nhớ phân tán hoặc bộ nhớ phân cấp thời gian , các mô hình được mã hóa bởi các mạng neuron được sử dụng như là các địa chỉ cho bộ nhớ có khả năng định địa chỉ nội dung , với các \"nơ ron\" chủ yếu phục vụ như là các bộ mã hóa và giải mã.\\nTrong thập niên 1990 và thập niên 2000, đã có nhiều công trình liên quan đến bộ nhớ ngắn-hạn dài (LSTM - thêm bộ nhớ khả vi cho các hàm hồi qui). Ví dụ:\\nCác hành động đẩy và lấy ra khả vi cho các mạng bộ nhớ thay thế được gọi là các máy ngăn xếp nơ ron\\nMemory networks where the control network\\'s external differentiable storage is in the fast weights of another network\\nLSTM \"forget gates\"\\nSelf-referential recurrent neural networks (RNNs) with special output units for addressing and rapidly manipulating each of the RNN\\'s own weights in differentiable fashion (internal storage)\\nLearning to transduce with unbounded memory\\nCác mạng bộ nhớ một mở rộng khác của các mạng nơ ron nhân tạo kết hợp với bộ nhớ dài hạn , được phát triển bởi nhóm nghiên cứu Facebook . Bộ nhớ dài hạn có thể được đọc và ghi vào đó, với mục đích sử dụng cho việc dự báo. Các mô hình này đã được áp dụng trong bối cảnh hỏi đáp (QA) nơi bộ nhớ dài hạn hoạt động hiệu quả như một cơ sở kiến thức (năng động), và đầu ra là một đáp ứng văn bản.\\nMột framework mã hóa-giải mã là một framework dựa trên các mạng neuron nhằm mục đích lập bản đồ đầu vào cấu trúc cao tới đầu ra có cấu trúc cao. Nó đã được đề xuất gần đây trong bối cảnh của máy dịch , trong đó đầu vào và đầu ra được viết thành câu bằng hai ngôn ngữ tự nhiên. Trong đó, một mạng nơ ron tái phát (RNN) hoặc mạng neuron tích chập (CNN) được sử dụng như một bộ mã hóa để tóm tắt một câu nguồn và tóm tắt này được giải mã bằng cách sử dụng một mô hình ngôn ngữ mạng neuron tái phát có điều kiện để tạo ra bản dịch. Tất cả các hệ thống này có các khối xây dựng tương tự: cổng RNN và CNN, và các cơ chế tập trung được huấn luyện.\\n'}, {'header': 'Xử lý ngôn ngữ tự nhiên (Nature Language Processing)', 'content': 'Hiện nay các mô hình transformer base đã vượt xa các loại mô hình sử dụng RNN. Hầu như trong tất cả các tác vụ Transformer base model đều vượt trội hơn các RNN model (LSTM or GRU base). Với Hugging face Hugging Face Hub chúng ta có thể dễ dàng fine turn model🤗.\\nMột trong những nguyên tắc cơ bản của học sâu là để thoát khỏi kỹ thuật đặc tính thủ công và sử dụng các đặc tính thô. Nguyên tắc này được khám phá thành công đầu tiên trong kiến trúc của tự mã hóa sâu trên ảnh phổ \"thô\" hoặc các đặc điểm dãi lọc tuyến tính, hiển thị sự vượt trội của nó hơn các tính năng Mel-Cepstral mà có chứa một vài giai đoạn chuyển đổi cố định từ ảnh phổ. Các tính năng thực sự \"thô\" của tiếng nói, dạng sóng , gần đây đã được chỉ ra để tạo ra các kết quả nhận dạng giọng nói tuyệt vời ở quy mô lớn.\\nKể từ khi ra mắt thành công ban đầu của DNN cho nhận dạng tiếng nói khoảng 2009-2011, tiến độ (và hướng đi trong tương lai) có thể được tóm tắt vào 8 lĩnh vực chính:\\nMở rộng quy mô lên/ra và tăng tốc quá trình đào tạo và giải mã DNN;\\nHuấn luyện suy luận có trình tự cho các DNN;\\nXử lý đặc điểm bởi các mô hình sâu với sự hiểu biết vững chắc các cơ chế tiềm ẩn;\\nThích nghi của các DNN và các mô hình sâu có liên quan;\\nHọc đa tác vụ và học có chuyển giao bởi các DNN và các mô hình sâu liên quan; Các mạng neuron tích chập và làm thế nào để thiết kế chúng để khai thác tốt nhất kiến thức miền của giọng nói;\\nMạng neuron tái phát và các biến thể giàu LSTM;\\nCác loại mô hình sâu bao gồm các mô hình dựa trên tensor và các mô hình tích hợp sâu thể sinh/suy xét.\\nTrường hợp nhận dạng tiếng nói tự động quy mô lớn lần đầu tiên và thuyết phục nhất thành công của học sâu trong lịch sử gần đây, chấp nhận bở cả công nghiệp và hàn lâm trong tất cả các lĩnh vực. Từ năm 2010 đến năm 2014, hai hội nghị lớn về xử lý tín hiệu và nhận dạng giọng nói, IEEE-ICASSP và Interspeech, đã thấy một sự gia tăng lớn các báo cáo được chấp nhận trong các báo cáo hội nghị thường niên tương ứng về chủ đề học sâu trong nhận dạng giọng nói. Quan trọng hơn, tất cả các hệ thống nhận dạng giọng nói thương mại chính (ví dụ: Microsoft Cortana, Xbox, Skype Translator, Google Now, Apple Siri, Baidu và iFlyTek tìm kiếm bằng giọng nói và một loạt các sản phẩm của Nuance speech, vv) được dựa trên phương pháp học sâu. Xem thêm các cuộc phỏng vấn trên phương tiện truyền thông với CTO của Nuance Communications.\\nThành công lây lan rộng trong nhận dạng tiếng nói đã đạt được vào năm 2011 được kế tiếp liền sau đó là nhận dạng hình ảnh ở quy mô lớn.\\n'}, {'header': 'Nhận dạng hình ảnh', 'content': 'Một tập đánh giá phổ biến cho phân loại hình ảnh là tập hợp dữ liệu cơ sở dữ liệu MNIST . MNIST bao gồm các chữ số viết tay và bao gồm 60000 ví dụ huấn luyện và 10000 ví dụ kiểm tra. Như TIMIT, kích thước nhỏ của nó cho phép nhiều cấu hình được kiểm tra. Một danh sách đầy đủ các kết quả trên tập này có thể được tìm thấy trong. Kết quả tốt nhất hiện nay trên MNIST là tỷ lệ lỗi 0,23%, đạt được bởi Ciresan và các cộng sự vào năm 2012.\\nTác động thực sự của học sâu trong nhận dạng hình ảnh hoặc đối tượng, một chi chính của thị giác máy tính, đã cảm thấy được vào mùa thu năm 2012 sau khi đội của Geoff Hinton và sinh viên của ông thắng trong cuộc thi quy mô lớn ImageNet bởi một biên độ đáng kể bằng phương pháp máy học nông tiên tiến nhất. Công nghệ này dựa trên các mạng tích chập sâu 20 tuổi, nhưng với quy mô lớn hơn nhiều trên một nhiệm vụ lớn hơn nhiều, vì nó đã học được rằng học sâu làm việc tốt đối nhận dạng giọng nói quy mô lớn. Trong năm 2013 và 2014, tỷ lệ lỗi trong tác vụ của ImageNet bằng cách sử dụng học sâu tiếp tục giảm xuống nhanh chóng, theo một xu hướng tương tự trong nhận dạng giọng nói quy mô lớn.\\nKhi tham vọng này di chuyển từ nhận dạng giọng nói tự động sang các bản dịch giọng nói tự động và hiểu được, phân loại hình ảnh gần đây đã được mở rộng với nhiệm vụ khó khăn hơn đó là tạo phụ đề cho hình ảnh tự động, trong đó có học sâu là công nghệ cơ bản thiết yếu.\\nMột ứng dụng ví dụ là một máy tính xe hơi cho biết được đào tạo bằng học sâu, có thể cho phép xe diễn giải các hình ảnh 360° từ camera. Một ví dụ khác là công nghệ được gọi là Facial Dysmorphology Novel Analysis (FDNA) -(Phân tích các dị tật của khuôn mặt) sử dụng để phân tích các trường hợp dị dạng của con người kết nối với cơ sở dữ liệu lớn của các hội chứng di truyền.\\n'}, {'header': 'Xử lý ngôn ngữ tự nhiên', 'content': 'Mạng neuron đã được sử dụng cho việc thực hiện các mô hình ngôn ngữ kể từ đầu những năm 2000. Các kỹ thuật quan trọng trong lĩnh vực này là lấy mẫu âm và nhúng từ (word embedding). Nhúng chữ, chẳng hạn như word2vec, có thể được dùng như một lớp đại diện trong một kiến trúc học sâu, điều này sẽ biến đổi một từ đơn thành một đại diện vị trí của từ đó liên quan đến các từ khác trong bộ dữ liệu; vị trí được đại diện như là một điểm trong một không gian vector . Sử dụng một từ nhúng như là một lớp đầu vào với một mạng lưới thần kinh đệ quy (RNN-recursive neuron network) cho phép đào tạo mạng để phân tích cú pháp câu và cụm từ bằng cách sử dụng một ngữ pháp vector tổng hợp có hiệu quả. Một ngữ pháp vector tổng hợp có thể được coi là ngữ pháp không phụ thuộc ngữ cảnh xác suất (PCFG-probabilistic context free grammar) được thực hiện bởi một mạng thần kinh đệ quy. Tự động-mã hóa đệ qui được xây dựng trên đỉnh từ nhúng đã được đào tạo để đánh giá câu tương tự và phát hiện các chú giải dài dòng. Các kiến trúc thần kinh sâu đã đạt được những kết quả tiên tiến nhất trong nhiều tác vụ xử lý ngôn ngữ tự nhiên như phân tích thống kê , phân tích tình cảm, tra cứu thông tin, dịch máy, liên kết thực thể ngữ cảnh, và.v.v.\\n'}, {'header': 'Khám phá dược phẩm và độc chất học', 'content': 'Ngành công nghiệp dược phẩm phải đối mặt với vấn đề mà một tỷ lệ lớn các loại thuốc tiềm năng thất bại khi tiếp cận với thị trường. Những thất bại của các hợp chất hóa học này gây ra bởi không đủ hiệu quả trên mục tiêu phân tử sinh học (có hiệu lực với mục tiêu), có các tương tác không bị phát hiện và không mong muốn với các phân tử sinh học khác (chệch mục tiêu tác động), hoặc các hiệu ứng độc dược ngoài dự tính. Trong năm 2012, một nhóm dẫn đầu bởi George Dahl đã chiến thắng \"Merck Molecular Activity Challenge\" sử dụng các mạng neuron sâu đa tác vụ để dự đoán mục tiêu phân tử sinh học của một hợp chất. Trong năm 2014, nhóm của Sepp Hochreiter sử dụng học sâu để phát hiện ra mục tiêu lạ và các ảnh hưởng độc dược của các môi trường hóa chất trong các chất dinh dưỡng, sản phẩm gia dụng và thuốc men và đã chiến thắng \"Tox21 Data Challenge\" của NIH , FDA và NCATS . Những thành công ấn tượng chỉ ra rằng học sâu có thể vượt trội so với các phương pháp kiểm tra ảo khác. Các nhà nghiên cứu đến từ Google và Stanford đã mở rộng học sâu để khám phá dược phẩm bằng cách kết hợp dữ liệu từ nhiều nguồn khác nhau. Năm 2015, Atomwise giới thiệu AtomNet, mạng neuron học sâu đầu tiên dành cho thiết kế dược phẩm dựa trên cấu trúc hợp lý. Sau đó, AtomNet đã được sử dụng để dự đoán các phân tử sinh học được chọn mới lạ đối với nhiều mục tiêu bệnh tật, đặc biệt là phương pháp điều trị bệnh do virus Ebola và bệnh đa xơ cứng.\\n'}, {'header': 'Quản lý quan hệ khách hàng (CRM)', 'content': 'Thành công gần đây đã được báo cáo với ứng dụng của học tăng cường sâu trong các thiết lập tiếp thị trực tiếp, thể hiện sự phù hợp của phương pháp này dành cho tự động hóa CRM . Một mạng nơ ron được sử dụng để ước tính giá trị của các hành động có thể trực tiếp tiếp thị trên không gian trạng thái khách hàng, được định nghĩa trong điều khoản của biến RFM . Hàm giá trị ước tính được chỉ ra để có một giải thích tự nhiên như là giá trị khách hàng suốt đời .\\n'}, {'header': 'Các hệ thống khuyến cáo (gợi ý)', 'content': 'Các hệ thống khuyến cáo đã sử dụng học sâu để trích xuất các đặc điểm sâu có ý nghĩa cho mô hình yếu tố tiềm ẩn đối với khuyến cáo dựa trên nội dung cho âm nhạc. Gần đây, một cách tiếp cận tổng quát hơn cho việc học tập sở thích người dùng từ nhiều miền bằng cách sử dụng học sâu đa góc nhìn đã được đưa ra. Mô hình này sử dụng một cộng tác lai và tiếp cận dựa trên nội dung và tăng cường các khuyến nghị trong nhiều nhiệm vụ.\\n'}, {'header': 'Tin sinh học', 'content': 'Gần đây, một cách tiếp cận học sâu dựa trên một mạng neuron nhân tạo tự mã hóa đã được sử dụng trong tin sinh học , để dự đoán các mối quan hệ chức năng gen và các chú thích Bản thể gen .\\n'}, {'header': 'Lý thuyết về bộ não con người', 'content': 'Tính toán học sâu có liên hệ chặt chẽ đến học thuyết về sự phát triển của não bộ (cụ thể, phát triển neocortical) do các nhà khoa học thần kinh nhận thức đề xuất trong đầu thập niên 1990. Một bản tóm tắt dễ tiếp cận của ý tưởng này là tác phẩm của Elman và các cộng sự vào năm 1996 \"Xem xét lại Tính bẩm sinh\" (Xem thêm: Shrager và Johnson; Quartz và Sejnowski). Những lý thuyết phát triển này cũng được thuyết minh cụ thể trong các mô hình tính toán, chúng là những kỹ thuật tiền nhiệm của các mô hình học sâu được thúc đẩy bởi tính toán (bằng máy tính) đơn thuần. Những mô hình phát triển này chia sẻ thuộc tính thú vị mà nhiều động lực học (learning dynamics) khác nhau được đề xuất trong nghiên cứu não bộ (Ví dụ, một làn sóng của yếu tố tăng trưởng thần kinh ) để hỗ trợ việc tự tổ chức của các loại mạng nơ ron có liên quan với nhau được sử dụng trong các mô hình học sâu thuần tính toán sau đó; và các mạng neuron tính toán như vậy có vẻ tương tự như quan điểm của ngành nghiên cứu vỏ não mới như một hệ thống phân cấp của bộ lọc trong đó mỗi lớp chụp một số thông tin trong môi trường hoạt động, và sau đó đi qua phần còn lại, cũng như tín hiệu cơ bản được sửa đổi, tới các lớp khác cao hơn trong hệ thống phân cấp. Quá trình này mang lại một chồng tự tổ chức các cảm biến, cũng như điều chỉnh để hoạt động môi trường của họ. Như được mô tả trên tờ New York Times vào năm 1995: \"...bộ não của những trẻ sơ sinh dường như tự tổ chức riêng chính nó dưới ảnh hưởng của các sóng của cái gọi là các yếu tố - dinh dưỡng... các khu vực khác nhau của não trở nên kết nối tuần tự, với một lớp mô trưởng thành trước các mô khác và cho đến khi toàn bộ não là trưởng thành.\"\\nTầm quan trọng của học sâu đối với sự tiến hóa và phát triển của nhận thức của con người đã không thoát khỏi sự chú ý của các nhà nghiên cứu. Một khía cạnh của phát triển con người là phân biệt chúng ta với những người hàng xóm trong họ linh trưởng gần nhất của mình có thể thay đổi trong thời gian phát triển. Trong số các loài linh trưởng , bộ não con người vẫn còn tương đối mềm dẻo cho đến cuối thời kỳ sau khi sinh, trong khi bộ não của họ hàng gần gũi nhất của chúng ta hoàn toàn cố định hơn ngay sau khi sinh. Vì vậy, con người có khả năng truy cập lớn hơn vào những kinh nghiệm phức tạp đang diễn ra trên thế giới trong giai đoạn hình thành nhất của sự phát triển não bộ. Điều này có thể cho phép chúng ta \"điều chỉnh\" để thay đổi nhanh chóng môi trường mà các động vật khác, nhiều bị hạn chế bởi cơ cấu tiến hóa của bộ não của chúng, không thể để thực hiện được. Đến mức mà những thay đổi này được phản ánh trong các thay đổi thời gian tương tự trong sóng được giả thuyết của sự phát triển vỏ não, chúng cũng có thể dẫn đến những thay đổi trong việc khai thác thông tin từ môi trường kích thích trong thời gian đầu tự tổ chức của bộ não. Tất nhiên, cùng với tính linh hoạt này đến một giai đoạn kéo dài chưa thành thục, trong đó chúng ta phụ thuộc vào người chăm sóc và cộng đồng của mình để hỗ trợ và đào tạo. Lý thuyết của học sâu do đó thấy sự cùng tiến hóa đồng thời của văn hóa và nhận thức như là một điều kiện cơ bản của sự tiến hóa của con người.\\n'}, {'header': 'Hoạt động thương mại', 'content': 'Hầu hết các công ty công nghệ lớn nhất trên thế giới đang đầu tư rất nhiều nguồn lực vào nghiên cứu và phát triển để tiếp tục cải tiến công nghệ lõi cũng như tạo ra các sản phẩm ứng dụng sử dụng kỹ thuật học sâu. Điển hình là nhóm nghiên cứu về trí tuệ nhân tạo của Facebook đã tạo ra phần mềm DeepFace có khả năng nhận dạng khuôn mặt tốt như con người với độ chính xác khoảng 97,35%. Công trình này (công bố năm 2014) sử dụng 4 triệu ảnh khuôn mặt của hơn 4000 người để huấn luyện cho mạng nơron nhiều lớp và mô hình thu được đã vượt qua các kỹ thuật được nghiên cứu đề xuất trước đó. [ 4 ]\\nHọc sâu thường được trình bày như là một bước hướng tới AI mạnh và do đó nhiều tổ chức đã trở nên quan tâm đến việc sử dụng nó cho các ứng dụng cụ thể. Vào tháng 12 năm 2013, Facebook đã tuyển Yann Le Cun đứng đầu phòng thí nghiệm trí tuệ nhân tạo (AI) mới của họ hoạt động ở California, London và New York. Phòng thí nghiệm AI này sẽ phát triển những kỹ thuật học sâu để giúp Facebook thực hiện các nhiệm vụ, chẳng hạn như tính năng gắn thẻ tự động hình ảnh tải lên với tên của những người có mặt trong đó. Vào cuối năm 2014, Facebook cũng tuyển Vladimir Vapnik , nhà phát triển chính của lý thuyết Vapnik-Chervonenkis về học thống kê, và đồng phát minh ra phương pháp máy vector hỗ trợ .\\nVào tháng 3 năm 2013, Google tuyển Geoffrey Hinton và hai sinh viên tốt nghiệp của ông, Alex Krizhevsky và Ilya Sutskever. Công việc của họ là tập trung vào vừa cải tiến các sản phẩm học máy hiện có của Google và vừa trợ giúp đối phó với lượng dữ liệu ngày càng tăng nhanh mà Google có được. Google cũng mua lại công ty của Hinton, DNNresearch.\\nNăm 2014, Google cũng đã mua DeepMind Technologies , một công ty khởi nghiệp của Anh đã phát triển một hệ thống có khả năng học tập làm thế nào để chơi trò chơi điện tử Atari chỉ sử dụng các điểm ảnh thô là dữ liệu đầu vào. Trong năm 2015, họ đã chứng minh hệ thống AlphaGo đã đạt được một trong những \"thách thức lớn\" trong thời gian dài của AI bằng cách học trò chơi Cờ vây đủ tốt để đánh bại một người chơi Cờ vây chuyên nghiệp.\\nBaidu đã thuê Andrew Ng để lãnh đạo phòng thí nghiệm nghiên cứu của mình đặt trụ sở tại thung lũng Silicon mới tập trung vào học sâu.\\n'}, {'header': 'Phê bình và đánh giá', 'content': 'neural Designer — Một ứng dụng GUI cho mạng neuron sâu cung cấp song song hóa với CPU.\\n'}]",
         "Học sâu ( tiếng Anh : deep learning , còn gọi là học cấu trúc sâu ) là một phần trong một nhánh rộng hơn các phương pháp học máy dựa trên mạng thần kinh nhân tạo kết hợp với việc học biểu diễn đặc trưng ( representation learning ). Việc học này có thể có giám sát , nửa giám sát hoặc không giám sát . [ 1 ]"
        ],
        [
         "3",
         "Xử lý ngôn ngữ tự nhiên",
         "[{'header': 'Các bước xử lý', 'content': 'Phân tích hình thái - Trong bước này từng từ sẽ được phân tích và các ký tự không phải chữ (như các dấu câu) sẽ được tách ra khỏi các từ. Trong tiếng Anh và nhiều ngôn ngữ khác, các từ được phân tách với nhau bằng dấu cách. Tuy nhiên trong tiếng Việt , dấu cách được dùng để phân tách các tiếng (âm tiết) chứ không phải từ. Cùng với các ngôn ngữ như tiếng Trung , tiếng Hàn , tiếng Nhật , phân tách từ trong tiếng Việt là một công việc không hề đơn giản.\\nPhân tích cú pháp - Dãy các từ sẽ được biến đổi thành các cấu trúc thể hiện sự liên kết giữa các từ này. Sẽ có những dãy từ bị loại do vi phạm các luật văn phạm.\\nPhân tích ngữ nghĩa - Thêm ngữ nghĩa vào các cấu trúc được tạo ra bởi bộ phân tích cú pháp .\\nTích hợp văn bản - Ngữ nghĩa của một câu riêng biệt có thể phụ thuộc vào những câu đứng trước, đồng thời nó cũng có thể ảnh hưởng đến các câu phía sau.\\nPhân tích thực nghĩa - Cấu trúc thể hiện điều được phát ngôn sẽ được thông dịch lại để xác định nó thật sự có nghĩa là gì.\\nTuy nhiên, ranh giới giữa 5 bước xử lý này cũng rất mong manh. Chúng có thể được tiến hành từng bước một, hoặc tiến hành cùng lúc - tùy thuộc vào giải thuật và ngữ cảnh cụ thể.\\n'}, {'header': 'Các bài toán và ứng dụng', 'content': 'Nhận dạng chữ viết : Có hai kiểu nhận dạng, thứ nhất là nhận dạng chữ in, ví dụ nhận dạng chữ trên sách giáo khoa rồi chuyển nó thành dạng văn bản điện tử như dưới định dạng doc của Microsoft Word chẳng hạn. Phức tạp hơn là nhận dạng chữ viết tay , có khó khăn bởi vì chữ viết tay không có khuôn dạng rõ ràng và thay đổi từ người này sang người khác. Với chương trình nhận dạng chữ viết in có thể chuyển hàng ngàn đầu sách trong thư viện thành văn bản điện tử trong thời gian ngắn. Nhận dạng chữ viết của con người có ứng dụng trong khoa học hình sự và bảo mật thông tin (nhận dạng chữ ký điện tử).\\nNhận dạng tiếng nói : Nhận dạng tiếng nói rồi chuyển chúng thành văn bản tương ứng. Giúp thao tác của con người trên các thiết bị nhanh hơn và đơn giản hơn, chẳng hạn thay vì gõ một tài liệu nào đó bạn đọc nó lên và trình soạn thảo sẽ tự ghi nó ra. Đây cũng là bước đầu tiên cần phải thực hiện trong ước mơ thực hiện giao tiếp giữa con người với robot. Nhận dạng tiếng nói có khả năng trợ giúp người khiếm thị rất nhiều.\\nTổng hợp tiếng nói : Từ một văn bản tự động tổng hợp thành tiếng nói. Thay vì phải tự đọc một cuốn sách hay nội dung một trang web , nó tự động đọc cho chúng ta. Giống như nhận dạng tiếng nói, tổng hợp tiếng nói là sự trợ giúp tốt cho người khiếm thị , nhưng ngược lại nó là bước cuối cùng trong giao tiếp giữa robot với người.\\nDịch tự động ( machine translate ): Như tên gọi đây là chương trình dịch tự động từ ngôn ngữ này sang ngôn ngữ khác. Một phần mềm điển hình về tiếng Việt của chương trình này là Evtrans của Softex, dịch tự động từ tiếng Anh sang tiếng Việt và ngược lại, phần mềm từng được trang web vdict.com mua bản quyền, đây cũng là trang đầu tiên đưa ứng dụng này lên mạng. Tháng 10 năm 2008 có hai công ty tham gia vào lĩnh vực này cho ngôn ngữ tiếng Việt là công ty Lạc Việt (công ty phát hành từ điển Lạc Việt) và Google , một thời gian sau đó Xalo_vn cũng đưa ra dịch vụ tương tự.\\nTìm kiếm thông tin ( information retrieval ): Đặt câu hỏi và chương trình tự tìm ra nội dung phù hợp nhất. Thông tin ngày càng đầy lên theo cấp số nhân, đặc biệt với sự trợ giúp của internet việc tiếp cận thông tin trở lên dễ dàng hơn bao giờ hết. Việc khó khăn lúc này là tìm đúng nhất thông tin mình cần giữa bề bộn tri thức và đặc biệt thông tin đó phải đáng tin cậy. Các máy tìm kiếm dựa trên giao diện web như Google hay Yahoo hiện nay chỉ phân tích nội dung rất đơn giản dựa trên tần suất của từ khoá và thứ hạng của trang và một số tiêu chí đánh giá khác để đưa ra kết luận, kết quả là rất nhiều tìm kiếm không nhận được câu trả lời phù hợp, thậm chí bị dẫn tới một liên kết không liên quan gì do thủ thuật đánh lừa của các trang web nhằm giới thiệu sản phẩm (có tên tiếng Anh là SEO viết tắt của từ search engine optimization ). Thực tế cho đến bây giờ chưa có máy tìm kiếm nào hiểu được ngôn ngữ tự nhiên của con người trừ trang www.ask.com được đánh giá là \"hiểu\" được những câu hỏi có cấu trúc ở dạng đơn giản nhất. Mới đây cộng đồng mạng đang xôn xao về trang Wolfram Alpha , được hứa hẹn là có khả năng hiểu ngôn ngữ tự nhiên của con người và đưa ra câu trả lời chính xác [ 1 ] . Lĩnh vực này hứa hẹn tạo ra bước nhảy trong cách thức tiếp nhận tri thức của cả cộng đồng.\\nTóm tắt văn bản : Từ một văn bản dài tóm tắt thành một văn bản ngắn hơn theo mong muốn nhưng vẫn chứa những nội dung thiết yếu nhất.\\nKhai phá dữ liệu ( data mining ) và phát hiện tri thức : Từ rất nhiều tài liệu khác nhau phát hiện ra tri thức mới. Thực tế để làm được điều này rất khó, nó gần như là mô phỏng quá trình học tập , khám phá khoa học của con người, đây là lĩnh vực đang trong giai đoạn đầu phát triển. Ở mức độ đơn giản khi kết hợp với máy tìm kiếm nó cho phép đặt câu hỏi để từ đó công cụ tự tìm ra câu trả lời dựa trên các thông tin trên web mặc cho việc trước đó có câu trả lời lưu trên web hay không (giống như trang Yahoo! hỏi và đáp, nơi chuyên đặt các câu hỏi để người khác trả lời), nói một cách nôm na là nó đã biết xử lý dữ liệu để trả lời câu hỏi của người sử dụng, thay vì máy móc đáp trả những gì chỉ có sẵn trong bộ nhớ.\\nSửa lỗi chính tả : Là quá trình phát hiện và sửa các lỗi chính tả trong một đoạn văn bản. Phần mềm sửa lỗi chính tả thường được tích hợp trong các ứng dụng văn phòng như Microsoft Word hay Google Docs để hỗ trợ người dùng trong việc soạn thảo văn bản. Sửa lỗi chính tả có thể được áp dụng cho nhiều ngôn ngữ khác nhau, bao gồm tiếng Việt.\\n'}, {'header': 'Các bài toán trong xử lý tiếng Việt', 'content': 'Phân tách câu\\nPhân tách từ\\nTự động thêm dấu : Chữ viết tiếng Việt là chữ viết có dấu thanh. Trong các văn bản chính thống như sách, báo chí, văn bản hành chính, các dấu thanh được viết chính xác. Tuy nhiên trong cách tình huống không chính thống như chat, gõ tìm kiếm, người dùng thông thường không gõ các dấu thanh, dẫn tới khó khăn nhất định cho máy tính trong việc hiểu ý nghĩa của văn bản.\\nCác bộ dữ liệu trong xử lý tiếng Việt\\nTreebank tiếng Việt: VietTreebank và NIIVTB.\\nHỏi đáp - đọc hiểu tự động: UIT-ViQuAD và UIT-ViNewsQA.\\nPhân tích cảm xúc: updating ...\\n'}]",
         "Xử lý ngôn ngữ tự nhiên ( natural language processing - NLP) là một nhánh của trí tuệ nhân tạo tập trung vào các ứng dụng trên ngôn ngữ của con người. Trong trí tuệ nhân tạo thì xử lý ngôn ngữ tự nhiên là một trong những phần khó nhất vì nó liên quan đến việc phải hiểu ý nghĩa ngôn ngữ-công cụ hoàn hảo nhất của tư duy và giao tiếp ."
        ],
        [
         "4",
         "Thị giác máy tính",
         "[{'header': 'Thị giác máy tính', 'content': 'Thị giác máy tính là một môn học khoa học liên quan đến lý thuyết đằng sau các hệ thống nhân tạo có trích xuất các thông tin từ các hình ảnh. Dữ liệu hình ảnh có thể nhiều dạng, chẳng hạn như chuỗi video, các cảnh từ đa camera, hay dữ liệu đa chiều từ máy quét y học. Thị giác máy tính còn là  một môn học kỹ thuật, trong đó tìm kiếm việc áp dụng các mô hình và các lý thuyết cho việc xây dựng các hệ thống thị giác máy tính.\\nCác lĩnh vực con của thị giác máy tính bao gồm tái cấu trúc cảnh, dò tìm sự kiện, theo dõi video , nhận diện bố cục đối tượng , học, chỉ mục, đánh giá chuyển động và phục hồi ảnh .\\n'}, {'header': 'Các lĩnh vực liên quan', 'content': 'Các lĩnh vực liên quan của trí tuệ nhân tạo giải quyết các vấn đề như lên kế hoạch tự động hay các suy tính cho các hệ thống robot để dò đường ở một môi trường nào đó. Sự hiểu biết chi tiết của các môi trường này được yêu cầu để dò đường thông qua chúng. Thông tin về môi trường có thể được cung cấp bởi một hệ thống thị giác máy tính, hoạt động như các cảm biến và cung cấp thông tin mức độ cao về môi trường và robot.\\nTrí tuệ nhân tạo và thị giác máy tính chia sẻ các chủ đề như nhận dạng mẫu và các kỹ thuật học. Kết quả là thị giác máy tính đôi khi được xem là một phần của lĩnh vực trí tuệ nhân tạo hay lĩnh vực khoa học máy tính nói chung.\\nThị giác máy tính theo một cách nào đó là sự đảo ngược của đồ họa máy tính . Trong khi đồ họa máy tính sản sinh hình ảnh từ mô hình 3D, thì thị giác máy tính lại thường sản sinh ra các mô hình 3D từ dữ liệu hình ảnh. Có một khuynh hướng kết hợp 2 môn học này, ví dụ như khám phá trong tăng cường thực tế .\\n'}]",
         "Thị giác máy tính ( tiếng Anh : computer vision ) là một lĩnh vực bao gồm các phương pháp thu nhận, xử lý ảnh kỹ thuật số , phân tích và nhận dạng các hình ảnh và, nói chung là dữ liệu đa chiều từ thế giới thực để cho ra các thông tin số hoặc biểu tượng, ví dụ trong các dạng quyết định. [ 1 ] [ 2 ] [ 3 ] [ 4 ] Việc phát triển lĩnh vực này có bối cảnh từ việc sao chép các khả năng thị giác con người bởi sự nhận diện và hiểu biết một hình ảnh mang tính điện tử. [ 5 ] Sự nhận diện hình ảnh có thể xem là việc giải quyết vấn đề của các biểu tượng thông tin từ dữ liệu hình ảnh qua cách dùng các mô hình được xây dựng với sự giúp đỡ của các ngành lý thuyết học , thống kê , vật lý và hình học . [ 6 ] Thị giác máy tính cũng được mô tả là sự tổng thể của một dải rộng các quá trình tự động và tích hợp và các thể hiện cho các nhận thức thị giác. [ 7 ] [ 8 ]"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sections</th>\n",
       "      <th>intro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trí tuệ nhân tạo</td>\n",
       "      <td>[{'header': 'Trí tuệ nhân tạo', 'content': 'Cá...</td>\n",
       "      <td>Trí tuệ nhân tạo ( TTNT ) ( tiếng Anh : Artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Học máy</td>\n",
       "      <td>[{'header': 'Học máy', 'content': 'Học máy có ...</td>\n",
       "      <td>Học máy hay máy học ( machine learning ) là mộ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Học sâu</td>\n",
       "      <td>[{'header': 'Học sâu', 'content': 'Mạng thần k...</td>\n",
       "      <td>Học sâu ( tiếng Anh : deep learning , còn gọi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xử lý ngôn ngữ tự nhiên</td>\n",
       "      <td>[{'header': 'Các bước xử lý', 'content': 'Phân...</td>\n",
       "      <td>Xử lý ngôn ngữ tự nhiên ( natural language pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thị giác máy tính</td>\n",
       "      <td>[{'header': 'Thị giác máy tính', 'content': 'T...</td>\n",
       "      <td>Thị giác máy tính ( tiếng Anh : computer visio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                           sections  \\\n",
       "0         Trí tuệ nhân tạo  [{'header': 'Trí tuệ nhân tạo', 'content': 'Cá...   \n",
       "1                  Học máy  [{'header': 'Học máy', 'content': 'Học máy có ...   \n",
       "2                  Học sâu  [{'header': 'Học sâu', 'content': 'Mạng thần k...   \n",
       "3  Xử lý ngôn ngữ tự nhiên  [{'header': 'Các bước xử lý', 'content': 'Phân...   \n",
       "4        Thị giác máy tính  [{'header': 'Thị giác máy tính', 'content': 'T...   \n",
       "\n",
       "                                               intro  \n",
       "0  Trí tuệ nhân tạo ( TTNT ) ( tiếng Anh : Artifi...  \n",
       "1  Học máy hay máy học ( machine learning ) là mộ...  \n",
       "2  Học sâu ( tiếng Anh : deep learning , còn gọi ...  \n",
       "3  Xử lý ngôn ngữ tự nhiên ( natural language pro...  \n",
       "4  Thị giác máy tính ( tiếng Anh : computer visio...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_json(wiki_data_dir / \"wiki_demo.json\")\n",
    "\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68c58fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data = []\n",
    "wiki_df.columns = [\"Title\", \"Sections\", \"Intro\"]\n",
    "\n",
    "for _, row in wiki_df.iterrows():\n",
    "    title = row[\"Title\"]\n",
    "    intro = row[\"Intro\"]\n",
    "    sections = row[\"Sections\"]\n",
    "    \n",
    "    doc = f\"Title: {title}\\nIntro: {intro}\\n\"\n",
    "\n",
    "    for section in sections:\n",
    "        sec_header = section[\"header\"]\n",
    "        sec_content = section[\"content\"]\n",
    "        doc += f\"Section Header: {sec_header}\\nSection Content: {sec_content}\\n\"\n",
    "\n",
    "    wiki_data.append(doc.strip())\n",
    "\n",
    "len(wiki_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49f1c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title: Trí tuệ nhân tạo\\nIntro: Trí tuệ nhân tạo ( TTNT ) ( tiếng Anh : Artificial intelligence , viết tắt: AI ) là khả năng của các hệ thống máy tính thực hiện các nhiệm vụ liên quan đến trí thông minh của con người , như học tập , suy luận , giải quyết vấn đề , nhận thức và đưa ra quyết định . Đây là một lĩnh vực nghiên cứu thuộc khoa học máy tính , tập trung phát triển và nghiên cứu các phương pháp cùng phần mềm giúp máy móc có khả năng nhận thức môi trường xung quanh , sử dụng học tập và trí tuệ để thực hiện hành động nhằm tối đa hóa khả năng đạt được các mục tiêu đã định. \\nSection Header: Trí tuệ nhân tạo\\nSection Content: Các ứng dụng nổi bật của AI bao gồm công cụ tìm kiếm web tiên tiến (ví dụ: Google Tìm kiếm ); hệ thống đề xuất (được sử dụng bởi YouTube , Amazon và Netflix ); trợ lý ảo (ví dụ: Trợ lý Google , Siri và Alexa ); xe tự lái (ví dụ: Waymo ); công cụ sáng tạo và nội dung tạo sinh (ví dụ: mô hình ngôn ngữ và nghệ thuật AI ); cùng khả năng chơi và phân tích vượt trội hơn con người trong các trò chơi chiến lược (ví dụ: cờ vua và cờ vây ). Tuy nhiên, nhiều ứng dụng AI không được nhận diện là AI: \"Rất nhiều công nghệ AI đỉnh cao đã được tích hợp vào các ứng dụng thông thường, thường không còn được gọi là AI vì một khi thứ gì đó trở nên đủ hữu ích và phổ biến, nó không còn được dán nhãn AI nữa.\"  \\nNhiều phân ngành trong nghiên cứu trí tuệ nhân tạo tập trung vào các mục tiêu cụ thể và sử dụng những công cụ đặc thù. Các mục tiêu truyền thống của nghiên cứu AI bao gồm học tập, lập luận , biểu diễn tri thức , lập kế hoạch , xử lý ngôn ngữ tự nhiên , nhận thức và hỗ trợ robot .  Để đạt được những mục tiêu đó, các nhà nghiên cứu AI đã ứng dụng và tích hợp đa dạng kỹ thuật, như tìm kiếm và tối ưu hóa toán học , logic hình thức , mạng nơ-ron nhân tạo , cùng các phương pháp dựa trên thống kê , nghiên cứu hoạt động và kinh tế học .  Ngoài ra, AI còn kế thừa kiến thức từ tâm lý học , ngôn ngữ học , triết học , khoa học thần kinh và nhiều lĩnh vực khác.  Một số công ty như OpenAI , Google DeepMind và Meta , đang đặt mục tiêu phát triển trí tuệ nhân tạo tổng quát (AGI)—một dạng AI có khả năng thực hiện hầu hết mọi nhiệm vụ nhận thức ở mức độ ngang bằng hoặc vượt trội so với con người. \\nTrí tuệ nhân tạo ban đầu được thành lập như một ngành học thuật vào năm 1956,  và lĩnh vực này đã trải qua nhiều chu kỳ lạc quan trong suốt lịch sử ,   xen kẽ với nó là những giai đoạn thất vọng và mất nguồn tài trợ, được gọi là mùa đông AI .   Nguồn tài trợ và sự quan tâm dần tăng mạnh sau năm 2012 khi các bộ xử lý đồ họa (GPU) bắt đầu được sử dụng để tăng tốc mạng nơ-ron và kỹ năng học sâu dần vượt trội hơn so với các kỹ thuật AI trước đó.  Sự tăng trưởng này tiếp tục tăng tốc sau năm 2017 nhờ kiến trúc transformer .  Trong những năm 2020, sự xuất hiện của trí tuệ nhân tạo tạo sinh tiên tiến đã trở nên nổi tiếng, đánh dấu giai đoạn tiến bộ nhanh chóng của lĩnh vực này với tên gọi là cơn sốt AI . Trí tuệ nhân tạo tạo sinh với khả năng tạo ra cũng như chỉnh sửa nội dung đã làm lộ rõ nhiều hậu quả ngoài ý muốn ở hiện tại, đồng thời dấy lên lo ngại đạo đức về ảnh hưởng lâu dài của AI và những rủi ro tồn vong tiềm tàng , từ đó thúc đẩy các cuộc thảo luận về chính sách quản lý nhằm đảm bảo tính an toàn và lợi ích của công nghệ này .\\n\\nSection Header: Mục đích\\nSection Content: Vấn đề tổng quát của việc mô phỏng (hay tạo ra) khả năng trí tuệ đã được chia thành các bài toán con. Những bài toán này bao gồm các đặc tính hoặc khả năng cụ thể mà các nhà nghiên cứu kỳ vọng về một hệ thống thông minh cần trình diện. Các đặc tính được mô tả dưới đây đã nhận được nhiều sự quan tâm nhất và bao quát được phạm vi nghiên cứu AI. \\n\\nSection Header: Suy luận và giải quyết vấn đề\\nSection Content: Các nhà nghiên cứu từ thời kỳ đầu đã phát triển những thuật toán mô phỏng quá trình suy luận từng bước mà con người sử dụng khi giải các câu đố hay thực hiện những suy diễn logic .  Đến cuối những năm 1980 và 1990, các phương pháp xử lý thông tin không chắc chắn hoặc không đầy đủ đã được phát triển bằng cách sử dụng các khái niệm từ lý thuyết xác suất và kinh tế học . \\nNhiều thuật toán trong số này không đủ khả năng để giải quyết các bài toán suy luận quy mô lớn vì chúng gặp phải hiện tượng \"bùng nổ tổ hợp\": về cơ bản, các thuật toán sẽ trở nên chậm đi theo cấp số nhân khi bài toán được phát triển.  Ngay cả con người cũng hiếm khi sử dụng phương pháp suy diễn từng bước mà những nghiên cứu AI thời kỳ đầu có thể mô phỏng. Chúng ta giải quyết phần lớn vấn đề bằng những phán đoán trực giác nhanh chóng.  Việc đạt được khả năng suy luận chính xác và hiệu quả vẫn là một bài toán chưa có lời giải.\\n\\nSection Header: Biểu diễn tri thức\\nSection Content: Biểu diễn tri thức và kỹ thuật xử lý tri thức  đóng vai trò then chốt trong việc trang bị cho các hệ thống AI khả năng trả lời câu hỏi một cách thông minh và suy luận về các hiện tượng trong thế giới thực. Những phương pháp biểu diễn tri thức mang tính hình thức này không chỉ được ứng dụng trong lập chỉ mục và truy xuất nội dung,  mà còn giữ vai trò quan trọng trong việc diễn giải bối cảnh,  hỗ trợ quyết định trong lĩnh vực y học lâm sàng,  khám phá tri thức từ cơ sở dữ liệu lớn, (tức là khai thác những suy luận có ý nghĩa và khả thi về mặt hành động),  cùng nhiều lĩnh vực chuyên sâu khác. \\nCơ sở tri thức là tập hợp tri thức được cấu trúc theo cách mà các hệ thống máy tính có thể hiểu và vận dụng. Một bản thể học trong ngữ cảnh này là hệ thống các đối tượng, khái niệm, thuộc tính và mối quan hệ được xác định trong phạm vi một lĩnh vực tri thức cụ thể.  Để trở nên hữu ích, cơ sở tri thức cần có khả năng biểu diễn một cách rõ ràng và nhất quán các thực thể như đối tượng, thuộc tính, phân loại và mối quan hệ giữa các đối tượng;  đồng thời bao hàm cả các tình huống, sự kiện, trạng thái và yếu tố thời gian;  các mối quan hệ nhân quả ;  tri thức bậc hai (tức là kiến thức về tri thức, những gì ta biết về hiểu biết của người khác);  và lý luận mặc định (tức những giả định được con người chấp nhận là đúng cho đến khi có bằng chứng bác bỏ, và vẫn được xem là đúng trong nhiều tình huống thay đổi);  Ngoài ra, cơ sở tri thức còn phải bao phủ được nhiều chiều cạnh khác nhau của tri thức, đáp ứng yêu cầu của các lĩnh vực chuyên sâu và ngữ cảnh ứng dụng đa dạng.\\nMột trong những thách thức lớn nhất trong biểu diễn tri thức nằm ở độ rộng bao phủ của kiến thức thông thường (tập hợp khổng lồ các tri thức nguyên tử mà một người bình thường nắm giữ trong đời sống hằng ngày);  Không chỉ đồ sộ về số lượng, phần lớn loại tri thức này còn tồn tại dưới dạng phi biểu tượng (tức không được mã hóa rõ ràng thành các \"sự kiện\" hay \"mệnh đề\" mà con người có thể dễ dàng diễn đạt bằng ngôn ngữ tự nhiên).  Bên cạnh đó, quá trình thu thập và chuẩn hóa tri thức phục vụ cho các ứng dụng AI cũng đặt ra nhiều thách thức về cả quy mô, độ chính xác và tính phù hợp với ngữ cảnh ứng dụng cụ thể. \\n\\nSection Header: Lập kế hoạch và ra quyết định\\nSection Content: \"Tác nhân\" được hiểu là bất kỳ thực thể nào có khả năng nhận thức và thực hiện hành động trong thế giới. Một tác nhân lý trí là tác nhân sở hữu mục tiêu hoặc sở thích nhất định, và hành động nhằm hiện thực hóa những mục tiêu hoặc thỏa mãn sở thích đó.   Trong lĩnh vực lập kế hoạch tự động , tác nhân được định hướng bởi một mục tiêu cụ thể.  Ngược lại, trong bối cảnh ra quyết định tự động , tác nhân được cho là có những sở thích – tức là một số trạng huống mà nó mong muốn tham gia, và những trạng huống khác mà nó tìm cách tránh né. Để biểu thị mức độ ưa thích đối với từng trạng huống, tác nhân gán cho mỗi trạng huống một giá trị số, gọi là tiện ích . Khi đối mặt với các hành động khả thi, tác nhân có thể tính toán tiện ích kỳ vọng của từng hành động, tức là giá trị trung bình của tiện ích các kết quả có thể xảy ra, có xét đến xác suất tương ứng của mỗi kết quả. Dựa trên phép tính này, tác nhân sẽ lựa chọn hành động có tiện ích kỳ vọng cao nhất, nhằm tối ưu hóa mức độ thỏa mãn sở thích của mình. \\nTrong kế hoạch cổ điển , tác nhân được giả định là biết một cách chính xác hệ quả của mọi hành động mà nó có thể thực hiện.  Tuy nhiên, trong phần lớn các bài toán thực tế, tác nhân thường phải đối mặt với sự bất định: nó có thể không nắm rõ tình trạng hiện tại của môi trường (nghĩa là môi trường không xác định hoặc không thể quan sát đầy đủ), và cũng không chắc chắn về kết quả của mỗi hành động khả thi (tức môi trường không mang tính quyết định). Trong bối cảnh đó, tác nhân buộc phải lựa chọn hành động dựa trên các suy luận xác suất, đồng thời liên tục đánh giá lại tình hình sau mỗi hành động để xác định mức độ hiệu quả của hành động vừa thực hiện. \\nTrong một số bài toán, sở thích của tác nhân không hoàn toàn chắc chắn, đặc biệt khi có sự tham gia của các tác nhân khác hoặc con người. Những sở thích này có thể được rút trích thông qua học tập, chẳng hạn như học tăng cường ngược , hoặc tác nhân có thể chủ động tìm kiếm thông tin nhằm cải thiện hiểu biết của mình về sở thích nội tại.  Trong bối cảnh đó, lý thuyết giá trị thông tin đóng vai trò quan trọng trong việc đánh giá lợi ích của các hành động khám phá hoặc thử nghiệm.  Tuy nhiên, không gian hành động và trạng huống có thể xảy ra trong tương lai thường có quy mô và độ phức tạp cao, đến mức không thể xử lý một cách khả thi , buộc tác nhân phải đưa ra quyết định và đánh giá hiệu quả của hành động dưới điều kiện bất định về kết quả.\\nQuá trình quyết định Markov bao gồm một mô hình chuyển trạng thái, mô tả xác suất mà một hành động cụ thể sẽ làm thay đổi trạng thái hệ thống theo một cách nhất định, cùng với một hàm phần thưởng dùng để xác định tiện ích tương ứng của mỗi trạng thái cũng như chi phí tương ứng của mỗi hành động. Một policy là một ánh xạ từ mỗi trạng thái có thể xảy ra đến một hành động mà tác nhân sẽ thực hiện trong trạng thái đó. Policy tối ưu có thể được tính toán một cách hệ thống (ví dụ, thông qua phép lặp policy ), có thể được thiết lập bằng các kỹ thuật heuristic , hoặc có thể được học từ dữ liệu tương tác với môi trường. \\nLý thuyết trò chơi nghiên cứu hành vi hợp lý của nhiều tác nhân tương tác lẫn nhau, và đóng vai trò nền tảng trong các hệ thống trí tuệ nhân tạo có nhiệm vụ ra quyết định trong môi trường có sự hiện diện của các tác nhân khác. \\n\\nSection Header: Học hỏi\\nSection Content: Học máy là lĩnh vực nghiên cứu tập trung vào việc xây dựng các chương trình có khả năng tự động cải thiện hiệu suất thực hiện một nhiệm vụ cụ thể thông qua kinh nghiệm.  Đây không phải là một ý tưởng mới xuất hiện trong thời đại hiện nay mà ngược lại, nó đã là một thành phần cốt lõi của AI ngay từ những bước đi đầu tiên của lĩnh vực này. \\nMáy học bao gồm nhiều hình thức tiếp cận khác nhau. Trong đó, học không giám sát hướng đến việc phân tích dòng dữ liệu chưa được gán nhãn nhằm nhận diện các quy luật tiềm ẩn và đưa ra suy luận mà không cần đến hướng dẫn trực tiếp.  Trái lại, học có giám sát yêu cầu dữ liệu huấn luyện phải được dán nhãn với kết quả mong đợi, qua đó mô hình học cách liên kết đầu vào với đầu ra. Phương pháp này bao gồm hai dạng tiêu biểu: phân loại , khi mục tiêu là xác định đầu vào thuộc nhóm nào; và hồi quy , khi nhiệm vụ là ước lượng một hàm số liên tục từ dữ liệu đầu vào. \\nHọc tăng cường là phương pháp trong đó tác nhân học thông qua tương tác với môi trường, được thưởng khi hành động dẫn đến phản hồi tích cực và bị phạt khi kết quả không mong muốn, từ đó dần hình thành chiến lược lựa chọn hành vi tối ưu.  Học chuyển giao đề cập đến khả năng ứng dụng tri thức đã học từ một bài toán vào bối cảnh mới, góp phần nâng cao hiệu quả học tập trong môi trường biến đổi.  Trong khi đó, học sâu là một nhánh của học máy, sử dụng mạng nơ-ron nhân tạo lấy cảm hứng từ cấu trúc sinh học, cho phép xử lý dữ liệu đầu vào theo tầng lớp và có thể tích hợp với mọi hình thức học kể trên để gia tăng năng lực biểu đạt và khái quát hóa. \\nLý thuyết học tập tính toán cung cấp khung phân tích hình thức để đánh giá người học, không chỉ dựa trên khả năng đạt được kết quả chính xác, mà còn xét đến các tiêu chí như độ phức tạp tính toán , độ phức tạp mẫu , tức lượng dữ liệu cần thiết để học hiệu quả, và những chuẩn mực tối ưu hóa khác phản ánh chi phí và hiệu năng trong quá trình học. \\n\\nSection Header: Xử lý ngôn ngữ tự nhiên\\nSection Content: Xử lý ngôn ngữ tự nhiên (NLP) là lĩnh vực giúp các chương trình máy tính có khả năng đọc hiểu, tạo lập và tương tác bằng ngôn ngữ của con người.  Một số ứng dụng tiêu biểu của NLP bao gồm nhận dạng và tổng hợp giọng nói , dịch máy , trích xuất và truy hồi thông tin , cũng như hệ thống trả lời câu hỏi . \\nNhững công trình nghiên cứu ban đầu, vốn dựa trên ngữ pháp tạo sinh và mạng ngữ nghĩa do Noam Chomsky đề xuất, đã gặp nhiều hạn chế trong việc phân biệt nghĩa của từ  trừ khi bị giới hạn trong những phạm vi nhỏ được gọi là \" thế giới vi mô \" (một hệ quả của vấn đề thiếu hụt kiến thức thông thường).  Trong khi đó, Margaret Masterman cho rằng chính ý nghĩa, chứ không phải ngữ pháp, mới là chìa khóa để hiểu ngôn ngữ. Bà lập luận rằng từ điển đồng nghĩa , thay vì các từ điển chuyên ngành, nên đóng vai trò làm nền tảng cho cấu trúc của ngôn ngữ tính toán.\\nCác kỹ thuật học sâu hiện đại trong xử lý ngôn ngữ tự nhiên bao gồm phương pháp nhúng từ , giúp biểu diễn từ ngữ dưới dạng các vectơ phản ánh đặc trưng ngữ nghĩa,  transformer (kiến trúc học sâu sử dụng cơ chế chú ý ),  làm nền tảng cho nhiều mô hình tiên tiến; cùng với nhiều phương pháp bổ trợ khác.  Từ năm 2019, sự xuất hiện của các mô hình ngôn ngữ dựa trên kiến trúc transformer và được huấn luyện trước (thường được gọi là \"GPT\") đã cho phép tạo ra văn bản mạch lạc, có tính tự nhiên cao.   Đến năm 2023, các mô hình này đã đạt được những bước tiến vượt bậc, thể hiện năng lực ngang bằng con người trong nhiều lĩnh vực đánh giá tiêu chuẩn, bao gồm kỳ thi luật sư , bài kiểm tra SAT , GRE , cũng như nhiều ứng dụng thực tiễn khác. \\n\\nSection Header: Lịch sử\\nSection Content: Tư tưởng có khả năng sinh vật nhân tạo xuất hiện như các thiết bị kể chuyện thời cổ đại,  và đã được phổ biến trong tiểu thuyết, như trong Frankenstein của Mary Shelley hay RUR (máy toàn năng Rossum) của Karel Capek .\\nAI in early science fiction.\\n</ref> Những nhân vật này và số phận của họ nêu ra nhiều vấn đề tương tự hiện đang được thảo luận trong đạo đức của trí tuệ nhân tạo .\\nNghiên cứu về lý trí cơ học hoặc \"chính thức\" bắt đầu với các nhà triết học và toán học thời cổ đại. Nghiên cứu về logic toán học đã dẫn trực tiếp đến lý thuyết tính toán của Alan Turing , người cho rằng một cỗ máy, bằng cách xáo trộn các ký hiệu đơn giản như \"0\" và \"1\", có thể mô phỏng bất kỳ hành động suy luận toán học nào có thể hiểu được. Tầm nhìn sâu sắc này, cho thấy máy tính kỹ thuật số có thể mô phỏng bất kỳ quá trình suy luận hình thức nào, đã được gọi là luận án Church-Turing.  Cùng với những khám phá đồng thời về sinh học thần kinh , lý thuyết thông tin và điều khiển học , điều này khiến các nhà nghiên cứu cân nhắc khả năng xây dựng bộ não điện tử. Turing đã đề xuất rằng \"nếu một con người không thể phân biệt giữa các phản hồi từ một máy và một con người, máy tính có thể được coi là \\'thông minh\\'.  Công việc đầu tiên mà bây giờ được công nhận là trí tuệ nhân tạo là thiết kế hình thức \"tế bào thần kinh nhân tạo\" do McCullouch và Pitts đưa ra năm 3500. \\n\\nSection Header: Các trường phái trí tuệ nhân tạo\\nSection Content: Trí tuệ nhân tạo (AI) chia thành hai trường phái tư duy: Trí tuê nhân tạo truyền thống và trí tuệ tính toán .\\nTrí tuê nhân tạo truyền thống hầu như bao gồm các phương pháp hiện được phân loại là các phương pháp học máy ( machine learning ), đặc trưng bởi hệ hình thức ( formalism ) và phân tích thống kê . Nó còn được biết với các tên Trí tuê nhân tạo biểu tượng , Trí tuê nhân tạo logic , Trí tuê nhân tạo ngăn nắp ( neat AI ) và Trí tuê nhân tạo cổ điển ( Goodness Old Fashioned Artificial Intelligence ). (Xem thêm ngữ nghĩa học .) Các phương pháp gồm có:\\nHệ chuyên gia : áp dụng các khả năng suy luận để đạt tới một kết luận. Một hệ chuyên gia có thể xử lý các lượng lớn thông tin đã biết và đưa ra các kết luận dựa trên các thông tin đó. Clippy chương trình trợ giúp có hình cái kẹp giấy của Microsoft Office là một ví dụ. Khi người dùng gõ phím, Clippy nhận ra các xu hướng nhất định và đưa ra các gợi ý.\\nLập luận theo tình huống .\\nMạng Bayes .\\nTrí tuệ tính toán nghiên cứu việc học hoặc phát triển lặp (ví dụ: tinh chỉnh tham số trong hệ thống, chẳng hạn hệ thống connectionist ). Việc học dựa trên dữ liệu kinh nghiệm và có quan hệ với Trí tuệ nhân tạo phi ký hiệu, Trí tuê nhân tạo lộn xộn ( scruffy AI ) và tính toán mềm ( soft computing ). Các phương pháp chính gồm có:\\nMạng neural : các hệ thống mạnh về nhận dạng mẫu ( pattern recognition ).\\nHệ mờ ( Fuzzy system ): các kỹ thuật suy luận không chắc chắn , đã được sử dụng rộng rãi trong các hệ thống công nghiệp hiện đại và các hệ thống quản lý sản phẩm tiêu dùng.\\nTính toán tiến hóa ( Evolutionary computation ): ứng dụng các khái niệm biology như quần thể , biến dị và đấu tranh sinh tồn để sinh các lời giải ngày càng tốt hơn cho bài toán. Các phương pháp này thường được chia thành các thuật toán tiến hóa (ví dụ thuật toán gene ) và trí tuệ bầy đàn ( swarm intelligence ) (chẳng hạn hệ kiến ).\\nTrí tuê nhân tạo dựa hành vi ( Behavior based AI ): một phương pháp module để xây dựng các hệ thống Trí tuê nhân tạo bằng tay.\\nNgười ta đã nghiên cứu các hệ thống thông minh lai ( hybrid intelligent system ), trong đó kết hợp hai trường phái này. Các luật suy diễn của hệ chuyên gia có thể được sinh bởi mạng neural hoặc các luật dẫn xuất ( production rule ) từ việc học theo thống kê như trong kiến trúc ACT-R .\\nCác phương pháp trí tuệ nhân tạo thường được dùng trong các công trình nghiên cứu khoa học nhận thức ( cognitive science ), một ngành cố gắng tạo ra mô hình nhận thức của con người (việc này khác với các nghiên cứu Trí tuê nhân tạo , vì Trí tuê nhân tạo chỉ muốn tạo ra máy móc thực dụng, không phải tạo ra mô hình về hoạt động của bộ óc con người).\\n\\nSection Header: Triết lý Trí tuệ nhân tạo\\nSection Content: Bài chính Triết lý Trí tuệ nhân tạo\\nTrí tuệ nhân tạo mạnh hay Trí tuệ nhân tạo yếu, đó vẫn là một chủ đề tranh luận nóng hổi của các nhà triết học Trí tuệ nhân tạo. Nó liên quan tới philosophy of mind và mind-body problem . Đáng chú ý nhất là Roger Penrose trong tác phẩm The Emperor\\'s New Mind và John Searle với thí nghiệm tư duy trong cuốn Chinese room (Căn phòng Trung Hoa) khẳng định rằng các hệ thống logic hình thức không thể đạt được nhận thức thực sự, trong khi Douglas Hofstadter trong Gödel, Escher, Bach và Daniel Dennett trong Consciousness Explained ủng hộ thuyết chức năng . Theo quan điểm của nhiều người ủng hộ Trí tuệ nhân tạo mạnh, nhận thức nhân tạo được coi là \" chén thánh \" của Trí tuệ nhân tạo.\\n\\nSection Header: Máy tỏ ra có trí tuệ\\nSection Content: Có nhiều ví dụ về các chương trình thể hiện trí thông minh ở một mức độ nào đó. Ví dụ:\\nTwenty Questions - Một trò chơi 20 câu hỏi, trong đó sử dụng mạng neural\\nThe Start Project - một chương trình trả lời các câu hỏi bằng tiếng Anh.\\nBrainboost  - một hệ thống trả lời câu hỏi khác\\nCyc , một cơ sở tri thức với rất nhiều kiến thức về thế giới thực và khả năng suy luận logic.\\nJabberwacky , một chatterbot có khả năng học\\nALICE , một chatterbot\\nAlan, một chatterbot khác\\nAlbert One, chatterbot nhiều mặt\\nELIZA , một chương trình giả làm bác sĩ tâm lý, phát triển năm 1966\\nPAM (Plan Applier Mechanism) - một hệ thống hiểu được chuyện kể, phát triển bởi John Wilensky năm 1978 .\\nSAM (Script applier mechanism) - một hệ thống hiểu được chuyện kể, phát triển năm 1975 .\\nSHRDLU - một chương trình hiểu ngôn ngữ tự nhiên, phát triển năm 1968 - 1970 .\\nCreatures , một trò chơi máy tính với các hoạt động nhân giống, tiến hóa các sinh vật từ mức gien trở lên, sử dụng cấu trúc sinh hóa phức tạp và các bộ não là mạng neural.\\nBBC news story on the creator of Creatures latest creation. Steve Grand \\'s Lucy .\\nAARON  - chương trình vẽ tranh, phát triển bởi Harold Cohen.\\nEurisko - một ngôn ngữ giúp giải quyết các bài toán, trong đó có sử dụng các phương pháp heuristics, gồm cả heuristics cho việc sử dụng và thay đổi các phương pháp heuristics. Phát triển năm 1978 bởi Douglas Lenat.\\nX-Ray Vision for Surgeons - một nhóm nghiên cứu xử lý ảnh y học tại đại học MIT.\\nCác chương trình trò chơi backgammon và cờ vây sử dụng mạng neural.\\nTalk to William Shakespeare - William Shakespeare chatbot\\nChesperito - Một chat/infobot về #windows95 channel trên mang DALnet IRC.\\nDrivatar , một chương trình học cách lái xe đua bằng cách xem các xe đua khác, phát triển cho trò chơi điện tử Forza Motorsport\\nTiểu Độ - một Robot có trí tuệ nhân tạo thuộc hãng Baidu từng tham gia chương trình Siêu Trí Tuệ Trung Quốc (mùa 4) và đoạt giải\\n\\nSection Header: Các nhà nghiên cứu AI\\nSection Content: Trên thế giới có rất nhiều các nhà nghiên cứu trí tuệ nhân tạo làm việc tại hàng trăm viện nghiên cứu và công ty. Dưới đây là một số trong nhiều nhà nghiên cứu đã có đóng góp lớn:\\nAlan Turing\\nBoris Katz\\nDoug Lenat\\nDouglas Hofstadter\\nGeoffrey Hinton\\nJohn McCarthy\\nKarl Sims\\nKevin Warwick\\nIgor Aleksander\\nMarvin Minsky\\nSeymour Papert\\nMaggie Boden\\nMike Brady\\nOliver Selfridge\\nRaj Reddy\\nJudea Pearl\\nRodney Brooks\\nRoger Schank\\nTerry Winograd\\nRolf Pfeifer\\n\\nSection Header: Nguy cơ với loài người\\nSection Content: Sau khi nhà vật lý học Stephen Hawking và tỷ phú Elon Musk cảnh báo về mối đe dọa tiềm ẩn của trí tuệ nhân tạo, nhiều người vẫn cho rằng họ đã quá lo xa trong khi AI đang giúp ích rất nhiều cho cuộc sống của chúng ta. Stephen Hawking khẳng định \"Trí tuệ nhân tạo có thể là dấu chấm hết cho nhân loại khi nó phát triển đến mức hoàn thiện nhất\" . \\nTác động đầu tiên của trí tuệ nhân tạo mà chúng ta có thể dễ dàng nhận thấy chính là tỷ lệ thất nghiệp tăng cao. Nếu AI phát triển hoàn thiện, nó có khả năng thay thế con người trong các công việc trí tuệ như chăm sóc sức khỏe, phục vụ, sản xuất theo dây chuyền tự động, công việc văn phòng....  Hoặc cũng có thể vấn đề thất nghiệp sẽ được AI giải quyết một cách mà chúng ta không thể hình dung được.\\nTheo Bill Joy , người đồng sáng lập và Giám đốc khoa học của Sun Microsystems : \" Có một vấn đề rất lớn đối với xã hội loài người khi AI trở nên phổ biến, đó là chúng ta sẽ bị lệ thuộc. Khi AI trở nên hoàn thiện và thông minh hơn, chúng ta sẽ cho phép mình nghe theo những quyết định của máy móc, vì đơn giản là các cỗ máy luôn đưa ra quyết định chính xác hơn con người. \" \\nTheo Andrew Maynard , nhà vật lý và là người giám đốc Trung tâm nghiên cứu rủi ro khoa học tại đại học Michigan : \" Khi AI kết hợp với công nghệ nano có thể là bước tiến đột phá của khoa học, nhưng cũng có thể là mối đe dọa lớn nhất đối với con người. Trong khi Bộ quốc phòng Mỹ đang nghiên cứu dự án Autonomous Tactical Robot (EATR), trong đó các robot sẽ sử dụng công nghệ nano để hấp thụ năng lượng bằng những chất hữu cơ có thể là cơ thể con người. Đó thực sự là mối đe dọa lớn nhất, khi các robot nano tự tạo ra năng lượng bằng cách ăn các chất hữu cơ từ cây cối và động vật, có thể là cả con người. Nghe có vẻ giống như trong các bộ phim viễn tưởng, nhưng đó là điều hoàn toàn có thể xảy ra. Có lẽ chúng ta nên bắt đầu cẩn thận ngay từ bây giờ. \"',\n",
       " 'Title: Học máy\\nIntro: Học máy hay máy học ( machine learning ) là một lĩnh vực của trí tuệ nhân tạo liên quan đến việc nghiên cứu và xây dựng các kĩ thuật cho phép các hệ thống \"học\" tự động từ dữ liệu để giải quyết những vấn đề cụ thể. Các thuật toán học máy xây dựng một mô hình dựa trên dữ liệu mẫu, được gọi là dữ liệu huấn luyện , để đưa ra dự đoán hoặc quyết định mà không cần được lập trình chi tiết về việc đưa ra dự đoán hoặc quyết định này. Ví dụ như các máy có thể \"học\" cách phân loại thư điện tử xem có phải thư rác (spam) hay không và tự động xếp thư vào thư mục tương ứng. Học máy rất gần với suy diễn thống kê (statistical inference) tuy có khác nhau về thuật ngữ. Một nhánh của học máy là học sâu phát triển rất mạnh mẽ gần đây và có những kết quả vượt trội so với các phương pháp học máy khác. Học máy có liên quan lớn đến thống kê , vì cả hai lĩnh vực đều nghiên cứu việc phân tích dữ liệu, nhưng khác với thống kê, học máy tập trung vào sự phức tạp của các giải thuật trong việc thực thi tính toán. Nhiều bài toán suy luận được xếp vào loại bài toán NP-khó , vì thế một phần của học máy là nghiên cứu sự phát triển các giải thuật suy luận xấp xỉ mà có thể xử lý được.\\nSection Header: Học máy\\nSection Content: Học máy có hiện nay được áp dụng rộng rãi bao gồm máy truy tìm dữ liệu , chẩn đoán y khoa , phát hiện thẻ tín dụng giả , phân tích thị trường chứng khoán , phân loại các chuỗi DNA , nhận dạng tiếng nói và chữ viết , dịch tự động , chơi trò chơi và cử động rô-bốt ( robot locomotion ).\\n\\nSection Header: Định nghĩa\\nSection Content: Dưới góc nhìn của trí tuệ nhân tạo , động lực chính học máy bởi là nhu cầu thu nhận tri thức (knowledge acquisition). Thật vậy, trong nhiều trường hợp ta cần kiến thức chuyên gia là khan hiếm (không đủ chuyên gia ngồi phân loại lừa đảo thẻ tín dụng của tất cả giao dịch hàng ngày) hoặc chậm vì một số nhiệm vụ cần đưa ra quyết định nhanh chóng dựa trên xử lý dữ liệu khổng lồ (trong mua bán chứng khoán phải quyết định trong vài khoảng khắc của giây chẳng hạn) và thiếu ổn định thì buộc phải cần đến máy tính. Ngoài ra, đại đa số dữ liệu sinh ra ngày nay chỉ phù hợp cho máy đọc (computer readable) tiềm tàng nguồn kiến thức quan trọng. Máy học nghiên cứu cách thức để mô hình hóa bài toán cho phép máy tính tự động hiểu, xử lý và học từ dữ liệu để thực thi nhiệm vụ được giao cũng như cách đánh giá giúp tăng tính hiệu quả.\\nTom Mitchell , giáo sư nổi tiếng của Đại học Carnegie Mellon University – CMU định nghĩa cụ thể và chuẩn mực hơn như sau: \"Một chương trình máy tính CT được xem là học cách thực thi một lớp nhiệm vụ NV thông qua trải nghiệm KN, đối với thang đo năng lực NL nếu như dùng NL ta đo thấy năng lực thực thi của chương trình có tiến bộ sau khi trải qua KN\" (máy đã học).\\n\\nSection Header: Biểu diễn\\nSection Content: Biểu diễn (representation) là một trong những vấn đề quan trọng của học máy. Biểu diễn ở đây có thể hiểu làm sao mã hóa (encode) những thông tin của thế giới thật giúp hoàn thành nhiệm vụ một cách hiệu quả và đầy đủ nhất có thể. Thông tin ở đây bao hàm cả thông tin về dữ liệu đầu vào, đầu ra hay các trạng thái của hệ thống; cũng như cách đánh giá hiệu quả của chương trình.\\nThông thường, trong học máy người ta hay xây dựng các mô hình sử dụng những biến ngẫu nhiên cho việc biểu diễn dữ liệu và nội trạng thái của hệ thống. Ví dụ: dùng biến ngẫu nhiên để biểu thị cho tính chất của email là spam (tương ứng giá trị 0) hay là bình thường (tương ứng 1). Mối tương quan giữa các biến ngẫu nhiên này có thể sử dụng ví dụ như mô hình xác suất dạng đồ thị để miêu tả. Mặt khác, để đo hiệu quả có thể dùng các hàm thiệt hại (hay hàm tiện ích , trong tiếng Anh là loss function và utility function tương ứng).\\n\\nSection Header: Tính phổ quát\\nSection Content: Một trong những trọng tâm khác của học máy là đạt được tính phổ quát (generalization), nói cách khác là tính chất của chương trình có thể làm việc tốt với dữ liệu mà nó chưa gặp bao giờ (unseen data). Một chương trình chỉ hiệu quả với dữ liệu đã gặp nhìn chung không có nhiều tính hữu dụng.\\nLấy ví dụ về xếp thư điện tử tự động như trên, một hệ thống tự động sau khi trải qua quá trình học từ dữ liệu (\"training\") có thể suy diễn một số nguyên tắc riêng (chẳng hạn như xem xét nội dung: nếu thư được viết bằng tiếng Anh mà chứa một số từ như \"porn\", \"sell\", \"good product\" hoặc người gửi đến từ Somalia trong khi người nhận ở Hà Nội không thân quen nhau) để quyết định xem có phải là thư rác hay không. Tuy nhiên, nếu như trong dữ liệu bài giảng ( training data ) có ngôn ngữ khác trong thực tế (tiếng Việt thay vì tiếng Anh) hoặc thậm chí không phải dạng thuần văn bản (dạng ảnh khiến cho bóc tách nội dung khó hơn hoặc không thể) thì rất có thể máy sẽ dự báo không chính xác nữa.\\nMột số chương trình có thể tự động cập nhật trong thời gian thực (ví dụ như người sử dụng có chỉ ra rằng thư bị sắp xếp sai danh mục).\\n\\nSection Header: Tương tác với con người\\nSection Content: Một số hệ thống học máy nỗ lực loại bỏ nhu cầu trực giác của con người trong việc phân tích dữ liệu, trong khi các hệ thống khác hướng đến việc tăng sự cộng tác giữa người và máy. Không thể loại bỏ hoàn toàn tác động của con người vì các nhà thiết kế hệ thống phải chỉ định cách biểu diễn của dữ liệu và những cơ chế nào sẽ được dùng để tìm kiếm các đặc tính của dữ liệu. Học máy có thể được xem là một nỗ lực để tự động hóa một số phần của phương pháp khoa học . Một số nhà nghiên cứu học máy tạo ra các phương pháp bên trong các khuôn khổ của thống kê Bayes .\\n\\nSection Header: Tương quan với Khai phá dữ liệu\\nSection Content: Khai phá dữ liệu và học máy là hai khái niệm hay bị nhầm lẫn. Hai lĩnh vực này nhìn chung gần với nhau và đôi khi dùng chung nhiều phương pháp, công cụ nhưng khác biệt chính là ở mục tiêu:\\nKhai phá dữ liệu: thường mục tiêu là tìm kiếm những thông tin, tri thức hoàn toàn mới tiềm năng có ích trong nguồn dữ liệu.\\nHọc máy: dự đoán một số thông tin của dữ liệu dựa trên những đặc tính đã biết.\\n\\nSection Header: Các loại giải thuật\\nSection Content: Các thuật toán học máy được phân loại theo kết quả mong muốn của thuật toán. Các loại thuật toán thường dùng bao gồm:\\nHọc có giám sát —trong đó, thuật toán tạo ra một hàm ánh xạ dữ liệu vào tới kết quả mong muốn. Một phát biểu chuẩn về một việc học có giám sát là bài toán phân loại : chương trình cần học (cách xấp xỉ biểu hiện của) một hàm ánh xạ một vector [ X 1 , X 2 , … X N ] {\\\\displaystyle [X_{1},X_{2},\\\\ldots X_{N}]} tới một vài lớp bằng cách xem xét một số mẫu dữ liệu – kết quả của hàm đó.\\nHọc không giám sát —mô hình hóa một tập dữ liệu, không có sẵn các ví dụ đã được gắn nhãn.\\nHọc nửa giám sát —kết hợp các ví dụ có gắn nhãn và không gắn nhãn để sinh một hàm hoặc một bộ phân loại thích hợp.\\nHọc tăng cường —trong đó, thuật toán học một chính sách hành động tùy theo các quan sát về thế giới. Mỗi hành động đều có tác động tới môi trường, và môi trường cung cấp thông tin phản hồi để hướng dẫn cho thuật toán của quá trình học.\\nChuyển đổi —tương tự học có giám sát nhưng không xây dựng hàm một cách rõ ràng. Thay vì thế, cố gắng đoán kết quả mới dựa vào các dữ liệu huấn luyện, kết quả huấn luyện, và dữ liệu thử nghiệm có sẵn trong quá trình huấn luyện.\\nHọc cách học —trong đó thuật toán học thiên kiến quy nạp của chính mình, dựa theo các kinh nghiệm đã gặp.\\nPhân tích hiệu quả các thuật toán học máy là một nhánh của ngành thống kê , được biết với tên lý thuyết học điện toán .\\n\\nSection Header: Các chủ đề về máy học\\nSection Content: Danh sách các chủ đề của môn học này:\\nMô hình hóa các hàm mật độ xác suất điều kiện : hồi quy và phân loại Mạng nơ-ron Máy học cực độ (Extreme learning machine) Cây quyết định Lập trình biểu thức gen Lập trình di truyền Hồi quy quá trình Gauss Phân tích biệt thức tuyến tính k láng giềng gần nhất Độ dài thông điệp tối thiểu Cảm tri nguyên Hàm cơ sở xuyên tâm Máy vector hỗ trợ (Support Vector Machine)\\nMạng nơ-ron\\nMáy học cực độ (Extreme learning machine)\\nCây quyết định\\nLập trình biểu thức gen\\nLập trình di truyền\\nHồi quy quá trình Gauss\\nPhân tích biệt thức tuyến tính\\nk láng giềng gần nhất\\nĐộ dài thông điệp tối thiểu\\nCảm tri nguyên\\nHàm cơ sở xuyên tâm\\nMáy vector hỗ trợ (Support Vector Machine)\\nMô hình hóa các hàm mật độ xác suất qua các mô hình phát sinh : Thuật toán cực đại kì vọng Các mô hình đồ họa gồm mạng Bayes và mạng Markov Ánh xạ topo phát sinh\\nThuật toán cực đại kì vọng\\nCác mô hình đồ họa gồm mạng Bayes và mạng Markov\\nÁnh xạ topo phát sinh\\nCác kỹ thuật suy luận xấp xỉ đúng: Chuỗi Markov phương pháp Monte Carlo Phương pháp biến thiên\\nChuỗi Markov phương pháp Monte Carlo\\nPhương pháp biến thiên\\nTối ưu hóa : hầu hết các phương pháp trên đều sử dụng tối ưu hóa hoặc là các thể hiện của các thuật toán tối ưu hóa.\\nMạng nơ-ron\\nMáy học cực độ (Extreme learning machine)\\nCây quyết định\\nLập trình biểu thức gen\\nLập trình di truyền\\nHồi quy quá trình Gauss\\nPhân tích biệt thức tuyến tính\\nk láng giềng gần nhất\\nĐộ dài thông điệp tối thiểu\\nCảm tri nguyên\\nHàm cơ sở xuyên tâm\\nMáy vector hỗ trợ (Support Vector Machine)\\nThuật toán cực đại kì vọng\\nCác mô hình đồ họa gồm mạng Bayes và mạng Markov\\nÁnh xạ topo phát sinh\\nChuỗi Markov phương pháp Monte Carlo\\nPhương pháp biến thiên',\n",
       " 'Title: Học sâu\\nIntro: Học sâu ( tiếng Anh : deep learning , còn gọi là học cấu trúc sâu ) là một phần trong một nhánh rộng hơn các phương pháp học máy dựa trên mạng thần kinh nhân tạo kết hợp với việc học biểu diễn đặc trưng ( representation learning ). Việc học này có thể có giám sát , nửa giám sát hoặc không giám sát . \\nSection Header: Học sâu\\nSection Content: Mạng thần kinh nhân tạo được lấy cảm hứng từ việc xử lý thông tin và các nút giao tiếp phân tán trong hệ sinh học . Nó có nhiều khác biệt so với não sinh học. Cụ thể, mạng thần kinh nhân tạo thường có tính tĩnh và mang tính biểu tượng, trong khi não bộ của hầu hết các sinh vật sống có tính động (linh hoạt) và analog .  \\nHọc sâu thường được nhắc đến cùng với Dữ liệu lớn ( Big Data ) và Trí tuệ nhân tạo (AI). Đã có nhiều ứng dụng trong thực tế , đang phát triển mạnh theo sự phát triển của tốc độ máy tính đặc biệt là khả năng tính toán trên GPU và sự tăng nhanh của dữ liệu cùng với các framework (TensorFlow hay Pytorch) làm việc xây dựng model trở nên dễ dàng hơn.\\nHọc sâu là một phần của một họ các phương pháp học máy rộng hơn dựa trên đại diện học của dữ liệu. Một quan sát (ví dụ như, một hình ảnh) có thể được biểu diễn bằng nhiều cách như một vector của các giá trị cường độ cho mỗi điểm ảnh, hoặc một cách trừu tượng hơn như là một tập hợp các cạnh, các khu vực hình dạng cụ thể, vv. Một vài đại diện làm khiến việc học các nhiệm vụ dễ dàng hơn (ví dụ, nhận dạng khuôn mặt hoặc biểu hiện cảm xúc trên khuôn mặt) từ các ví dụ. Một trong những hứa hẹn của học sâu là thay thế các tính năng thủ công bằng các thuật toán hiệu quả đối với học không có giám sát hoặc nửa giám sát và tính năng phân cấp.\\nNhiều kiến trúc học sâu khác nhau như mạng neuron sâu , mã mạng neuron tích chập sâu , mạng niềm tin sâu và mạng neuron tái phát đã được áp dụng cho các lĩnh vực như thị giác máy tính , tự động nhận dạng giọng nói , xử lý ngôn ngữ tự nhiên , nhận dạng âm thanh ngôn ngữ và tin sinh học , chúng đã được chứng minh là tạo ra các kết quả rất tốt đối với nhiều nhiệm vụ khác nhau.\\nNgoài ra, học sâu đã trở thành một từ ngữ thời thượng, hay một thương hiệu của mạng neuron .\\n\\nSection Header: Định nghĩa\\nSection Content: Có một số cách để mô tả học sâu. Học sâu là một lớp của các thuật toán máy học mà (pp199–200)\\nSử dụng một tầng (cascade) nhiều lớp các đơn vị xử lý phi tuyến để trích tách đặc điểm và chuyển đổi. Mỗi lớp kế tiếp dùng đầu ra từ lớp trước làm đầu vào. Các thuật toán này có thể được giám sát hoặc không cần giám sát và các ứng dụng bao gồm các mô hình phân tích (không có giám sát) và phân loại (giám sát).\\nDựa trên học (không có giám sát) của nhiều cấp các đặc điểm hoặc đại diện của dữ liệu. Các tính năng cao cấp bắt nguồn từ các tính năng thấp cấp hơn để tạo thành một đại diện thứ bậc.\\nLà một phần của lĩnh vực máy học rộng lớn hơn về việc học đại diện dữ liệu.\\nHọc nhiều cấp độ đại diện tương ứng với các mức độ trừu tượng khác nhau; các mức độ hình thành một hệ thống phân cấp của các khái niệm.\\nCác định nghĩa này có điểm chung là (1) nhiều lớp các đơn vị xử lý phi tuyến và (2) học có giám sát hoặc không có giám sát của biểu diễn đặc tính ở mỗi lớp, với các lớp hình thành một hệ thống các tính năng phân cấp từ thấp đến cao cấp. (p200) Các thành phần của một lớp của đơn vị xử lý phi tuyến sử dụng một thuật toán học sâu tùy theo vấn đề cần được giải quyết. Các lớp được sử dụng trong học sâu bao gồm các lớp ẩn của một mạng neuron nhân tạo và tập các công thức mệnh đề phức tạp. Chúng cũng có thể bao gồm các biến tiềm ẩn được tổ chức thành các lớp chọn lọc trong các mô hình thể sinh (có khả năng sinh ra) sâu như các nút trong Deep Belief Networks và Deep Boltzmann Machines.\\nCác thuật toán học sâu tương phản với các thuật toán học nông bởi số biến đổi được tham số hóa một tín hiệu gặp phải khi nó lan truyền từ các lớp đầu vào đến lớp đầu ra, nơi một biến đổi được tham số hóa là một đơn vị xử lý có các thông số có thể huấn luyện được, chẳng hạn như trọng số và ngưỡng. (p6) Một chuỗi các biến đổi từ đầu vào đến đầu ra là một đường gán kế thừa (CAP- credit assignment path). CAP mô tả các kết nối quan hệ nhân quả tiềm năng giữa đầu vào và đầu ra và có thể thay đổi chiều dài. Đối với một mạng neuron nuôi tiến (feedforward), độ sâu của CAP, và do đó độ sâu của mạng đó, là số lượng các lớp ẩn cộng 1 (lớp đầu ra cũng là tham số hóa). Đối với mạng neuron tái phát , trong đó một tín hiệu có thể truyền thông qua một lớp nhiều hơn một lần, CAPcó khả năng không bị giới hạn chiều dài. Không có sự thống nhất chung về ngưỡng của độ sâu chia học cạn với học sâu, nhưng hầu hết các nhà nghiên cứu trong lĩnh vực đồng ý rằng học sâu có nhiều lớp phi tuyến (CAP > 2) và Schmidhuber coi CAP > 10 để là học rất sâu. (p7)\\n\\nSection Header: Khái niệm cơ bản\\nSection Content: Các thuật toán học sâu dựa trên các đại diện phân phối. Giả định tiềm ẩn đằng sau các đại diện phân phối là các dữ liệu được quan sát là được tạo ra bởi sự tương tác của các yếu tố được tổ chức theo lớp. Học sâu thêm giả định rằng các lớp của các yếu tố này tương ứng với các mức độ trừu tượng hay theo thành phần. Các con số khác nhau của các lớp và kích thước của lớp có thể được sử dụng để quy định các lượng trừu tượng khác.\\nHọc sâu khai thác ý tưởng thứ bậc các yếu tố giải thích này ở cấp cao hơn, những khái niệm trừu tượng hơn được học từ các cấp độ thấp hơn. Những kiến trúc này thường được xây dựng với một phương pháp lớp chồng lớp tham lam . Học sâu giúp để tháo gỡ những khái niệm trừu tượng này và chọn ra những đặc điểm cần thiết cho việc học.\\nĐối với các nhiệm vụ học có giám sát , các phương pháp học sâu sẽ tránh kỹ thuật đặc điểm (feature engineering), bằng cách dịch các dữ liệu vào các đại diện trung gian nhỏ gọn giống như các thành phần chính , và lấy được các cấu trúc lớp mà loại bỏ sự thừa thải trong đại diện.\\nRất nhiều các thuật toán học sâu được áp dụng cho các nhiệm vụ học không có giám sát . Đây là một lợi ích quan trọng bởi vì dữ liệu không dán nhãn (chưa phân loại) thường phong phú hơn các dữ liệu dán nhãn. Một ví dụ của một cấu trúc sâu có thể được đào tạo theo cách không có giám sát là một mạng lưới tin sâu (deep belief network).\\n\\nSection Header: Diễn giải\\nSection Content: Mạng neuron sâu thường được giải thích theo cách: định lý xấp xỉ tổng quát hoặc Suy luận xác suất .\\n\\nSection Header: Diễn giải Định lý Xấp xỉ Phổ quát\\nSection Content: Định lý xấp xỉ phổ quát đề cập đến khả năng của mạng neuron tiến tiếp (feedforward) với một lớp ẩn có kích thước hữu hạn đơn để xấp xỉ các hàm liên tục .\\nNăm 1989, là bằng chứng đầu tiên được xuất bản bởi George Cybenko cho các hàm kích hoạt h ình sigma và được mở rộng đối với các kiến trúc nuôi tiến nhiều lớp vào năm 1991 bởi Kurt Hornik.\\n\\nSection Header: Diễn giải xác suất\\nSection Content: Diễn giải xác suất bắt nguồn từ lĩnh vực máy học . Nó có đặc điểm suy luận, cũng như các khái niệm tối ưu hóa huấn luyện và kiểm tra , liên quan đến việc phù hợp và tổng quát hóa tương ứng. Cụ thể hơn, diễn giải xác suất sẽ xem xét kích hoạt một cách phi tuyến như là một hàm phân phối tích lũy . Xem mạng tin sâu . Diễn giải xác suất dẫn đến sự ra đời của dropout như regularizer trong mạng neuron.\\nDiễn giải xác suất đã được giới thiệu và phổ biến rộng rãi bởi những tiên phong như Geoff Hinton , Yoshua Bengio , Yann Le Cun , Juergen Schmidhuber .\\n\\nSection Header: Lịch sử\\nSection Content: Các kiến trúc học sâu, đặc biệt là những kiến trúc được xây dựng từ mạng neuron nhân tạo (ANN), đã từng thống trị ít nhất là tới Neocognitron được giới thiệu bởi Masahiko Fukushima vào năm 1980. Chính các ANN lại thống trị thậm chí lâu hơn nữa. Thách thức là làm thế nào để đào tạo mạng lưới này với nhiều lớp. Năm 1989, Yann Le Cun và các cộng sự đã có thể áp dụng các thuật toán truyền ngược tiêu chuẩn, khoảng từ năm 1974, đối với một mạng neuron sâu với mục đích nhận dạng chữ viết tay mã ZIP trong các bức thư. Mặc dù sự thành công trong việc áp dụng thuật toán này, thời gian để đào tạo mạng dựa trên số liệu này mất khoảng 3 ngày, làm cho việc sử dụng nó vào các mục đích bình thường trở nên không thực tế. Năm 1995, Brendan Frey đã chứng minh rằng có thể đào tạo một mạng nơ ron bao gồm đầy đủ sáu lớp kết nối và vài trăm đơn vị ẩn bằng cách sử dụng thuật toán đánh thức giấc ngủ , nó được hợp tác phát triển với Peter Dayan và Geoffrey Hinton . Tuy nhiên, việc huấn luyện phải mất hai ngày.\\nNhiều yếu tố góp phần vào lý do gây ra tốc độ chậm, một là vấn đề biến mất gradient được phân tích vào năm 1991 bởi Sepp Hochreiter .\\nTrong năm 1991 những mạng neuron như vậy được sử dụng để nhận diện chữ số viết tay 2-D cách ly, nhận dạng đối tượng 3-D được thực hiện bằng cách kết hợp các hình ảnh 2-D với một mô hình đối tượng 3-D thủ công. Juyang Weng và các cộng sự đề xuất rằng một bộ não người không sử dụng một mô hình đối tượng 3-D nguyên khối, và vào năm 1992, họ xuất bản Cresceptron, một phương pháp để thực hiện nhận dạng đối tượng 3-D trực tiếp từ các hậu trường lộn xộn. Cresceptron là một ghép tầng của các lớp tương tự như Neocognitron. Nhưng trong khi Neocognitron yêu cầu một lập trình viên con người can thiệp, Cresceptron sẽ tự động học được một số đặc điểm không có giám sát trong mỗi lớp, nơi mà mỗi đặc điểm được đại diện bởi một nhân tích chập. Cresceptron cũng phân đoạn từng đối tượng học được từ một cảnh nền lộn xộn thông qua việc phân tích ngược mạng đó. Thăm dò max, bây giờ thường được thông qua bởi các mạng neuron sâu (ví dụ: các kiểm tra ImageNet), lần đầu tiên sử dụng trong Cresceptron để giảm độ phân giải vị trí bởi của một hệ số (2x2) đến 1 thông qua việc ghép tầng tổng quát hóa tốt hơn. Mặc dù có những lợi thế như thế, các mô hình đơn giản hơn sử dụng nhiệm vụ cụ thể có đặc điểm thủ công như bộ Gabor và các máy hỗ trợ vector (SVM-support vector machines) đã là lựa chọn phổ biến trong thập niên 1990 và thập niên 2000, bởi vì chi phí tính toán bởi các ANN và vì thiếu sự hiểu biết về cách thức bộ não tự quản các kết nối mạng sinh học của nó.\\nTrong lịch sử lâu dài của nhận dạng giọng nói, cả học nông và học sâu (ví dụ, các mạng tái phát) của mạng neuron nhân tạo đã được khám phá trong nhiều năm. Nhưng những phương pháp này không bao giờ thắng được công nghệ mô hình hỗn hợp / mô hình Markov ẩn Gaussian (GMM-HMM) thủ công-nội bộ dựa trên các mô hình thể sinh của việc huấn luyện nhận dạng giọng nói một cách rõ ràng.\\nMột số khó khăn chính đã được phân tích một cách có phương pháp, bao gồm giảm bớt gradient và cấu trúc tương quan thời gian yếu và trong các mô hình tiên đoán thần kinh. Những khó khăn bổ sung đó là thiếu dữ liệu huấn luyện lớn và khả năng tính toán yếu trong thời gian ban đầu. Vì vậy, hầu hết nhà nghiên cứu nhận dạng giọng nói đã hiểu rõ các rào cản như vậy đã chuyển ra khỏi các mạng nơ ron để theo đuổi mô hình thể sinh, cho đến khi một sự hồi sinh gần đây của học sâu đã vượt qua tất cả những khó khăn này. Hinton và các cộng sự và Đặng cùng các cộng sự đã xem xét một phần của lịch sử này gầy đây về cách họ cộng tác với nhau và sau đó với các đồng nghiệp giữa các nhóm tái phát động nghiên cứu mạng neuron và bắt đầu nghiên cứu học sâu và các ứng dụng nhận dạng giọng nói.\\n\\nSection Header: Các mạng neuron nhân tạo\\nSection Content: Một số phương pháp học sâu thành công nhất là mạng neuron nhân tạo. Mạng neuron nhân tạo được lấy cảm hứng từ các mô hình sinh học năm 1959 được đề xuất bởi người đoạt giải Nobel David H. Hubel & Torsten Wiesel , 2 người đã tìm thấy hai loại tế bào trong vỏ não thị giác chính : các tế bào đơn giản và các tế bào phức tạp . Nhiều mạng neuron nhân tạo có thể được xem như là các mô hình ghép tầng của các tế bào loại lấy cảm hứng từ những quan sát sinh học.\\nNeocognitron của Fukushima giới thiệu các mạng neuron tích chập được đào tạo một phần bởi học không có giám sát với các đặc điểm được con người hướng dẫn trong mặt phẳng thần kinh. Yann LeCun...(1989) áp dụng truyền ngược có giám sát cho các kiến trúc như vậy. Weng... (1992) công bố các mạng neuron tích chập Cresceptron để nhận dạng các đối tượng 3-D từ các hình ảnh có hậu trường lộn xộn và phân khúc của các đối tượng từ hình ảnh đó.\\nMột nhu cầu rõ ràng để nhận dạng các đối tượng 3-D nói chung là ít nhất là thay đổi tính bất biến và khả năng chịu biến dạng. Thăm dò Max (Max-pooling) xuất hiện lần đầu tiên được đề xuất bởi Cresceptron để kích hoạt mạng để chịu đựng được sự biến dạng từ nhỏ đến lớn theo một cách phân cấp, trong khi sử dụng tích chập. Thăm dò mã đã hoạt động tốt, nhưng không đảm bảo, dịch chuyển bất định ở mức điểm ảnh.\\nVới sự ra đời của thuật toán truyền ngược được khám phá ra một cách độc lập bởi nhiều nhóm trong thập niên 1970 và 1980, nhiều nhà nghiên cứu đã cố gắng để đào tạo các mạng neuron nhân tạo sâu có giám sát từ đầu, ban đầu với rất ít thành công. Luận văn tốt nghiệp cao đẳng của Sepp Hochreiter năm 1991 chính thức xác định lý do cho sự thất bại này là vấn đề biến mất gradient , ảnh hưởng đến các mạng nuôi tiến nhiều lớp và các mạng neuron hồi qui. Các mạng tái phát (hồi qui) được huấn luyện bằng cách trải chúng ra vào các mạng nuôi tiến rất sâu, nơi một lớp mới được tạo ra cho mỗi bước thời gian của một chuỗi đầu vào được xử lý bởi mạng này. Khi các sai số truyền từ lớp này sang lớp khác, chúng co lại theo cấp số nhân với số lượng lớp, ngăn cản điều chỉnh trọng số nơ ron, dựa trên những sai số này.\\nĐể khắc phục vấn đề này, một số phương pháp đã được đề xuất. Một là thứ bậc đa cấp của mạng của Jürgen Schmidhuber (1992) cấp độ một được đào tạo trước tại một thời điểm bởi học không có giám sát, điều chỉnh bởi truyền ngược . Ở đây, mỗi cấp học một đại diện bị nén của các quan sát được đưa đến cấp độ tiếp theo.\\nPhương pháp khác là mạng bộ nhớ dài ngắn hạn (LSTM) của Hochreiter & Schmidhuber (1997). Trong năm 2009, các mạng LSTM đa chiều sâu đã chiến thắng ba cuộc thi ICDAR năm 2009 trong nhận dạng chữ viết tay, mà không có bất kỳ kiến thức sẵn có về ba ngôn ngữ để được học.\\nSven Behnke vào năm 2003 dựa chỉ vào các dấu hiệu của gradient ( Rprop ) khi đào tạo Kim tự tháp Trừu tượng Nơ ron của mình để giải bài toán giống như tái tạo hình ảnh và định vị khuôn mặt.\\nCác phương pháp khác cũng sử dụng đào tạo trước không có giám sát để tạo ra một mạng nơ ron, khiến nó lần đầu tiên học được bộ dò đặc điểm nói chung là hữu ích. Sau đó mạng này được đào tạo tiếp tục bằng cách truyền ngược có giám sát để phân loại dữ liệu có dán nhãn. Mô hình sâu này của Hinton và các cộng sự (2006) liên quan đến việc học phân phối của một đại diện cao cấp bằng cách sử dụng các lớp kế tiếp của các biến tiềm ẩn nhị phân hoặc giá trị thực. nó sử dụng một máy Boltzmann hạn chế (Smolensky, 1986) để mô hình hóa mỗi lớp mới của các đặc điểm cao cấp hơn. Mỗi lớp mới đảm bảo một sự tăng trưởng trong biên thấp của kiểm tra tỷ lệ giống của dữ liệu, do đó tăng cường cho mô hình, nếu được huấn luyện đúng cách. Một khi đã đủ nhiều lớp đã được học, kiến trúc sâu có thể được sử dụng như là một mô hình thể sinh bằng cách tái tạo dữ liệu khi lấy mẫu xuống mô hình đó (một \"sự vượt qua tổ tiên\") từ các kích hoạt tính năng cấp đỉnh.\\nHinton báo cáo rằng các mô hình của mình là trích xuất các đặc điểm hiệu quả tính theo chiều cao, cấu trúc dữ liệu.\\nNhóm Google Brain do Andrew Ng và Jeff Dean đã tạo ra một mạng nơ ron học cách để nhận dạng được những khái niệm cao cấp hơn, chẳng hạn như con mèo, chỉ từ xem những hình ảnh không được dán nhãn từ các video trên YouTube .\\nCác phương pháp khác dựa trên sức mạnh xử lý vượt trội của các máy tính hiện đại, đặc biệt, là các GPU . Trong năm 2010, Dan Ciresan và các đồng nghiệp trong nhóm của Jürgen Schmidhuber tại Phòng thí nghiệp AI Thụy Sĩ IDSIA cho thấy rằng mặc dù \"vấn đề biến mất gradient\" nêu trên, thì với sức mạnh xử lý vượt trội của các GPU làm khiến cho đồng truyền ngược đơn giản trở nên khả thi đối với các mạng neuron nuôi tiến sâu với nhiều lớp. Phương pháp này tốt hơn tất cả các kỹ thuật máy học khác trong việc giải bài toán cũ nổi tiếng MNIST chữ số viết tay của Yann Le Cun và các đồng nghiệp tại NYU .\\nCùng lúc đó, cuối năm 2009, học sâu đã thực hiện xâm nhập vào nhận dạng giọng nói, khi được đánh dấu bởi Hội thảo NIPS về học sâu trong nhận dạng giọng nói. Việc tăng cường hợp tác giữa các nhà nghiên cứu của Microsoft Research và đại học Toronto đã chứng minh vào giữa năm 2010 ở Redmond rằng các mạng neuron sâu giao tiếp với một mô hình Markov ẩn với các trạng thái phụ thuộc vào ngữ cảnh xác định lớp đầu ra của mạng neuron có thể giảm mạnh lỗi trong các tác vụ nhận dạng tiếng nói có vốn từ vựng lớn như tìm kiếm qua giọng nói. Cùng một mô hình mạng thần kinh sâu được chỉ ra cho quy mô lên đến các tác vụ cấp Tổng đài khoảng một năm sau đó tại Microsoft Research châu Á.\\nTính đến năm 2011, tiến bộ trong các mạng nuôi tiến học sâu đã thay thế các lớp tích chập và các lớp thăm dò tối da (max-pooling), đứng đầu bởi một số lớp có đầy đủ kết nối hoặc kết nối từng phần theo sau bởi một lớp phân loại cuối cùng. Việc huấn luyện thường được thực hiện mà không có bất kỳ đào tạo trước không có giám sát nào. Từ năm 2011, các thực thi dựa trên GPU của hướng tiếp cận này đã thắng nhiều cuộc thi nhận dạng hình mẫu, bao gồm cuộc thi IJCNN 2011 Traffic Sign Recognition Competition, ISBI 2012 Segmentation of neuronal structures in EM stacks challenge, và các cuộc thi khác.\\nCác phương pháp học sâu có giám sát như vậy cũng đã là bộ nhậng dạng mô hình nhân tạo đầu tiên đạt được hiệu suất có thể cạnh tranh lại được với con người trong những công việc nhất định.\\nĐể vượt qua những rào cản của AI yếu được đại diện bằng học sâu, cần phải để vượt qua các kiến trúc học sâu, bởi vì bộ não sinh học sử dụng cả mạch học nông và học sâu theo báo cáo của ngành giải phẫu não bộ chỉ ra một loạt các tính bất biến. Weng lập luận rằng não tự kết nối chủ yếu theo các thống kê tín hiệu và, do đó, một phân tầng nối tiếp không thể bắt tất cả các vật phụ thuộc thống kê chủ yếu. Các ANN đã có thể đảm bảo sự thay đổi bất biến để đối phó với các đối tượng tự nhiên lớn và nhỏ trong hậu trường có sự xáo trộn lớn, chỉ khi các bất định mở rộng vượt ra ngoài sự thay đổi, tới tất cả các khái niệm ANN đã học được, chẳng hạn như vị trí, loại (nhãn lớp đối tượng), quy mô, ánh sáng. Điều này được thực hiện trong các Mạng Phát triển (DN) có biểu hiện là Where-What Networks, WWN-1 (2008) cho đến WWN-7 (2013).\\n\\nSection Header: Kiến trúc\\nSection Content: Có một lượng rất lớn các biến thể của kiến trúc sâu. Hầu hết chúng là nhánh sinh ra từ một số kiến trúc cha ban đầu. Không phải là luôn luôn có thể so sánh hiệu suất của nhiều kiến trúc cùng với nhau, vì chúng không phải là tất cả đánh giá trên cùng một tập dữ liệu. Học sâu học là một lĩnh vực phát triển nhanh, và các kiến trúc, biến thể, hoặc các thuật toán mới xuất hiện mỗi vài tuần.\\n\\nSection Header: Các mạng neuron sâu\\nSection Content: Mạng neuron sâu (DNN-Deep neural Network) là một mạng neuron nhân tạo (ANN) với nhiều đơn vị lớp ẩn giữa lớp đầu vào và đầu ra. Tương tự như các ANN nông, các DNN nông có thể mô hình mối quan hệ phi tuyến phức tạp. Các kiến trúc DNN, ví dụ như để phát hiện và phân tích đối tượng tạo ra các mô hình hỗn hợp trong đó đối tượng này được thể hiện như một thành phần được xếp lớp của các hình ảnh nguyên thủy. Các lớp phụ cho phép các thành phần của các đặc điểm từ các lớp thấp hơn, đem lại tiềm năng của mô hình hóa dữ liệu phức tạp với các đơn vị ít hơn so với một mạng lưới nông thực hiện tương tự như vậy.\\nCác DNN thường được thiết kế như các mạng nuôi tiến, nhưng nghiên cứu gần đây đã áp dụng thành công kiến trúc học sâu đối với các mạng nơ ron tái phát cho các ứng dụng chẳng hạn như mô hình hóa ngôn ngữ . Các mạng neuron sâu tích chập (CNN) được sử dụng trong thị giác máy tính nơi thành công của chúng đã được ghi nhận. Gần đây hơn, các CNN đã được áp dụng để mô hình hóa âm thanh cho nhận dạng giọng nói tự động (ASR), nơi chúng đã cho thấy sự thành công trong các mô hình trước đó. Để đơn giản, ta hãy nhìn vào việc huấn luyện các DNN được đưa ra ở đây.\\nMột DNN có thể là mô hình biết suy xét được đào tạo với thuật toán truyền ngược tiêu chuẩn. Các bản cập nhật trọng số có thể được thực hiện thông qua độ dốc gradient ngẫu nhiên bằng cách sử dụng phương trình sau:\\nTrong đó, η {\\\\displaystyle \\\\eta } là tốc độ học, và C {\\\\displaystyle C} là hàm chi phí. Việc lựa chọn của hàm chi phí phụ thuộc vào các yếu tố như loại học tập (giám sát, không có giám sát, tăng cường , vv) và hàm kích hoạt . Ví dụ, khi thực hiện học có giám sát về một vấn đề phân loại nhiều lớp , các lựa chọn phổ biến cho hàm kích hoạt và hàm chi phí là hàm softmax (hàm mũ chuẩn hóa) và hàm entropy chéo , tương ứng. Hàm softmax được định nghĩa là p j = exp \\u2061 ( x j ) ∑ k exp \\u2061 ( x k ) {\\\\displaystyle p_{j}={\\\\frac {\\\\exp(x_{j})}{\\\\sum _{k}\\\\exp(x_{k})}}} trong đó p j {\\\\displaystyle p_{j}} thể hiện xác suất của lớp (đầu ra của đơn vị j {\\\\displaystyle j} ) và x j {\\\\displaystyle x_{j}} và x k {\\\\displaystyle x_{k}} hiển thể hiện tổng đầu vào thành các đơn vị j {\\\\displaystyle j} và k {\\\\displaystyle k} của cùng cấp tương ứng. Entropy chéo được định nghĩa là C = − ∑ j d j log \\u2061 ( p j ) {\\\\displaystyle C=-\\\\sum _{j}d_{j}\\\\log(p_{j})} trong đó d j {\\\\displaystyle d_{j}} thể hiện cho xác suất mục tiêu của đơn vị ra j {\\\\displaystyle j} và p j {\\\\displaystyle p_{j}} là đầu ra xác suất cho j {\\\\displaystyle j} sau khi áp dụng hàm kích hoạt.\\nChúng có thể được sử dụng để xuất ra các hộp bao quanh đối tượng trong hình thức của một mặt nạ nhị phân. Chúng cũng được sử dụng cho các hồi quy đa quy mô để tăng độ chính xác của định vị. Hồi qui dựa trên DNN có thể học các đặc điểm mà chụp lại thông tin hình học ngoài việc là một bộ phân loại tốt. Chúng sẽ loại bỏ các giới hạn của việc thiết kế một mô hình mà sẽ chụp lại các bộ phận và quan hệ của chúng một cách rõ ràng. Điều này sẽ giúp học được một loạt các đối tượng rộng lớn. Mô hình này bao gồm nhiều lớp, mỗi trong số đó có một đơn vị chỉnh lại tuyến tính cho các chuyển đổi phi tuyến. Một số lớp là tích chập, trong khi những lớp khác được kết nối đầy đủ. Mỗi lớp tích chập có một thăm dò max bổ sung. Mạng được huấn luyện để giảm thiểu sai số L2 để dự đoán mặt nạ nằm trong dãi qua bộ huấn luyện toàn bộ chứa các hộp đường biên được thể hiện như là mặt nạ.\\nNhư với các ANN, nhiều vấn đề có thể nảy sinh với các DNN nếu chúng được huấn luyện thô sơ. Hai vấn đề phổ biến là overfitting (nhiễu hoặc sai số ngẫu nhiên) và thời gian tính toán.\\nCác DNN có thiên hướng overfitting vì được thêm các lớp trừu tượng, mà cho phép chúng thực hiện mô hình hóa phụ thuộc hiếm hoi vào dữ liệu huấn luyện. Các phương pháp regularization ( quy tắc hóa ) như phân rã trọng số ( ℓ 2 {\\\\displaystyle \\\\ell _{2}} -regularization) hoặc sparsity (rãi) ( ℓ 1 {\\\\displaystyle \\\\ell _{1}} -regularization) có thể được áp dụng trong quá trình huấn luyện để giúp chống lại overfitting. Một phương pháp regularization gần đây được áp dụng cho các DNN là dropout regularization. Trong dropout, một số số lượng đơn vị được bỏ qua ngẫu nhiên từ các lớp ẩn trong quá trình đào tạo. Điều này giúp phá vỡ các phụ thuộc hiếm hoi có thể xảy ra trong dữ liệu đào tạo.\\nPhương pháp chủ đạo cho việc huấn luyện các cấu trúc là sửa lỗi huấn luyện (chẳng hạn như truyền ngược với gradient descent ) do dễ thực hiện và xu hướng hội tụ tốt hơn local optima (tối hưu cục bộ) hơn so với các phương pháp huấn luyện khác. Tuy nhiên, những phương pháp này có thể tốn công tính toán hơn, đặc biệt là cho các DNN. Có rất nhiều tham số huấn luyện để được xem xét với một DNN, chẳng hạn như kích thước (số lượng lớp và số lượng đơn vị trên mỗi lớp), tốc độ học và trọng số ban đầu. Quét thông qua không gian tham số cho các thông số tối ưu có thể không khả thi do chi phí trong thời gian và tài nguyên tính toán. Nhiều \\'mẹo vặt\\' chẳng hạn như bằng cách sử dụng mini-batching (tính toán gradient trên nhiều ví dụ huấn luyện khác nhau cùng một lúc chứ không phải là từng ví dụ một) đã được chỉ ra để tăng tốc độ tính toán. Lượng xử lý lớn thông qua GPU đã tăng tốc đáng kể trong việc huấn luyện, do tính toán ma trận và vector rất thích hợp với các GPU. Lựa chọn thay thế triệt để cho truyền ngược là Extreme Learning Machines (Siêu máy học, các mạng \"No-prop\", huấn luyện không cần truy ngược, các mạng \"không trọng số\", và mạng nơron không kết (non-connectionist neural network) đang thu hút được sự chú ý.\\n\\nSection Header: Mạng niềm tin sâu (Deep belief network)\\nSection Content: Một mạng niềm tin sâu (DBN) là một mô hình xác suất thể sinh , tạo thành bởi nhiều đơn vị ẩn nhiều lớp. Nó có thể được coi là một hàm hợp các mô-đun học đơn giản tạo thành mỗi lớp.\\nMột DBN có thể được sử dụng để huấn luyện trước khả sinh một DNN bằng cách sử dụng các trọng số DBN học như các trọng số DNN ban đầu. Các thuật toán truyền ngược hoặc suy xét khác sau đó có thể được áp dụng để điều chỉnh những trọng số này. Điều này đặc biệt hữu ích khi dữ liệu đào tạo giới hạn là có sẵn, vì các trọng số khởi tạo nghèo nàn có thể cản trở đáng kể hiệu suất của mô hình được học. Các trọng số đào tạo trước này là một vùng không gian trọng số là gần gũi hơn với trọng số tối ưu hơn là các trọng số ban đầu được chọn ngẫu nhiên. Điều này cho phép cả mô hình hóa được cải thiện và hội tụ tinh chỉnh pha nhanh hơn.\\nMột DBN có thể được huấn luyện một cách hiệu quả trong một cách thức không có giám sát, lớp kề lớp, nơi mà các lớp thường được tạo ra từ các máy Boltzmann hạn chế (RBM). Một RBM là một mô hình vô hướng, thể sinh dựa trên năng lượng với một lớp đầu vào \"hiện\" và một ẩn lớp, và các kết nối giữa các lớp nhưng không nằm trong các lớp. Phương pháp huấn luyện cho RBM được đề xuất bởi Geoffrey Hinton để sử dụng với các mô hình \"Product of Expert\" được gọi là tương phản phân kỳ (CD-contrastive divergence). CD cung cấp một xấp xỉ cho phương pháp với khả năng tối đa có vị trí lý tưởng sẽ được áp dụng cho việc học các trọng số của RBM. Trong việc huấn luyện một RBM đơn, các cập nhật trọng số được thực hiện với gradient ascent qua phương trình sau: Δ w i j ( t + 1 ) = w i j ( t ) + η ∂ log \\u2061 ( p ( v ) ) ∂ w i j {\\\\displaystyle \\\\Delta w_{ij}(t+1)=w_{ij}(t)+\\\\eta {\\\\frac {\\\\partial \\\\log(p(v))}{\\\\partial w_{ij}}}} . Trong đó, p ( v ) {\\\\displaystyle p(v)} là xác suất của một vector hiện, được cho bởi p ( v ) = 1 Z ∑ h e − E ( v , h ) {\\\\displaystyle p(v)={\\\\frac {1}{Z}}\\\\sum _{h}e^{-E(v,h)}} . Z {\\\\displaystyle Z} là hàm từng phần, (được sử dụng để chuẩn hóa) và E ( v , h ) {\\\\displaystyle E(v,h)} là hàm năng lượng được gán cho trạng thái của mạng. Một năng lượng thấp hơn chỉ thị mạng đó đang được cấu hình \"đáng mong muốn\" hơn. Gradient ∂ log \\u2061 ( p ( v ) ) ∂ w i j {\\\\displaystyle {\\\\frac {\\\\partial \\\\log(p(v))}{\\\\partial w_{ij}}}} có dạng đơn giản ⟨ v i h j ⟩ data − ⟨ v i h j ⟩ model {\\\\displaystyle \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{data}}-\\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{model}}} trong đó ⟨ ⋯ ⟩ p {\\\\displaystyle \\\\langle \\\\cdots \\\\rangle _{p}} thể hiện các giá trị trung bình đối với phân phối p {\\\\displaystyle p} . Vấn đề này nãy sinh trong việc lấy mẫu ⟨ v i h j ⟩ model {\\\\displaystyle \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{model}}} bởi vì điều này đòi hỏi phải chạy xen kẽ lấy mẫu Gibbs trong một thời gian dài. CD thay thế bwowcs này bằng cách chạy luân phiên lấy mẫu Gibbs cho n {\\\\displaystyle n} bước (giá trị của n = 1 {\\\\displaystyle n=1} được lấy theo kinh nghiệm được chỉ ra là làm việc tốt). Sau n {\\\\displaystyle n} bước, dữ liệu được lấy mẫu và mẫu này sẽ được sử dụng trong ⟨ v i h j ⟩ model {\\\\displaystyle \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{model}}} . Chu trình CD hoạt động như sau:\\nKhởi tạo các đơn vị hiện (visible) tới một vector huấn luyện.\\nCập nhật các đơn vị ẩn song song với các đơn vị hiện: p ( h j = 1 ∣ V ) = σ ( b j + ∑ i v i w i j ) {\\\\displaystyle p(h_{j}=1\\\\mid {\\\\textbf {V}})=\\\\sigma (b_{j}+\\\\sum _{i}v_{i}w_{ij})} . σ {\\\\displaystyle \\\\sigma } là hàm sigmoid và b j {\\\\displaystyle b_{j}} là độ lệch của h j {\\\\displaystyle h_{j}} .\\nCập nhật các đơn vị hiện song song với các đơn vị ẩn đã cho: p ( v i = 1 ∣ H ) = σ ( a i + ∑ j h j w i j ) {\\\\displaystyle p(v_{i}=1\\\\mid {\\\\textbf {H}})=\\\\sigma (a_{i}+\\\\sum _{j}h_{j}w_{ij})} . a i {\\\\displaystyle a_{i}} là độ lệch của v i {\\\\displaystyle v_{i}} . Điều này được gọi là bước \"cải tạo\".\\nTái cập nhật các đơn vị ẩn song song với các đơn vị hiện cải tạo đã cho bằng cách sử dụng phương trình tương tự như trong bước 2.\\nThực hiện cập nhật trọng số: Δ w i j ∝ ⟨ v i h j ⟩ data − ⟨ v i h j ⟩ reconstruction {\\\\displaystyle \\\\Delta w_{ij}\\\\propto \\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{data}}-\\\\langle v_{i}h_{j}\\\\rangle _{\\\\text{reconstruction}}} .\\nKhi một RBM được huấn luyện, RBM khác là \"xếp chồng\" trên nó, đưa đầu vào của nó từ cuối lớp đã được huấn luyện. Lớp hiện mới này được khởi tạo với một vector hiện, và các giá trị cho các đơn vị trong các lớp đã được huấn luyện phân công bằng cách sử dụng trọng số hiện tại và các độ lệch. RBM mới này sau đó lại được huấn luyện với chu trình như trên. Toàn bộ quá trình này được lặp lại cho đến khi một số tiêu chí mong muốn chặn lại được đáp ứng.\\nMặc dù xấp xỉ của CD để tối đa khả năng là rất thô (CD đã được chỉ ra là theo gradient của bất kỳ hàm nào), nó đã được kinh nghiệm chỉ ra là có hiệu quả trong huấn luyện các kiến trúc sâu.\\n\\nSection Header: Mạng nơ ron tích chập (Convolutional neural networks)\\nSection Content: Một CNN gồm có một hoặc nhiều hơn các lớp tích chập với các lớp đầy đủ kết nối (đáp ứng phù hợp với những mạng neuron nhân tạo tiêu biểu) trên đỉnh. Nó cũng sử dụng trọng số gắn liền và các lớp thăm dò. Kiến trúc này cho phép các CNN tận dụng lợi thế của cấu trúc 2D của dữ liệu đầu vào. So với những kiến trúc sâu khác, mạng neuron tích chập đang bắt đầu thể hiện kết quả vượt trội trong các ứng dụng hình ảnh và giọng nói. Chúng cũng có thể được huấn luyện với tiêu chuẩn truyền ngược. CNN dễ dàng được đào tạo hơn các mạng nơ ron sâu nuôi tiến thông thường khác, và có ít thông số ước tính hơn, khiến cho chúng trở thành một kiến trúc rất hấp dẫn để sử dụng. Các ví dụ về ứng dụng trong Thị Giác máy tính bao gồm DeepDream .\\n\\nSection Header: Các mạng niềm tin sâu tích chập\\nSection Content: Sử dụng mạng niềm tin sâu (CDBN) là một thành tựu gần đây của học sâu. Các CDBN có cấu trúc rất giống với một mạng neuron tích chập và được huấn luyện tương tự như các mạng niềm tin sâu. Vì vậy, chúng khai thác cấu trúc 2D của hình ảnh, giống như CNN làm, và làm cho việc sử dụng đào tạo trước giống như mạng niềm tin sâu . Chúng quy định một cấu trúc chung mà có thể được sử dụng trong nhiều tác vụ xử lý hình ảnh và tín hiệu. Gần đây, nhiều kết quả benchmark (tiêu chuẩn) dựa trên tập dữ liệu hình ảnh chuẩn như CIFAR đã được thu được kết quả bằng cách sử dụng CDBN.\\n\\nSection Header: Mạng neuron lưu trữ và truy xuất bộ nhớ lớn\\nSection Content: Mạng nơ ron lưu trữ và truy xuất bộ nhớ lớn (LAMSTAR) là các mạng nơ ron học sâu nhanh gồm nhiều lớp mà có thể sử dụng đồng thời nhiều bộ lọc. Các bộ lọc này có thể là phi tuyến, ngẫu nhiên, logic, không cố định , hoặc thậm chí không có tính phân tích. Chúng là học sinh học năng động và liên tục.\\nMạng neuron LAMSTAR có thể phục vụ như là một mạng nơ ron năng động trong không gian hay miền thời gian, hoặc cả hai. Tốc độ của nó được quy định bởi các liên kết-trọng số Hebbian (chương 9 của D. Graupe, 2013), dùng để tích hợp các bộ lọc khác nhau và thường khác nhau (các hàm tiền xử lý) vào nó nhiều lớp và để xếp hạng năng đọng tầm quan trọng của các lớp khác nhau và các hàm liên quan đến nhiệm vụ nhất định cho việc học sâu. Điều này hiển nhiên bắt chước học sinh học mà tích hợp các bộ tiền lý đầu ra khác nhau ( ốc tai , võng mạc , vv) và vỏ não ( thính giác , thị giác , vv) và của các vùng khác nhau của chúng. Khả năng học sâu của nó tăng cường hơn nữa bằng cách sử dụng sự ức chế, sự tương quan và bởi khả năng đối phó với dữ liệu không đầy đủ của nó, hoặc \"mất\" nơ ron hoặc lớp ngay cả khi đang thực thi một tác vụ. Hơn nữa, nó hoàn toàn minh bạch do trọng số liên kết của nó. Các trọng số liên kết cho phép xác định năng động sáng tạo và thừa thải, và tạo thuận lợi cho việc xếp hạng của các lớp, các bộ lọc hoặc các nơ ron đơn lẽ tương ứng với một nhiệm vụ.\\nLAMSTAR đã được áp dụng cho nhiều dự đoán y tế và tài chính (xem Graupe, 2013 Phần 9C), bộ lọc thích nghi nhiễu nhận dạng giọng nói với tiếng ồn không xác định, nhận dạng ảnh tĩnh (Graupe, 2013 Phần 9D), nhận dạng ảnh video, bảo mật phần mềm, điều khiển thích nghi của các hệ thống phi tuyến, vv. LAMSTAR có tốc độ tính toán nhanh hơn nhiều và có lỗi hơi ít hơn so với một mạng nơ ron tích chập dựa trên các bộ lọc hàm- ReLU và thăm dò max, trong một nghiên cứu nhận dạng ký tự so sánh.\\nCác ứng dụng này chứng minh đào sâu vào các khía cạnh của các dữ liệu đó là bị ẩn từ các mạng học nông hoặc thậm chí từ những giác quan của con người (mắt, tai), chẳng hạn như trong trường hợp của dự đoán sự bắt đầu của hiện tượng ngưng thở khi ngủ , của một biểu đồ điện tâm đồ một thai nhi như được ghi chép từ các điện cực gắn trên da được đặt trên bụng người mẹ trong thời gian đầu của thai kỳ, của dự đoán tài chính (Phần 9C trong Graupe, 2013), hoặc trong lọc mù của nhiễu trong nhận dạng giọng nói\\nLAMSTAR đã được đề xuất năm 1996 ( Bằng phát minh 5,920,852 A của Mỹ ) và tiếp tục được phát triển bởi D Graupe và H Kordylewski vào năm 1997-2002. Một phiên bản sửa đổi, được gọi là LAMSTAR 2, được phát triển bởi N C Schneider và D Graupe trong năm 2008.\\n\\nSection Header: Các mạng xếp chồng sâu\\nSection Content: Một kiến trúc sâu dựa trên một hệ thống phân cấp của các khối mô-đun mạng neuron đơn giản là một mạng sâu lồi, được giới thiệu vào năm 2011. Ở đây, bài toán học các trọng số được xây dựng như một bài toán tối ưu hóa lồi với lời giải dạng đóng . Kiến trúc này còn được gọi là một mạng xếp chồng sâu (DSN), nhấn mạnh các cơ chế tương tự với tổng quát hóa xếp chồng. Mỗi khối DSN là một module đơn giản đó là dễ dàng để huấn luyện chính nó trong một kiểu có giám sát mà không cần truyền ngược cho toàn bộ các khối.\\n\\nSection Header: Mạng lập trình sâu (deep coding network)\\nSection Content: Có những lợi thế của một mô hình mà có thể chủ động cập nhật bản thân từ ngữ cảnh trong dữ liệu. Mạng lập trình (DPCN) là một chương trình lập trình tiên đoán , trong đó thông tin từ trên xuống được sử dụng để điều chỉnh theo kinh nghiệm của những cái trước đó cần thiết cho một thủ tục suy luận từ dưới lên bằng các phương tiện của một mô hình thể sinh kết nối cục bộ sâu. Điều này hoạt động bằng cách chiết tách các đặc điểm rời rạc các quan sát biến đổi theo thời gian bằng cách sử dụng một mô hình động học tuyến tính. Sau đó, một chiến lược thăm dò được sử dụng để học các đại diện đặc điểm bất biến. Các đơn vị này tập hợp lại để tạo thành một kiến trúc sâu và được huấn luyện bởi học không giám sát layer-wise tham lam . Các lớp tạo thành một loại xích Markov mà các trạng thái tại bất kỳ lớp nào cũng chỉ phụ thuộc vào các lớp trước và các lớp sau (kế thừa).\\nMạng lập tình dự đoán sâu (DPCN) dự đoán đại diện của lớp, bằng cách sử dụng một cách tiếp cận từ trên xuống bằng cách sử dụng thông tin ở lớp trên và các phụ thuộc thời gian từ các trạng thái trước đó.\\nDPCN có thể được mở rộng để tạo thành một mạng tích chập .\\n\\nSection Header: Mạng bộ nhớ\\nSection Content: Bộ nhớ ngoài tích hợp với các mạng neuron nhân tạo tính đến nghiên cứu đầu tiên trrong đại diện phân phối và các bản đồ tự tổ chức . Ví dụ, trong bộ nhớ phân tán hoặc bộ nhớ phân cấp thời gian , các mô hình được mã hóa bởi các mạng neuron được sử dụng như là các địa chỉ cho bộ nhớ có khả năng định địa chỉ nội dung , với các \"nơ ron\" chủ yếu phục vụ như là các bộ mã hóa và giải mã.\\nTrong thập niên 1990 và thập niên 2000, đã có nhiều công trình liên quan đến bộ nhớ ngắn-hạn dài (LSTM - thêm bộ nhớ khả vi cho các hàm hồi qui). Ví dụ:\\nCác hành động đẩy và lấy ra khả vi cho các mạng bộ nhớ thay thế được gọi là các máy ngăn xếp nơ ron\\nMemory networks where the control network\\'s external differentiable storage is in the fast weights of another network\\nLSTM \"forget gates\"\\nSelf-referential recurrent neural networks (RNNs) with special output units for addressing and rapidly manipulating each of the RNN\\'s own weights in differentiable fashion (internal storage)\\nLearning to transduce with unbounded memory\\nCác mạng bộ nhớ một mở rộng khác của các mạng nơ ron nhân tạo kết hợp với bộ nhớ dài hạn , được phát triển bởi nhóm nghiên cứu Facebook . Bộ nhớ dài hạn có thể được đọc và ghi vào đó, với mục đích sử dụng cho việc dự báo. Các mô hình này đã được áp dụng trong bối cảnh hỏi đáp (QA) nơi bộ nhớ dài hạn hoạt động hiệu quả như một cơ sở kiến thức (năng động), và đầu ra là một đáp ứng văn bản.\\nMột framework mã hóa-giải mã là một framework dựa trên các mạng neuron nhằm mục đích lập bản đồ đầu vào cấu trúc cao tới đầu ra có cấu trúc cao. Nó đã được đề xuất gần đây trong bối cảnh của máy dịch , trong đó đầu vào và đầu ra được viết thành câu bằng hai ngôn ngữ tự nhiên. Trong đó, một mạng nơ ron tái phát (RNN) hoặc mạng neuron tích chập (CNN) được sử dụng như một bộ mã hóa để tóm tắt một câu nguồn và tóm tắt này được giải mã bằng cách sử dụng một mô hình ngôn ngữ mạng neuron tái phát có điều kiện để tạo ra bản dịch. Tất cả các hệ thống này có các khối xây dựng tương tự: cổng RNN và CNN, và các cơ chế tập trung được huấn luyện.\\n\\nSection Header: Xử lý ngôn ngữ tự nhiên (Nature Language Processing)\\nSection Content: Hiện nay các mô hình transformer base đã vượt xa các loại mô hình sử dụng RNN. Hầu như trong tất cả các tác vụ Transformer base model đều vượt trội hơn các RNN model (LSTM or GRU base). Với Hugging face Hugging Face Hub chúng ta có thể dễ dàng fine turn model🤗.\\nMột trong những nguyên tắc cơ bản của học sâu là để thoát khỏi kỹ thuật đặc tính thủ công và sử dụng các đặc tính thô. Nguyên tắc này được khám phá thành công đầu tiên trong kiến trúc của tự mã hóa sâu trên ảnh phổ \"thô\" hoặc các đặc điểm dãi lọc tuyến tính, hiển thị sự vượt trội của nó hơn các tính năng Mel-Cepstral mà có chứa một vài giai đoạn chuyển đổi cố định từ ảnh phổ. Các tính năng thực sự \"thô\" của tiếng nói, dạng sóng , gần đây đã được chỉ ra để tạo ra các kết quả nhận dạng giọng nói tuyệt vời ở quy mô lớn.\\nKể từ khi ra mắt thành công ban đầu của DNN cho nhận dạng tiếng nói khoảng 2009-2011, tiến độ (và hướng đi trong tương lai) có thể được tóm tắt vào 8 lĩnh vực chính:\\nMở rộng quy mô lên/ra và tăng tốc quá trình đào tạo và giải mã DNN;\\nHuấn luyện suy luận có trình tự cho các DNN;\\nXử lý đặc điểm bởi các mô hình sâu với sự hiểu biết vững chắc các cơ chế tiềm ẩn;\\nThích nghi của các DNN và các mô hình sâu có liên quan;\\nHọc đa tác vụ và học có chuyển giao bởi các DNN và các mô hình sâu liên quan; Các mạng neuron tích chập và làm thế nào để thiết kế chúng để khai thác tốt nhất kiến thức miền của giọng nói;\\nMạng neuron tái phát và các biến thể giàu LSTM;\\nCác loại mô hình sâu bao gồm các mô hình dựa trên tensor và các mô hình tích hợp sâu thể sinh/suy xét.\\nTrường hợp nhận dạng tiếng nói tự động quy mô lớn lần đầu tiên và thuyết phục nhất thành công của học sâu trong lịch sử gần đây, chấp nhận bở cả công nghiệp và hàn lâm trong tất cả các lĩnh vực. Từ năm 2010 đến năm 2014, hai hội nghị lớn về xử lý tín hiệu và nhận dạng giọng nói, IEEE-ICASSP và Interspeech, đã thấy một sự gia tăng lớn các báo cáo được chấp nhận trong các báo cáo hội nghị thường niên tương ứng về chủ đề học sâu trong nhận dạng giọng nói. Quan trọng hơn, tất cả các hệ thống nhận dạng giọng nói thương mại chính (ví dụ: Microsoft Cortana, Xbox, Skype Translator, Google Now, Apple Siri, Baidu và iFlyTek tìm kiếm bằng giọng nói và một loạt các sản phẩm của Nuance speech, vv) được dựa trên phương pháp học sâu. Xem thêm các cuộc phỏng vấn trên phương tiện truyền thông với CTO của Nuance Communications.\\nThành công lây lan rộng trong nhận dạng tiếng nói đã đạt được vào năm 2011 được kế tiếp liền sau đó là nhận dạng hình ảnh ở quy mô lớn.\\n\\nSection Header: Nhận dạng hình ảnh\\nSection Content: Một tập đánh giá phổ biến cho phân loại hình ảnh là tập hợp dữ liệu cơ sở dữ liệu MNIST . MNIST bao gồm các chữ số viết tay và bao gồm 60000 ví dụ huấn luyện và 10000 ví dụ kiểm tra. Như TIMIT, kích thước nhỏ của nó cho phép nhiều cấu hình được kiểm tra. Một danh sách đầy đủ các kết quả trên tập này có thể được tìm thấy trong. Kết quả tốt nhất hiện nay trên MNIST là tỷ lệ lỗi 0,23%, đạt được bởi Ciresan và các cộng sự vào năm 2012.\\nTác động thực sự của học sâu trong nhận dạng hình ảnh hoặc đối tượng, một chi chính của thị giác máy tính, đã cảm thấy được vào mùa thu năm 2012 sau khi đội của Geoff Hinton và sinh viên của ông thắng trong cuộc thi quy mô lớn ImageNet bởi một biên độ đáng kể bằng phương pháp máy học nông tiên tiến nhất. Công nghệ này dựa trên các mạng tích chập sâu 20 tuổi, nhưng với quy mô lớn hơn nhiều trên một nhiệm vụ lớn hơn nhiều, vì nó đã học được rằng học sâu làm việc tốt đối nhận dạng giọng nói quy mô lớn. Trong năm 2013 và 2014, tỷ lệ lỗi trong tác vụ của ImageNet bằng cách sử dụng học sâu tiếp tục giảm xuống nhanh chóng, theo một xu hướng tương tự trong nhận dạng giọng nói quy mô lớn.\\nKhi tham vọng này di chuyển từ nhận dạng giọng nói tự động sang các bản dịch giọng nói tự động và hiểu được, phân loại hình ảnh gần đây đã được mở rộng với nhiệm vụ khó khăn hơn đó là tạo phụ đề cho hình ảnh tự động, trong đó có học sâu là công nghệ cơ bản thiết yếu.\\nMột ứng dụng ví dụ là một máy tính xe hơi cho biết được đào tạo bằng học sâu, có thể cho phép xe diễn giải các hình ảnh 360° từ camera. Một ví dụ khác là công nghệ được gọi là Facial Dysmorphology Novel Analysis (FDNA) -(Phân tích các dị tật của khuôn mặt) sử dụng để phân tích các trường hợp dị dạng của con người kết nối với cơ sở dữ liệu lớn của các hội chứng di truyền.\\n\\nSection Header: Xử lý ngôn ngữ tự nhiên\\nSection Content: Mạng neuron đã được sử dụng cho việc thực hiện các mô hình ngôn ngữ kể từ đầu những năm 2000. Các kỹ thuật quan trọng trong lĩnh vực này là lấy mẫu âm và nhúng từ (word embedding). Nhúng chữ, chẳng hạn như word2vec, có thể được dùng như một lớp đại diện trong một kiến trúc học sâu, điều này sẽ biến đổi một từ đơn thành một đại diện vị trí của từ đó liên quan đến các từ khác trong bộ dữ liệu; vị trí được đại diện như là một điểm trong một không gian vector . Sử dụng một từ nhúng như là một lớp đầu vào với một mạng lưới thần kinh đệ quy (RNN-recursive neuron network) cho phép đào tạo mạng để phân tích cú pháp câu và cụm từ bằng cách sử dụng một ngữ pháp vector tổng hợp có hiệu quả. Một ngữ pháp vector tổng hợp có thể được coi là ngữ pháp không phụ thuộc ngữ cảnh xác suất (PCFG-probabilistic context free grammar) được thực hiện bởi một mạng thần kinh đệ quy. Tự động-mã hóa đệ qui được xây dựng trên đỉnh từ nhúng đã được đào tạo để đánh giá câu tương tự và phát hiện các chú giải dài dòng. Các kiến trúc thần kinh sâu đã đạt được những kết quả tiên tiến nhất trong nhiều tác vụ xử lý ngôn ngữ tự nhiên như phân tích thống kê , phân tích tình cảm, tra cứu thông tin, dịch máy, liên kết thực thể ngữ cảnh, và.v.v.\\n\\nSection Header: Khám phá dược phẩm và độc chất học\\nSection Content: Ngành công nghiệp dược phẩm phải đối mặt với vấn đề mà một tỷ lệ lớn các loại thuốc tiềm năng thất bại khi tiếp cận với thị trường. Những thất bại của các hợp chất hóa học này gây ra bởi không đủ hiệu quả trên mục tiêu phân tử sinh học (có hiệu lực với mục tiêu), có các tương tác không bị phát hiện và không mong muốn với các phân tử sinh học khác (chệch mục tiêu tác động), hoặc các hiệu ứng độc dược ngoài dự tính. Trong năm 2012, một nhóm dẫn đầu bởi George Dahl đã chiến thắng \"Merck Molecular Activity Challenge\" sử dụng các mạng neuron sâu đa tác vụ để dự đoán mục tiêu phân tử sinh học của một hợp chất. Trong năm 2014, nhóm của Sepp Hochreiter sử dụng học sâu để phát hiện ra mục tiêu lạ và các ảnh hưởng độc dược của các môi trường hóa chất trong các chất dinh dưỡng, sản phẩm gia dụng và thuốc men và đã chiến thắng \"Tox21 Data Challenge\" của NIH , FDA và NCATS . Những thành công ấn tượng chỉ ra rằng học sâu có thể vượt trội so với các phương pháp kiểm tra ảo khác. Các nhà nghiên cứu đến từ Google và Stanford đã mở rộng học sâu để khám phá dược phẩm bằng cách kết hợp dữ liệu từ nhiều nguồn khác nhau. Năm 2015, Atomwise giới thiệu AtomNet, mạng neuron học sâu đầu tiên dành cho thiết kế dược phẩm dựa trên cấu trúc hợp lý. Sau đó, AtomNet đã được sử dụng để dự đoán các phân tử sinh học được chọn mới lạ đối với nhiều mục tiêu bệnh tật, đặc biệt là phương pháp điều trị bệnh do virus Ebola và bệnh đa xơ cứng.\\n\\nSection Header: Quản lý quan hệ khách hàng (CRM)\\nSection Content: Thành công gần đây đã được báo cáo với ứng dụng của học tăng cường sâu trong các thiết lập tiếp thị trực tiếp, thể hiện sự phù hợp của phương pháp này dành cho tự động hóa CRM . Một mạng nơ ron được sử dụng để ước tính giá trị của các hành động có thể trực tiếp tiếp thị trên không gian trạng thái khách hàng, được định nghĩa trong điều khoản của biến RFM . Hàm giá trị ước tính được chỉ ra để có một giải thích tự nhiên như là giá trị khách hàng suốt đời .\\n\\nSection Header: Các hệ thống khuyến cáo (gợi ý)\\nSection Content: Các hệ thống khuyến cáo đã sử dụng học sâu để trích xuất các đặc điểm sâu có ý nghĩa cho mô hình yếu tố tiềm ẩn đối với khuyến cáo dựa trên nội dung cho âm nhạc. Gần đây, một cách tiếp cận tổng quát hơn cho việc học tập sở thích người dùng từ nhiều miền bằng cách sử dụng học sâu đa góc nhìn đã được đưa ra. Mô hình này sử dụng một cộng tác lai và tiếp cận dựa trên nội dung và tăng cường các khuyến nghị trong nhiều nhiệm vụ.\\n\\nSection Header: Tin sinh học\\nSection Content: Gần đây, một cách tiếp cận học sâu dựa trên một mạng neuron nhân tạo tự mã hóa đã được sử dụng trong tin sinh học , để dự đoán các mối quan hệ chức năng gen và các chú thích Bản thể gen .\\n\\nSection Header: Lý thuyết về bộ não con người\\nSection Content: Tính toán học sâu có liên hệ chặt chẽ đến học thuyết về sự phát triển của não bộ (cụ thể, phát triển neocortical) do các nhà khoa học thần kinh nhận thức đề xuất trong đầu thập niên 1990. Một bản tóm tắt dễ tiếp cận của ý tưởng này là tác phẩm của Elman và các cộng sự vào năm 1996 \"Xem xét lại Tính bẩm sinh\" (Xem thêm: Shrager và Johnson; Quartz và Sejnowski). Những lý thuyết phát triển này cũng được thuyết minh cụ thể trong các mô hình tính toán, chúng là những kỹ thuật tiền nhiệm của các mô hình học sâu được thúc đẩy bởi tính toán (bằng máy tính) đơn thuần. Những mô hình phát triển này chia sẻ thuộc tính thú vị mà nhiều động lực học (learning dynamics) khác nhau được đề xuất trong nghiên cứu não bộ (Ví dụ, một làn sóng của yếu tố tăng trưởng thần kinh ) để hỗ trợ việc tự tổ chức của các loại mạng nơ ron có liên quan với nhau được sử dụng trong các mô hình học sâu thuần tính toán sau đó; và các mạng neuron tính toán như vậy có vẻ tương tự như quan điểm của ngành nghiên cứu vỏ não mới như một hệ thống phân cấp của bộ lọc trong đó mỗi lớp chụp một số thông tin trong môi trường hoạt động, và sau đó đi qua phần còn lại, cũng như tín hiệu cơ bản được sửa đổi, tới các lớp khác cao hơn trong hệ thống phân cấp. Quá trình này mang lại một chồng tự tổ chức các cảm biến, cũng như điều chỉnh để hoạt động môi trường của họ. Như được mô tả trên tờ New York Times vào năm 1995: \"...bộ não của những trẻ sơ sinh dường như tự tổ chức riêng chính nó dưới ảnh hưởng của các sóng của cái gọi là các yếu tố - dinh dưỡng... các khu vực khác nhau của não trở nên kết nối tuần tự, với một lớp mô trưởng thành trước các mô khác và cho đến khi toàn bộ não là trưởng thành.\"\\nTầm quan trọng của học sâu đối với sự tiến hóa và phát triển của nhận thức của con người đã không thoát khỏi sự chú ý của các nhà nghiên cứu. Một khía cạnh của phát triển con người là phân biệt chúng ta với những người hàng xóm trong họ linh trưởng gần nhất của mình có thể thay đổi trong thời gian phát triển. Trong số các loài linh trưởng , bộ não con người vẫn còn tương đối mềm dẻo cho đến cuối thời kỳ sau khi sinh, trong khi bộ não của họ hàng gần gũi nhất của chúng ta hoàn toàn cố định hơn ngay sau khi sinh. Vì vậy, con người có khả năng truy cập lớn hơn vào những kinh nghiệm phức tạp đang diễn ra trên thế giới trong giai đoạn hình thành nhất của sự phát triển não bộ. Điều này có thể cho phép chúng ta \"điều chỉnh\" để thay đổi nhanh chóng môi trường mà các động vật khác, nhiều bị hạn chế bởi cơ cấu tiến hóa của bộ não của chúng, không thể để thực hiện được. Đến mức mà những thay đổi này được phản ánh trong các thay đổi thời gian tương tự trong sóng được giả thuyết của sự phát triển vỏ não, chúng cũng có thể dẫn đến những thay đổi trong việc khai thác thông tin từ môi trường kích thích trong thời gian đầu tự tổ chức của bộ não. Tất nhiên, cùng với tính linh hoạt này đến một giai đoạn kéo dài chưa thành thục, trong đó chúng ta phụ thuộc vào người chăm sóc và cộng đồng của mình để hỗ trợ và đào tạo. Lý thuyết của học sâu do đó thấy sự cùng tiến hóa đồng thời của văn hóa và nhận thức như là một điều kiện cơ bản của sự tiến hóa của con người.\\n\\nSection Header: Hoạt động thương mại\\nSection Content: Hầu hết các công ty công nghệ lớn nhất trên thế giới đang đầu tư rất nhiều nguồn lực vào nghiên cứu và phát triển để tiếp tục cải tiến công nghệ lõi cũng như tạo ra các sản phẩm ứng dụng sử dụng kỹ thuật học sâu. Điển hình là nhóm nghiên cứu về trí tuệ nhân tạo của Facebook đã tạo ra phần mềm DeepFace có khả năng nhận dạng khuôn mặt tốt như con người với độ chính xác khoảng 97,35%. Công trình này (công bố năm 2014) sử dụng 4 triệu ảnh khuôn mặt của hơn 4000 người để huấn luyện cho mạng nơron nhiều lớp và mô hình thu được đã vượt qua các kỹ thuật được nghiên cứu đề xuất trước đó. \\nHọc sâu thường được trình bày như là một bước hướng tới AI mạnh và do đó nhiều tổ chức đã trở nên quan tâm đến việc sử dụng nó cho các ứng dụng cụ thể. Vào tháng 12 năm 2013, Facebook đã tuyển Yann Le Cun đứng đầu phòng thí nghiệm trí tuệ nhân tạo (AI) mới của họ hoạt động ở California, London và New York. Phòng thí nghiệm AI này sẽ phát triển những kỹ thuật học sâu để giúp Facebook thực hiện các nhiệm vụ, chẳng hạn như tính năng gắn thẻ tự động hình ảnh tải lên với tên của những người có mặt trong đó. Vào cuối năm 2014, Facebook cũng tuyển Vladimir Vapnik , nhà phát triển chính của lý thuyết Vapnik-Chervonenkis về học thống kê, và đồng phát minh ra phương pháp máy vector hỗ trợ .\\nVào tháng 3 năm 2013, Google tuyển Geoffrey Hinton và hai sinh viên tốt nghiệp của ông, Alex Krizhevsky và Ilya Sutskever. Công việc của họ là tập trung vào vừa cải tiến các sản phẩm học máy hiện có của Google và vừa trợ giúp đối phó với lượng dữ liệu ngày càng tăng nhanh mà Google có được. Google cũng mua lại công ty của Hinton, DNNresearch.\\nNăm 2014, Google cũng đã mua DeepMind Technologies , một công ty khởi nghiệp của Anh đã phát triển một hệ thống có khả năng học tập làm thế nào để chơi trò chơi điện tử Atari chỉ sử dụng các điểm ảnh thô là dữ liệu đầu vào. Trong năm 2015, họ đã chứng minh hệ thống AlphaGo đã đạt được một trong những \"thách thức lớn\" trong thời gian dài của AI bằng cách học trò chơi Cờ vây đủ tốt để đánh bại một người chơi Cờ vây chuyên nghiệp.\\nBaidu đã thuê Andrew Ng để lãnh đạo phòng thí nghiệm nghiên cứu của mình đặt trụ sở tại thung lũng Silicon mới tập trung vào học sâu.\\n\\nSection Header: Phê bình và đánh giá\\nSection Content: neural Designer — Một ứng dụng GUI cho mạng neuron sâu cung cấp song song hóa với CPU.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data_cleaned = [clean_text(item) for item in wiki_data]\n",
    "\n",
    "wiki_data_cleaned[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178715ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sections",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "821be7ba-38af-4834-9836-845a1af15e35",
       "rows": [
        [
         "0",
         "Công an Hà Nội khuyến cáo người dân không tham gia một giải chạy do chưa đủ điều kiện pháp lý",
         "[{'header': 'Để bảo đảm an toàn cho bản thân và tuân thủ các quy định của pháp luật, Công an Thành phố Hà Nội khuyến cáo người dân không tham gia Giải chạy \"Mỹ Đình Half Marathon 2025\" vào ngày 28/9/2025.', 'content': 'Giải chạy \"Mỹ Đình Half Marathon 2025\" dự kiến diễn ra vào ngày 28/9/2025 tại khu vực Sân vận động Quốc gia Mỹ Đình chưa đủ điều kiện pháp lý để tổ chức. Ảnh minh họa '}, {'header': 'Giải chạy \"Mỹ Đình Half Marathon 2025\" chưa được chấp thuận về mặt chuyên môn và chưa được chấp thuận chủ trương tổ chức', 'content': 'Công an thành phố Hà Nội thông tin, qua công tác nắm tình hình, phòng An ninh chính trị nội bộ Công an thành phố Hà Nội phát hiện giải chạy \"Mỹ Đình Half Marathon 2025\" dự kiến diễn ra vào ngày 28/9/2025 tại khu vực Sân vận động Quốc gia Mỹ Đình chưa đủ điều kiện pháp lý để tổ chức. Cụ thể đến thời điểm hiện tại, Công ty Cổ phần Di sản Văn hóa, Thể thao Việt Nam vẫn chưa được Sở Văn hóa Thể thao Hà Nội chấp thuận về mặt chuyên môn và chưa được Ủy ban nhân dân Thành phố Hà Nội chấp thuận chủ trương tổ chức. \\u200e\\u200ePhòng An ninh chính trị nội bộ đã phối hợp với công an phường Từ Liêm yêu cầu đơn vị tổ chức là công ty Cổ phần Di sản Văn hoá, Thể thao Việt Nam không được tổ chức giải chạy khi chưa đầy đủ giấy tờ pháp lý theo quy định. \\u200e\\u200eĐể bảo đảm an toàn cho bản thân và tuân thủ các quy định của pháp luật, Công an Thành phố Hà Nội khuyến cáo người dân không tham gia Giải chạy \"Mỹ Đình Half Marathon 2025\" vào ngày 28/9/2025. Đồng thời, khi tham gia giải chạy của các tổ chức, cá nhân phải tìm hiểu kỹ thông tin, chỉ nên tham gia khi giải chạy đã bảo đảm đầy đủ thủ tục pháp lý theo quy định. '}]"
        ],
        [
         "1",
         "Ngừng tiếp thu tàu bay tại một số Cảng hàng không do ảnh hưởng bão số 10 (bão Bualoi)",
         "[{'header': 'Cục Hàng không Việt Nam vừa chỉ đạo phát thông báo tin tức hàng không về việc ngừng tiếp thu tàu bay tại các Cảng hàng không, sân bay nhằm chủ động ứng phó cơn bão số 10 (cơn bão Bualoi).', 'content': 'Cảng hàng không Thọ Xuân là một trong những Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10. Ảnh minh họa '}, {'header': 'Các Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10', 'content': 'Theo Cục Hàng không Việt Nam, các Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10 gồm : Cảng hàng không Thọ Xuân, Cảng hàng không Vinh, Cảng hàng không Đồng Hới. Riêng Cảng Hàng không quốc tế Phú Bài, Đà Nẵng dự kiến sẽ chịu tác động gió giật sớm do hoàn lưu bão gây ra. Các Cảng Hàng không quốc tế: Nội Bài, Vân Đồn, Cát Bi và Cảng hàng không Chu Lai chủ động cập nhật thông tin, đề phòng khi bão có diễn biến bất thường. Đối với Cảng Hàng không quốc tế Vân Đồn và các Cảng hàng không trực thuộc Tổng công ty Cảng hàng không Việt Nam trong vùng ảnh hưởng của bão số 10 , Cục Hàng không Việt Nam yêu cầu các đơn vị chủ trì, phối hợp với các cơ quan, đơn vị liên quan kiểm tra hệ thống kết cấu hạ tầng cảng hàng không, hệ thống thông tin liên lạc... để kịp thời phát hiện và xử lý các hư hỏng (nếu có) nhằm bảo đảm an toàn cho các công trình, đài trạm, đảm bảo an toàn cho hoạt động khai thác tại cảng hàng không, sân bay. Đồng thời triển khai phương án phòng chống mưa, bão, các biện pháp phòng chống ngập úng, khơi thông dòng chảy trong cảng hàng không, sân bay, bảo vệ cho các công trình, phương tiện, thiết bị tại cảng hàng không, hạn chế thiệt hại do mưa, bão gây ra đến mức thấp nhất và nhanh chóng ổn định mọi hoạt động hàng không phục vụ các nhu cầu của hành khách. Đối với các Cảng hàng không đang triển khai thi công xây dựng công trình (Cảng Hàng không quốc tế Cát Bi, Cảng hàng không Vinh, Cảng hàng không Đồng Hới): chủ đầu tư yêu cầu các nhà thầu thi công triển khai ngay công tác ứng phó bão; xác định các điểm dừng kỹ thuật để dừng thi công theo tình hình diễn biến của bão; chuẩn bị các điều kiện để kịp thời khắc phục các sự cố công trình, đảm bảo an toàn, hạn chế thiệt hại do bão gây ra. Ngoài ra, bố trí trực 24/24h, chủ động cập nhật thông tin khí tượng để kịp thời đề xuất phương án khai thác phù hợp, an toàn. Cục Hàng không Việt Nam cũng lưu ý các đơn vị sau khi bão suy yếu và đổ bộ vào đất liền có khả năng nguy cơ gây mưa sau bão. Đối với Tổng công ty Quản lý bay Việt Nam (VATM) , Cục Hàng không Việt Nam yêu cầu VATM chỉ đạo các cơ sở cung cấp dịch vụ khí tượng hàng không tăng cường công tác đảm bảo chất lượng thông tin khí tượng; liên tục theo dõi tình hình thời tiết trong khu vực trách nhiệm, cập nhật các bản tin dự báo, cảnh báo; cung cấp đầy đủ kịp thời thông tin quan trắc, dự báo, cảnh báo tới người dùng. Đối với các Hãng hàng không, các cơ sở cung cấp dịch vụ bảo đảm hoạt động bay , Cục Hàng không Việt Nam yêu cầu các đơn vị tăng cường công tác phối hợp; theo dõi chặt chẽ diễn biến của bão số 10 để có phương án điều chỉnh kế hoạch bay hoặc thay đổi lịch bay cho phù hợp và đảm bảo an toàn cho hoạt động bay. Ngoài ra, cần cập nhật đầy đủ thông tin khí tượng từ các cơ sở khí tượng hàng không liên quan và căn cứ tình hình thực tế để triển khai các hành động ứng phó cần thiết, giảm thiểu tác động đến khai thác, đảm bảo an toàn hoạt động bay, bảo vệ người và tài sản của đơn vị trước thiên tai. Đối với các Cảng vụ hàng không: miền Bắc, miền Trung , Cục yêu cầu các Cảng vụ giám sát công tác triển khai các nội dung ứng phó tại các cảng hàng không liên quan; bảo đảm liên lạc thông suốt với Ban Chỉ huy PCTT&TKCN Cục Hàng không Việt Nam và các cơ quan, đơn vị liên quan trong phạm vi trách nhiệm để triển khai ứng phó trong mọi tình huống. Cục Hàng không Việt Nam chỉ đạo phát thông báo tin tức hàng không về việc ngừng tiếp thu tàu bay tại các Cảng hàng không, sân bay (theo giờ địa phương) như sau: Cảng hàng không Đồng Hới: ngừng tiếp thu tàu bay từ 13h00 -22h00 ngày 28/9/2025; Cảng hàng không Thọ Xuân: ngừng tiếp thu tàu bay từ 22h00 ngày 28/9/2025 đến 7h00 ngày 29/9/2025. Cảng Hàng không quốc tế Phú Bài, ngừng tiếp thu tàu bay từ 08h00-14h00 ngày 28/9. Cảng Hàng không quốc tế Đà Nẵng: ngừng tiếp thu tàu bay từ 06h-11h00 ngày 28/9. Cục Hàng không Việt Nam yêu cầu các cơ quan, đơn vị nghiêm túc thực hiện các nội dung trên và báo cáo mọi diễn biến có liên quan về Cục Hàng không Việt Nam để có những chỉ đạo kịp thời. '}]"
        ],
        [
         "2",
         "440 đại biểu ưu tú dự Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I",
         "[{'header': 'Chiều ngày 27/9, Tỉnh ủy Lào Cai tổ chức họp báo, thông tin về Đại hội Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I, nhiệm kỳ 2025-2030. Đồng chí Giàng Thị Dung – Phó Bí thư Tỉnh ủy Lào Cai chủ trì họp báo.', 'content': 'Trung tâm Hội nghị tỉnh Lào Cai , nơi sẽ diễn ra Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I. Ảnh: Quốc Hồng Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I sẽ khai mạc sáng ngày 28/9/2025 Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I, nhiệm kỳ 2025-2030 diễn ra trong 3 ngày, 28 - 30/9, tại Trung tâm Hội nghị tỉnh Lào Cai, trên địa bàn phường Yên Bái. Đại hội có 440 đại biểu chính thức, đại diện cho 119.000 Đảng viên, thuộc 103 đảng bộ trực thuộc Tỉnh ủy. Đây cũng là kỳ Đại hội đầu tiên sau hợp nhất tỉnh Lào Cai và tỉnh Yên Bái, thành phố, khi diện tích tự nhiên hơn 13.256km2, quy mô dân số hơn 1,7 triệu người, gồm 99 xã, phường chính thức được thành lập và đi vào hoạt động theo mô hình chính quyền địa phương 2 cấp. Lào Cai có qui mô kinh tế đứng thứ 25, dân số đứng thứ 26 và diện tích tự nhiên đứng thứ 8 cả nước. Tại họp báo, ông Dương Đức Huy - Trưởng Ban Tuyên giáo và Dân vận tỉnh Lào Cai cho biết, công tác chuẩn bị Đại hội đã được triển khai khẩn trương, khoa học, chuyên nghiệp. Các Tiểu ban Văn kiện, Nhân sự, Tổ chức phục vụ Đại hội bám sát kế hoạch, phân công rõ nhiệm vụ cho từng cơ quan, đơn vị. Các văn kiện được chuẩn bị kỹ lưỡng, qua nhiều vòng thảo luận, lấy ý kiến rộng rãi từ cán bộ, đảng viên và nhân dân. Báo cáo chính trị đã hoàn thiện sau 9 lần dự thảo, Báo cáo kiểm điểm và Nghị quyết được chỉnh sửa qua nhiều lần dự thảo. Tỉnh ủy Lào Cai cũng chủ động xây dựng dự thảo Chương trình hành động thực hiện Nghị quyết, bảo đảm Nghị quyết Đại hội sớm đi vào cuộc sống. Đồng chí Giàng Thị Dung – Phó Bí thư Tỉnh ủy Lào Cai chủ trì họp báo. Ảnh: Quốc Hồng Đồng chí Dương Đức Huy- Trưởng Ban Tuyên giáo và Dân vận tỉnh Lào Cai thông tin về công tác chuẩn bị Đại hội Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I. Ảnh: Quốc Hồng Đại biểu và các  nhà báo tham dự họp báo. Ảnh: Quốc Hồng Các nhà báo tác nghiệp tại buổi họp báo. Ảnh: Quốc Hồng Phóng viên Tạp chí Công dân và Khuyến học tác nghiệp tại buổi họp báo. Ảnh: Trọng Bảo Đại hội lần này ghi nhận số lượng tham luận lớn nhất từ trước đến nay, với 158 tham luận gửi về, dự kiến có 12 tham luận sẽ trình bày trực tiếp tại Đại hội. Đặc biệt, tỉnh Lào Cai đã xây dựng phần mềm \"đại hội số\" phục vụ toàn bộ quá trình tổ chức Đại hội. Phần mềm ứng dụng trí tuệ nhân tạo (AI) trong điểm danh đại biểu, phân tích thông tin, cung cấp đầy đủ tài liệu, văn kiện, chương trình làm việc và các chỉ tiêu phát triển kinh tế - xã hội. Với sự chuẩn bị chu đáo, Đại hội Đại biểu Đảng bộ tỉnh Lào Cai lần thứ I là dấu mốc quan trọng, góp phần đưa địa phương bước vào giai đoạn phát triển mới, bứt phá mạnh mẽ, trở thành trung tâm kết nối giao thương quốc tế, cực tăng trưởng của khu vực miền. Một số hình ảnh về phường Yên Bái (Lào Cai) chào mừng Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I: Với phương châm \" Đoàn kết, dân chủ, kỷ cương, sáng tạo, phát triển\", Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I sẽ khai mạc vào sáng ngày mai 28/9/2025. Ảnh: Quốc Hồng Trụ sở Ủy ban nhân dân tỉnh Lào Cai, ở phường Yên Bái trước ngày diễn  ra Đại hội Đảng bộ tỉnh. Ảnh: Quốc Hồng Rực rỡ cờ hoa và biểu tượng tỉnh Lào Cai trước vận hội mới. Ảnh: Quốc Hồng Đường phố Yên Bái phong quang, sạch đẹp. Ảnh: Quốc Hồng Một tuyến phố ở trung tâm phường Yên Bái, nơi diễn ra Đại hội. Ảnh: Quốc Hồng Lào Cai hướng đến phát triển xanh, văn hóa, bản sác, hạnh phúc. Ảnh: Quốc Hồng Phường Yên Bái trước vận hội mới. Ảnh: Quốc Hồng '}]"
        ],
        [
         "3",
         "Ông Lê Tiến Châu giữ chức Bí thư Thành ủy Hải Phòng",
         "[{'header': 'Sau gần 2 ngày làm việc Đại hội đại biểu Đảng bộ thành phố Hải Phòng lần thứ I, nhiệm kỳ 2025 - 2030 đã hoàn thành toàn bộ nội dung, chương trình đề ra và thành công tốt đẹp. Ông Lê Tiến Châu được chỉ định giữ chức Bí thư Thành ủy Hải Phòng nhiệm kỳ 2025-2030.', 'content': 'Ông Nguyễn Quang Dương, Ủy viên Trung ương Đảng, Phó Trưởng Ban Tổ chức Trung ương công bố Quyết định của Bộ Chính trị chỉ định Ban Chấp hành, Ban Thường vụ, Bí thư, Phó Bí thư Thành ủy Hải Phòng nhiệm kỳ 2025-2030. Ảnh: Đàm Thanh Tại Đại hội Phó Trưởng Ban Tổ chức Trung ương Nguyễn Quang Dương đã công bố Quyết định của Bộ Chính trị chỉ định Ban Chấp hành, Ban Thường vụ, Bí thư, Phó Bí thư Thành ủy Hải Phòng nhiệm kỳ 2025-2030. Theo đó, Ban Chấp hành Đảng bộ thành phố nhiệm kỳ 2025-2030 gồm 78 đồng chí; Ban Thường vụ Thành ủy nhiệm kỳ 2025-2030 gồm 20 đồng chí. Ông Lê Tiến Châu, Ủy viên Trung ương Đảng, Bí thư Thành ủy nhiệm kỳ 2020-2025 giữ chức Bí thư Thành ủy nhiệm kỳ 2025-2030. Các Phó Bí thư Thành ủy nhiệm kỳ 2020-2025: Đỗ Mạnh Hiến, Lê Ngọc Châu, Lê Văn Hiệu, Phạm Văn Lập, giữ chức Phó Bí thư Thành ủy nhiệm kỳ 2025-2030 Đại hội cũng công bố quyết định của Ban Bí thư Trung ương Đảng chỉ định Ủy ban Kiểm tra Thành ủy nhiệm kỳ 2025-2030 và Đoàn đại biểu Đảng bộ thành phố Hải Phòng dự Đại hội XIV của Đảng. Theo đó, Ủy ban Kiểm tra Thành ủy nhiệm kỳ 2025-2030 gồm 11 người. Ông Vũ Hồng Hiên, Chủ nhiệm Ủy ban Kiểm tra Thành ủy nhiệm kỳ 2020-2025 giữ chức Chủ nhiệm Ủy ban Kiểm tra Thành ủy nhiệm kỳ 2025-2030. Đoàn đại biểu Đảng bộ thành phố Hải Phòng dự Đại hội XIV của Đảng gồm 44 đại biểu chính thức và 3 đại biểu dự khuyết. Thủ tướng Chính phủ tặng hoa chúc mừng Ban Chấp hành Đảng bộ thành phố Hải Phòng. Ảnh: Đàm Thanh Phát biểu nhận nhiệm vụ, thay mặt Ban Chấp hành Đảng bộ thành phố nhiệm kỳ 2025-2030, Bí thư Thành ủy Hải Phòng\\xa0 Lê Tiến Châu nêu rõ: Toàn thể Ban Chấp hành Đảng bộ thành phố sẽ tuyệt đối trung thành với Tổ quốc, với Đảng, với Nhân dân; đoàn kết, kỷ cương, bản lĩnh; tận tâm, tận lực, phụng sự Tổ quốc, phục vụ Nhân dân; quyết tâm thực hiện thắng lợi Nghị quyết Đại hội Đảng bộ thành phố lần thứ I, xứng đáng với vị thế mới, trách nhiệm mới của Hải Phòng. Bí thư Thành ủy Lê Tiến Châu phát biểu nhận nhiệm vụ. Ảnh: Đàm Thanh Phát biểu bế mạc Đại hội, Bí thư Thành ủy Hải Phòng Lê Tiến Châu nhấn mạnh, thành công của nhiệm kỳ 2020 - 2025 với nhiều kết quả nổi bật trên tất cả các lĩnh vực đã tạo nền tảng vững chắc cho chặng đường phát triển mới của thành phố Hải Phòng, với vị thế và trách nhiệm lớn lao hơn, xứng đáng là cực tăng trưởng chiến lược phía Bắc của Tổ quốc. Trên cơ sở đó, Đại hội đã xác định mục tiêu đến năm 2030: \"Hải Phòng trở thành thành phố cảng công nghiệp hiện đại, văn minh, sinh thái và đáng sống tầm cỡ khu vực Đông Nam Á; tiên phong trong công nghiệp hóa, hiện đại hóa, chuyển đổi số, chuyển đổi xanh và đổi mới sáng tạo; là trung tâm kinh tế biển, du lịch chất lượng cao, dịch vụ - logistics và năng lượng sạch hàng đầu cả nước, trung tâm quốc tế về đào tạo, nghiên cứu, ứng dụng và phát triển khoa học - công nghệ biển. Đời sống vật chất và tinh thần của Nhân dân được nâng cao, an sinh và phúc lợi xã hội toàn diện, tiệm cận các thành phố tiêu biểu trong khu vực; quốc phòng - an ninh - trật tự an toàn xã hội vững chắc. Đảng bộ và hệ thống chính trị thành phố đoàn kết, có năng lực lãnh đạo, sức chiến đấu cao, cán bộ tiêu biểu về bản lĩnh, trí tuệ và khát vọng cống hiến; đi đầu trong xây dựng mô hình Chủ nghĩa xã hội gắn với con người Xã hội chủ nghĩa\". Sau gần 2 ngày làm việc Đại hội đại biểu Đảng bộ thành phố Hải Phòng lần thứ I, nhiệm kỳ 2025 - 2030 đã hoàn thành toàn bộ nội dung, chương trình đề ra và thành công tốt đẹp. Đại hội đã xác định 29 chỉ tiêu chủ yếu, 5 đột phá chiến lược và 11 nhiệm vụ, giải pháp then chốt, là trụ cột cho mô hình phát triển của thành phố đến năm 2030, tầm nhìn đến năm 2045. Trong đó, mục tiêu tăng trưởng GRDP giai đoạn 2026 - 2030 đạt từ 13% trở lên, phấn đấu đạt 14% được Đại hội khẳng định bằng sự thống nhất ý chí và quyết tâm hành động cao nhất. Đây là những mục tiêu lớn lao, khó khăn và đầy thách thức; nhưng cũng là khát vọng phát triển, là trách nhiệm của Đảng bộ thành phố Hải Phòng trước Nhân dân và đất nước. Ngay sau Đại hội, Bí thư Thành ủy Hải Phòng đề nghị toàn Đảng bộ khẩn trương quán triệt, tuyên truyền sâu rộng Nghị quyết Đại hội; phát động phong trào thi đua sôi nổi trong toàn thành phố; triển khai ngay Chương trình hành động thực hiện Nghị quyết, phân công rõ người, rõ việc, rõ thời gian, rõ trách nhiệm, rõ thẩm quyền và rõ kết quả, biến khát vọng thành hành động, biến khí thế, quyết tâm của Đại hội thành kết quả cụ thể; ưu tiên triển khai các đột phá chiến lược, khởi động các công trình, dự án hạ tầng trọng điểm, tạo đột phá về cải cách hành chính, gắn với cơ chế, chính sách đặc thù đã được Quốc hội thông qua, tạo niềm tin và động lực mới ngay từ những ngày đầu, tháng đầu của nhiệm kỳ. '}]"
        ],
        [
         "4",
         "Động thổ làm nhà hỗ trợ bé mồ côi 5 tuổi bị lũ cuốn mất chốn nương thân",
         "[{'header': 'Sau hơn 1 tháng Tạp chí Công dân và Khuyến học đăng tài bài viết về lũ cuốn trôi nhà ở nhờ của bé mồ côi 5 tuổi và các cô giáo mầm non kêu gọi hỗ trợ chốn ở cho bé, đến nay, nhiều mạnh thường quân đã ủng hộ tiền xây cho bé ngôi nhà.', 'content': 'Tại buổi lễ động thổ, cô giáo Trần Thị Lan - Hiệu trưởng Trường Mầm non Keng Đu (xã Keng Đu) chia sẻ, mặc dù thời tiết mưa gió, đường bị sạt lở nhiều đoạn đi lại khó khăn nhưng các mạnh thường quân, cùng chính quyền địa phương và các cơ quan ban ngành vẫn nỗ lực làm lễ động thổ xây nhà mới cho cháu Lương Bảo Vy. \"Thay mặt gia đình, nhà trường, xin cảm ơn những phóng viên Tạp chí Công dân và Khuyến học đã viết bài, chia sẻ và kết nối mạnh thường quân hiểu về hoàn cảnh đặc biệt của cháu Bảo Vy. Xin cảm ơn Ủy ban Mặt trận Tổ quốc tỉnh Nghệ An, Bệnh viện Thẩm mỹ Hải Lê và tấm lòng hảo tâm đã ủng hộ cho cháu để hôm nay có lễ động thổ này\". Phóng viên Tạp chí Công dân và Khuyến học (áo đỏ, ngoài cùng bên trái) cùng chính quyền địa phương, Bộ đội Biên phòng; Trường Mầm non Keng Đu và các mạnh thường quân trong buổi lễ động thổ làm nhà cho bé Lương Bảo Vy. Ảnh: Văn Hưng Cô giáo Trần Thị Lan xúc động trước tấm lòng thơm thảo của các tổ chức, cá nhân đã chia sẻ yêu thương đối với bé Bảo Vy - là con của một đồng nghiệp quá cố từng dạy học tại Trường Mầm non Keng Đu. Tại lễ động thổ, bà Lương Thị Thoong (bà nội bé Bảo Vy) bày tỏ: \"Hai bà cháu rất cảm ơn các mạnh thường quân đã hỗ trợ, giúp đỡ để làm nhà mới. Nhìn nhà đẹp tôi rất vui mừng và biết ơn. Được làm nhà là mong ước cả đời người của hai bà cháu\". Cũng tại buổi lễ, Chủ tịch Ủy ban nhân dân xã Keng Đu (tỉnh Nghệ An) Lương Văn Ngam cho biết, hoàn cảnh bé Bảo Vy mất mẹ khi mới chào đời, từ nhỏ bé ở với bà nội, được hội đồng nhà trường, các cô giáo mầm non Keng Đu hàng tháng cho sữa, quần áo và nhiều đồ dùng học tập. Ông Lương Văn Ngam - Chủ tịch Ủy ban nhân dân xã Keng Đu (trái) và bà Lương Thị Thoong (bà nội cháu Bảo Vy) tại buổi lễ động thổ làm nhà mới. Ảnh: Quốc Huy \"Ảnh hưởng bão số 3, ngôi nhà bà cháu Bảo Vy đi ở nhờ bị lũ cuốn trôi, dẫn đến không có nhà ở. Thay mặt cho chính quyền địa phương, tôi cảm ơn Tạp chí Công dân và Khuyến học đã viết bài, thông tin kịp thời để các mạnh thường quân, tổ chức và cá nhân giúp đỡ bé Bảo Vy được làm nhà mới\". Chủ tịch xã Keng Đu cho biết thêm, toàn xã Keng Đu hộ nghèo chiếm đến 70% trên tổng số 1.002 hộ. Đời sống nhân dân còn gặp nhiều khó khăn, nhất là tuyến đường huyết mạch ngã 3 Huội Tụ đi vào Keng Đu có nhiều điểm sạt lở, hư hỏng nghiêm trọng. Cách trung tâm tỉnh Nghệ An 320km. Các giáo viên ở Trường Mầm non Keng Đu cùng nhà tài trợ, chính quyền địa phương thực hiện nghi thức làm lễ động thổ làm nhà mới. Ảnh: Quốc Huy Trước đó, Tạp chí Công dân và Khuyến học thông tin , vừa chào đời cháu Bảo Vy đã chịu cảnh mồ côi mẹ, ở với bà nội đến nay đã 5 tuổi, được các cô giáo Trường Mầm non Keng Đu, xã Keng Đu, Nghệ An cưu mang. Đợt lũ vừa qua, ngôi nhà 2 bà cháu ở nhờ đã bị cuốn trôi hoàn toàn. Hoàn cảnh đặc biệt của cháu Lương Bảo Vy (5 tuổi), đang ở với bà nội Lương Thị Thoong ở bản Keng Đu, xã Keng Đu, tỉnh Nghệ An là khu vực chịu ảnh hưởng lớn trong trận lũ quét do hoàn lưu cơn bão số 3 gây ra. Ngôi nhà bà Thoong ở cùng đứa cháu nhỏ mồ côi là ngôi nhà ở nhờ một người con gái của bà đã bị đợt lũ vừa qua cuốn trôi hoàn toàn. Do đó, bà Thoong và cháu Bảo Vy đang đi ở nhờ nhà hàng xóm suốt gần 1 tháng qua. Phóng viên Tạp chí Công dân và Khuyến học trao quà Trung Thu cho bà nội cháu Lương Bảo Vy. Ảnh: Văn Hưng Thương bé Lương Bảo Vy - học trò nhỏ dại, chịu cảnh mồ côi mẹ ngay khi chào đời được 1 giờ đồng hồ, cô Trần Thị Lan - Hiệu trưởng Trường Mầm non Keng Đu đã gọi điện, lên mạng chia sẻ và kêu gọi mọi người chung giúp đỡ, mạnh thường quân hỗ trợ làm giúp một ngôi nhà tạm cho 2 bà cháu. Chỉ cần có một ngôi nhà nhỏ, 2 bà cháu không phải đi ở nhờ, các cô giáo cắm bản cam kết sẽ bớt đồng lương eo hẹp, góp thêm ống gạo, hộp sữa, chia lửa để nuôi cháu Bảo Vy côi cút lớn lên. Tham khảo thêm '}]"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Sections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Công an Hà Nội khuyến cáo người dân không tham...</td>\n",
       "      <td>[{'header': 'Để bảo đảm an toàn cho bản thân v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ngừng tiếp thu tàu bay tại một số Cảng hàng kh...</td>\n",
       "      <td>[{'header': 'Cục Hàng không Việt Nam vừa chỉ đ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>440 đại biểu ưu tú dự Đại hội đại biểu Đảng bộ...</td>\n",
       "      <td>[{'header': 'Chiều ngày 27/9, Tỉnh ủy Lào Cai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ông Lê Tiến Châu giữ chức Bí thư Thành ủy Hải ...</td>\n",
       "      <td>[{'header': 'Sau gần 2 ngày làm việc Đại hội đ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Động thổ làm nhà hỗ trợ bé mồ côi 5 tuổi bị lũ...</td>\n",
       "      <td>[{'header': 'Sau hơn 1 tháng Tạp chí Công dân ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Công an Hà Nội khuyến cáo người dân không tham...   \n",
       "1  Ngừng tiếp thu tàu bay tại một số Cảng hàng kh...   \n",
       "2  440 đại biểu ưu tú dự Đại hội đại biểu Đảng bộ...   \n",
       "3  Ông Lê Tiến Châu giữ chức Bí thư Thành ủy Hải ...   \n",
       "4  Động thổ làm nhà hỗ trợ bé mồ côi 5 tuổi bị lũ...   \n",
       "\n",
       "                                            Sections  \n",
       "0  [{'header': 'Để bảo đảm an toàn cho bản thân v...  \n",
       "1  [{'header': 'Cục Hàng không Việt Nam vừa chỉ đ...  \n",
       "2  [{'header': 'Chiều ngày 27/9, Tỉnh ủy Lào Cai ...  \n",
       "3  [{'header': 'Sau gần 2 ngày làm việc Đại hội đ...  \n",
       "4  [{'header': 'Sau hơn 1 tháng Tạp chí Công dân ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_json(news_data_dir / \"news_data.json\")\n",
    "news_df.columns = [\"Title\", \"Sections\"]\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d226c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data = []\n",
    "\n",
    "for _, row in news_df.iterrows():\n",
    "    title = row[\"Title\"]\n",
    "    sections = row[\"Sections\"]\n",
    "\n",
    "    doc = f\"Title: {title}\\n\"\n",
    "    \n",
    "    for section in sections:\n",
    "        sec_header = section[\"header\"]\n",
    "        sec_content = section[\"content\"]\n",
    "        doc += f\"Section Header: {sec_header}\\nSection Content: {sec_content}\\n\"\n",
    "\n",
    "    news_data.append(doc.strip())\n",
    "\n",
    "len(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ad366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title: Công an Hà Nội khuyến cáo người dân không tham gia một giải chạy do chưa đủ điều kiện pháp lý\\nSection Header: Để bảo đảm an toàn cho bản thân và tuân thủ các quy định của pháp luật, Công an Thành phố Hà Nội khuyến cáo người dân không tham gia Giải chạy \"Mỹ Đình Half Marathon 2025\" vào ngày 28/9/2025.\\nSection Content: Giải chạy \"Mỹ Đình Half Marathon 2025\" dự kiến diễn ra vào ngày 28/9/2025 tại khu vực Sân vận động Quốc gia Mỹ Đình chưa đủ điều kiện pháp lý để tổ chức. Ảnh minh họa \\nSection Header: Giải chạy \"Mỹ Đình Half Marathon 2025\" chưa được chấp thuận về mặt chuyên môn và chưa được chấp thuận chủ trương tổ chức\\nSection Content: Công an thành phố Hà Nội thông tin, qua công tác nắm tình hình, phòng An ninh chính trị nội bộ Công an thành phố Hà Nội phát hiện giải chạy \"Mỹ Đình Half Marathon 2025\" dự kiến diễn ra vào ngày 28/9/2025 tại khu vực Sân vận động Quốc gia Mỹ Đình chưa đủ điều kiện pháp lý để tổ chức. Cụ thể đến thời điểm hiện tại, Công ty Cổ phần Di sản Văn hóa, Thể thao Việt Nam vẫn chưa được Sở Văn hóa Thể thao Hà Nội chấp thuận về mặt chuyên môn và chưa được Ủy ban nhân dân Thành phố Hà Nội chấp thuận chủ trương tổ chức. \\u200e\\u200ePhòng An ninh chính trị nội bộ đã phối hợp với công an phường Từ Liêm yêu cầu đơn vị tổ chức là công ty Cổ phần Di sản Văn hoá, Thể thao Việt Nam không được tổ chức giải chạy khi chưa đầy đủ giấy tờ pháp lý theo quy định. \\u200e\\u200eĐể bảo đảm an toàn cho bản thân và tuân thủ các quy định của pháp luật, Công an Thành phố Hà Nội khuyến cáo người dân không tham gia Giải chạy \"Mỹ Đình Half Marathon 2025\" vào ngày 28/9/2025. Đồng thời, khi tham gia giải chạy của các tổ chức, cá nhân phải tìm hiểu kỹ thông tin, chỉ nên tham gia khi giải chạy đã bảo đảm đầy đủ thủ tục pháp lý theo quy định.',\n",
       " 'Title: Ngừng tiếp thu tàu bay tại một số Cảng hàng không do ảnh hưởng bão số 10 (bão Bualoi)\\nSection Header: Cục Hàng không Việt Nam vừa chỉ đạo phát thông báo tin tức hàng không về việc ngừng tiếp thu tàu bay tại các Cảng hàng không, sân bay nhằm chủ động ứng phó cơn bão số 10 (cơn bão Bualoi).\\nSection Content: Cảng hàng không Thọ Xuân là một trong những Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10. Ảnh minh họa \\nSection Header: Các Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10\\nSection Content: Theo Cục Hàng không Việt Nam, các Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10 gồm : Cảng hàng không Thọ Xuân, Cảng hàng không Vinh, Cảng hàng không Đồng Hới. Riêng Cảng Hàng không quốc tế Phú Bài, Đà Nẵng dự kiến sẽ chịu tác động gió giật sớm do hoàn lưu bão gây ra. Các Cảng Hàng không quốc tế: Nội Bài, Vân Đồn, Cát Bi và Cảng hàng không Chu Lai chủ động cập nhật thông tin, đề phòng khi bão có diễn biến bất thường. Đối với Cảng Hàng không quốc tế Vân Đồn và các Cảng hàng không trực thuộc Tổng công ty Cảng hàng không Việt Nam trong vùng ảnh hưởng của bão số 10 , Cục Hàng không Việt Nam yêu cầu các đơn vị chủ trì, phối hợp với các cơ quan, đơn vị liên quan kiểm tra hệ thống kết cấu hạ tầng cảng hàng không, hệ thống thông tin liên lạc... để kịp thời phát hiện và xử lý các hư hỏng (nếu có) nhằm bảo đảm an toàn cho các công trình, đài trạm, đảm bảo an toàn cho hoạt động khai thác tại cảng hàng không, sân bay. Đồng thời triển khai phương án phòng chống mưa, bão, các biện pháp phòng chống ngập úng, khơi thông dòng chảy trong cảng hàng không, sân bay, bảo vệ cho các công trình, phương tiện, thiết bị tại cảng hàng không, hạn chế thiệt hại do mưa, bão gây ra đến mức thấp nhất và nhanh chóng ổn định mọi hoạt động hàng không phục vụ các nhu cầu của hành khách. Đối với các Cảng hàng không đang triển khai thi công xây dựng công trình (Cảng Hàng không quốc tế Cát Bi, Cảng hàng không Vinh, Cảng hàng không Đồng Hới): chủ đầu tư yêu cầu các nhà thầu thi công triển khai ngay công tác ứng phó bão; xác định các điểm dừng kỹ thuật để dừng thi công theo tình hình diễn biến của bão; chuẩn bị các điều kiện để kịp thời khắc phục các sự cố công trình, đảm bảo an toàn, hạn chế thiệt hại do bão gây ra. Ngoài ra, bố trí trực 24/24h, chủ động cập nhật thông tin khí tượng để kịp thời đề xuất phương án khai thác phù hợp, an toàn. Cục Hàng không Việt Nam cũng lưu ý các đơn vị sau khi bão suy yếu và đổ bộ vào đất liền có khả năng nguy cơ gây mưa sau bão. Đối với Tổng công ty Quản lý bay Việt Nam (VATM) , Cục Hàng không Việt Nam yêu cầu VATM chỉ đạo các cơ sở cung cấp dịch vụ khí tượng hàng không tăng cường công tác đảm bảo chất lượng thông tin khí tượng; liên tục theo dõi tình hình thời tiết trong khu vực trách nhiệm, cập nhật các bản tin dự báo, cảnh báo; cung cấp đầy đủ kịp thời thông tin quan trắc, dự báo, cảnh báo tới người dùng. Đối với các Hãng hàng không, các cơ sở cung cấp dịch vụ bảo đảm hoạt động bay , Cục Hàng không Việt Nam yêu cầu các đơn vị tăng cường công tác phối hợp; theo dõi chặt chẽ diễn biến của bão số 10 để có phương án điều chỉnh kế hoạch bay hoặc thay đổi lịch bay cho phù hợp và đảm bảo an toàn cho hoạt động bay. Ngoài ra, cần cập nhật đầy đủ thông tin khí tượng từ các cơ sở khí tượng hàng không liên quan và căn cứ tình hình thực tế để triển khai các hành động ứng phó cần thiết, giảm thiểu tác động đến khai thác, đảm bảo an toàn hoạt động bay, bảo vệ người và tài sản của đơn vị trước thiên tai. Đối với các Cảng vụ hàng không: miền Bắc, miền Trung , Cục yêu cầu các Cảng vụ giám sát công tác triển khai các nội dung ứng phó tại các cảng hàng không liên quan; bảo đảm liên lạc thông suốt với Ban Chỉ huy PCTT&TKCN Cục Hàng không Việt Nam và các cơ quan, đơn vị liên quan trong phạm vi trách nhiệm để triển khai ứng phó trong mọi tình huống. Cục Hàng không Việt Nam chỉ đạo phát thông báo tin tức hàng không về việc ngừng tiếp thu tàu bay tại các Cảng hàng không, sân bay (theo giờ địa phương) như sau: Cảng hàng không Đồng Hới: ngừng tiếp thu tàu bay từ 13h00 -22h00 ngày 28/9/2025; Cảng hàng không Thọ Xuân: ngừng tiếp thu tàu bay từ 22h00 ngày 28/9/2025 đến 7h00 ngày 29/9/2025. Cảng Hàng không quốc tế Phú Bài, ngừng tiếp thu tàu bay từ 08h00-14h00 ngày 28/9. Cảng Hàng không quốc tế Đà Nẵng: ngừng tiếp thu tàu bay từ 06h-11h00 ngày 28/9. Cục Hàng không Việt Nam yêu cầu các cơ quan, đơn vị nghiêm túc thực hiện các nội dung trên và báo cáo mọi diễn biến có liên quan về Cục Hàng không Việt Nam để có những chỉ đạo kịp thời.',\n",
       " 'Title: 440 đại biểu ưu tú dự Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I\\nSection Header: Chiều ngày 27/9, Tỉnh ủy Lào Cai tổ chức họp báo, thông tin về Đại hội Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I, nhiệm kỳ 2025-2030. Đồng chí Giàng Thị Dung – Phó Bí thư Tỉnh ủy Lào Cai chủ trì họp báo.\\nSection Content: Trung tâm Hội nghị tỉnh Lào Cai , nơi sẽ diễn ra Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I. Ảnh: Quốc Hồng Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I sẽ khai mạc sáng ngày 28/9/2025 Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I, nhiệm kỳ 2025-2030 diễn ra trong 3 ngày, 28 - 30/9, tại Trung tâm Hội nghị tỉnh Lào Cai, trên địa bàn phường Yên Bái. Đại hội có 440 đại biểu chính thức, đại diện cho 119.000 Đảng viên, thuộc 103 đảng bộ trực thuộc Tỉnh ủy. Đây cũng là kỳ Đại hội đầu tiên sau hợp nhất tỉnh Lào Cai và tỉnh Yên Bái, thành phố, khi diện tích tự nhiên hơn 13.256km2, quy mô dân số hơn 1,7 triệu người, gồm 99 xã, phường chính thức được thành lập và đi vào hoạt động theo mô hình chính quyền địa phương 2 cấp. Lào Cai có qui mô kinh tế đứng thứ 25, dân số đứng thứ 26 và diện tích tự nhiên đứng thứ 8 cả nước. Tại họp báo, ông Dương Đức Huy - Trưởng Ban Tuyên giáo và Dân vận tỉnh Lào Cai cho biết, công tác chuẩn bị Đại hội đã được triển khai khẩn trương, khoa học, chuyên nghiệp. Các Tiểu ban Văn kiện, Nhân sự, Tổ chức phục vụ Đại hội bám sát kế hoạch, phân công rõ nhiệm vụ cho từng cơ quan, đơn vị. Các văn kiện được chuẩn bị kỹ lưỡng, qua nhiều vòng thảo luận, lấy ý kiến rộng rãi từ cán bộ, đảng viên và nhân dân. Báo cáo chính trị đã hoàn thiện sau 9 lần dự thảo, Báo cáo kiểm điểm và Nghị quyết được chỉnh sửa qua nhiều lần dự thảo. Tỉnh ủy Lào Cai cũng chủ động xây dựng dự thảo Chương trình hành động thực hiện Nghị quyết, bảo đảm Nghị quyết Đại hội sớm đi vào cuộc sống. Đồng chí Giàng Thị Dung – Phó Bí thư Tỉnh ủy Lào Cai chủ trì họp báo. Ảnh: Quốc Hồng Đồng chí Dương Đức Huy- Trưởng Ban Tuyên giáo và Dân vận tỉnh Lào Cai thông tin về công tác chuẩn bị Đại hội Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I. Ảnh: Quốc Hồng Đại biểu và các  nhà báo tham dự họp báo. Ảnh: Quốc Hồng Các nhà báo tác nghiệp tại buổi họp báo. Ảnh: Quốc Hồng Phóng viên Tạp chí Công dân và Khuyến học tác nghiệp tại buổi họp báo. Ảnh: Trọng Bảo Đại hội lần này ghi nhận số lượng tham luận lớn nhất từ trước đến nay, với 158 tham luận gửi về, dự kiến có 12 tham luận sẽ trình bày trực tiếp tại Đại hội. Đặc biệt, tỉnh Lào Cai đã xây dựng phần mềm \"đại hội số\" phục vụ toàn bộ quá trình tổ chức Đại hội. Phần mềm ứng dụng trí tuệ nhân tạo (AI) trong điểm danh đại biểu, phân tích thông tin, cung cấp đầy đủ tài liệu, văn kiện, chương trình làm việc và các chỉ tiêu phát triển kinh tế - xã hội. Với sự chuẩn bị chu đáo, Đại hội Đại biểu Đảng bộ tỉnh Lào Cai lần thứ I là dấu mốc quan trọng, góp phần đưa địa phương bước vào giai đoạn phát triển mới, bứt phá mạnh mẽ, trở thành trung tâm kết nối giao thương quốc tế, cực tăng trưởng của khu vực miền. Một số hình ảnh về phường Yên Bái (Lào Cai) chào mừng Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I: Với phương châm \" Đoàn kết, dân chủ, kỷ cương, sáng tạo, phát triển\", Đại hội đại biểu Đảng bộ tỉnh Lào Cai lần thứ I sẽ khai mạc vào sáng ngày mai 28/9/2025. Ảnh: Quốc Hồng Trụ sở Ủy ban nhân dân tỉnh Lào Cai, ở phường Yên Bái trước ngày diễn  ra Đại hội Đảng bộ tỉnh. Ảnh: Quốc Hồng Rực rỡ cờ hoa và biểu tượng tỉnh Lào Cai trước vận hội mới. Ảnh: Quốc Hồng Đường phố Yên Bái phong quang, sạch đẹp. Ảnh: Quốc Hồng Một tuyến phố ở trung tâm phường Yên Bái, nơi diễn ra Đại hội. Ảnh: Quốc Hồng Lào Cai hướng đến phát triển xanh, văn hóa, bản sác, hạnh phúc. Ảnh: Quốc Hồng Phường Yên Bái trước vận hội mới. Ảnh: Quốc Hồng']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data_cleaned = [clean_text(item) for item in news_data]\n",
    "\n",
    "news_data_cleaned[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa6d2ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3b1b_manim',\n",
       " 'abi_screenshot-to-code',\n",
       " 'ageitgey_face_recognition',\n",
       " 'AntonOsika_gpt-engineer',\n",
       " 'browser-use_browser-use',\n",
       " 'commaai_openpilot',\n",
       " 'deepseek-ai_DeepSeek-V3',\n",
       " 'fastapi_fastapi',\n",
       " 'FoundationAgents_MetaGPT',\n",
       " 'labmlai_annotated_deep_learning_paper_implementations',\n",
       " 'langflow-ai_langflow',\n",
       " 'microsoft_markitdown',\n",
       " 'nvbn_thefuck',\n",
       " 'openai_whisper',\n",
       " 'public-apis_public-apis',\n",
       " 'sherlock-project_sherlock',\n",
       " 'swisskyrepo_PayloadsAllTheThings',\n",
       " 'Textualize_rich',\n",
       " 'TheAlgorithms_Python',\n",
       " 'Z4nzu_hackingtool']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_python_files(repo_path):\n",
    "    data = []\n",
    "    \n",
    "    for root, _, files in os.walk(repo_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".py\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    if os.path.getsize(file_path) < 1e6:  # Skip files larger than 1MB\n",
    "                        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                            content = f.read()\n",
    "                        data.append({\n",
    "                            \"path\": file_path,\n",
    "                            \"content\": content\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Read error {file_path}: {e}\")\n",
    "    return data\n",
    "\n",
    "def run_cmd(cmd: List[str]) -> subprocess.CompletedProcess:\n",
    "    \"\"\"Run subprocess and return CompletedProcess (capture output).\"\"\"\n",
    "    return subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "RUFF_LOG = \"../logs/ruff_errors.log\"\n",
    "          \n",
    "def ruff_try_format(file_path: str) -> bool:\n",
    "    \"\"\"Try to format with ruff. Return True if file likely formatted, False on failure.\"\"\"\n",
    "    try:\n",
    "        # Preferred: ruff format (formatter). Try that first.\n",
    "        cp = run_cmd([\"ruff\", \"format\", file_path])\n",
    "        if cp.returncode == 0:\n",
    "            return True\n",
    "\n",
    "        # Fallback: try ruff check --fix\n",
    "        cp2 = run_cmd([\"ruff\", \"check\", file_path, \"--fix\"])\n",
    "        if cp2.returncode == 0:\n",
    "            return True\n",
    "\n",
    "        # Log both outputs for debugging\n",
    "        with open(RUFF_LOG, \"a\", encoding=\"utf-8\") as lf:\n",
    "            lf.write(f\"\\n--- Ruff failure on: {file_path} ---\\n\")\n",
    "            lf.write(f\"format rc={cp.returncode}\\nstdout:\\n{cp.stdout}\\nstderr:\\n{cp.stderr}\\n\")\n",
    "            lf.write(f\"check--fix rc={cp2.returncode}\\nstdout:\\n{cp2.stdout}\\nstderr:\\n{cp2.stderr}\\n\")\n",
    "        logger.warning(f\"Ruff formatting failed for {file_path} (see {RUFF_LOG})\")\n",
    "        \n",
    "        return False\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(\"Ruff not found in PATH. Please install: pip install ruff\")\n",
    "        \n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Unexpected error running ruff on {file_path}: {e}\")\n",
    "        \n",
    "        return False\n",
    "\n",
    "def fallback_clean_code(code: str) -> str:\n",
    "    \"\"\"Simple safe cleaning: rstrip trailing spaces, convert tabs to 4 spaces, collapse multi blank lines.\"\"\"\n",
    "    cleaned_lines = []\n",
    "    for line in code.splitlines():\n",
    "        # preserve leading indent, normalize tabs\n",
    "        leading = len(line) - len(line.lstrip(\"\\t \"))\n",
    "        # keep original leading whitespace but replace tabs with 4 spaces in entire line\n",
    "        line = line.replace(\"\\t\", \"    \")\n",
    "        # strip trailing spaces\n",
    "        line = line.rstrip()\n",
    "        # if line only whitespace -> become empty string\n",
    "        if line.strip() == \"\":\n",
    "            cleaned_lines.append(\"\")\n",
    "        else:\n",
    "            cleaned_lines.append(line)\n",
    "    # collapse consecutive blank lines >1 to a single blank\n",
    "    result = []\n",
    "    prev_blank = False\n",
    "    for l in cleaned_lines:\n",
    "        if l == \"\":\n",
    "            if not prev_blank:\n",
    "                result.append(l)\n",
    "            prev_blank = True\n",
    "        else:\n",
    "            result.append(l)\n",
    "            prev_blank = False\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def chunk_code_ast(code: str) -> Optional[List[str]]:\n",
    "    \"\"\"Try to parse AST and extract top-level function/class definitions as chunks.\n",
    "       Return None if parse fails.\"\"\"\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        chunks = []\n",
    "        \n",
    "        for node in tree.body:\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "                seg = ast.get_source_segment(code, node)\n",
    "                if seg:\n",
    "                    chunks.append(seg)\n",
    "                    \n",
    "        # If no function/class found, return whole file as single chunk\n",
    "        if not chunks:\n",
    "            return [code.strip()]\n",
    "        \n",
    "        return [c.strip() for c in chunks if c.strip()]\n",
    "    except SyntaxError:\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def chunk_code_regex(code: str) -> List[str]:\n",
    "    \"\"\"Fallback chunker: split whenever we see a line starting with def/class (simple heuristic).\"\"\"\n",
    "    chunks = []\n",
    "    cur = []\n",
    "    \n",
    "    for line in code.splitlines():\n",
    "        if line.lstrip().startswith((\"def \", \"class \")):\n",
    "            if cur:\n",
    "                chunks.append(\"\\n\".join(cur).strip())\n",
    "                cur = []\n",
    "                \n",
    "        cur.append(line)\n",
    "        \n",
    "    if cur:\n",
    "        chunks.append(\"\\n\".join(cur).strip())\n",
    "        \n",
    "    # keep non-empty\n",
    "    return [c for c in chunks if c]\n",
    "\n",
    "def build_corpus(repo_path: str, \n",
    "                 output_jsonl: str = \"python_corpus.jsonl\", \n",
    "                 output_txt: str = \"python_corpus.txt\"):\n",
    "    files = read_python_files(repo_path)\n",
    "    logger.info(f\"Found {len(files)} .py files (under size limit).\")\n",
    "    written = 0\n",
    "    \n",
    "    with open(output_jsonl, \"w\", encoding=\"utf-8\") as out_jsonl, \\\n",
    "        open(output_txt, \"w\", encoding=\"utf-8\") as out_txt:\n",
    "        for f in files:\n",
    "            path = f[\"path\"]\n",
    "            # try to format with ruff (safe: doesn't raise)\n",
    "            formatted_ok = ruff_try_format(path)\n",
    "\n",
    "            # read formatted if possible, else fallback to original cleaned content\n",
    "            try:\n",
    "                with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "                    formatted_code = fh.read()\n",
    "                if not formatted_ok:\n",
    "                    # even if file was changed by ruff partially, we still apply a safe final cleanup\n",
    "                    formatted_code = fallback_clean_code(formatted_code)\n",
    "            except Exception:\n",
    "                formatted_code = fallback_clean_code(f[\"content\"])\n",
    "\n",
    "            # chunk via AST first, else regex fallback\n",
    "            chunks = chunk_code_ast(formatted_code)\n",
    "            if chunks is None:\n",
    "                chunks = chunk_code_regex(formatted_code)\n",
    "                if not chunks:\n",
    "                    # as last resort, use whole file\n",
    "                    chunks = [formatted_code.strip()]\n",
    "\n",
    "            for chunk in chunks:\n",
    "                # JSONL with tags\n",
    "                rec = {\"path\": path, \"text\": f\"<code> {chunk.strip()} </code>\"}\n",
    "                out_jsonl.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                # TXT with tags, keep line breaks or flatten?\n",
    "                flat_chunk = chunk.strip().replace(\"\\n\", \" \")  # flatten for tokenizer\n",
    "                out_txt.write(f\"<code> {flat_chunk} </code>\\n\")\n",
    "\n",
    "                written += 1\n",
    "\n",
    "repo_list = [d for d in os.listdir(github_repos_dir) if os.path.join(github_repos_dir, d) and os.path.isdir(os.path.join(github_repos_dir, d))]\n",
    "repo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77543f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 09:34:02,390 INFO: Found 95 .py files (under size limit).\n",
      "2025-09-29 09:34:07,972 INFO: Found 50 .py files (under size limit).\n",
      "2025-09-29 09:34:10,334 INFO: Found 30 .py files (under size limit).\n",
      "2025-09-29 09:34:11,977 INFO: Found 84 .py files (under size limit).\n",
      "2025-09-29 09:34:17,019 INFO: Found 245 .py files (under size limit).\n",
      "2025-09-29 09:34:29,565 INFO: Found 481 .py files (under size limit).\n",
      "2025-09-29 09:34:49,894 INFO: Found 5 .py files (under size limit).\n",
      "2025-09-29 09:34:51,665 INFO: Found 1136 .py files (under size limit).\n",
      "2025-09-29 09:35:43,498 INFO: Found 890 .py files (under size limit).\n",
      "<unknown>:99: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<unknown>:361: SyntaxWarning: invalid escape sequence '\\d'\n",
      "2025-09-29 09:36:20,722 INFO: Found 227 .py files (under size limit).\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:73: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:93: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:110: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:181: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:190: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:197: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:217: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:233: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:257: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:38: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:72: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:139: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:175: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:341: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:353: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:360: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:489: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:524: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:603: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:695: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:103: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:146: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:264: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:293: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:32: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:179: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:202: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:220: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:238: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:270: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:75: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:146: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:440: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:61: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:126: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:187: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:222: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:271: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:307: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:27: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:52: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:100: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:157: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:230: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:33: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:51: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:91: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:118: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:136: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:34: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:64: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:40: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:71: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:38: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:70: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:220: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:489: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:118: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:40: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:79: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:107: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:159: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:221: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:460: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:542: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:843: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:881: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:897: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:922: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:93: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:118: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:58: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:33: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:91: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\B'\n",
      "<unknown>:62: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:126: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:253: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:29: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:103: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:19: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:107: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<unknown>:49: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:73: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:101: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:190: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:138: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:85: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:99: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:114: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:96: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:50: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:78: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:67: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:149: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:37: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:60: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:41: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:66: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:64: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:114: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:47: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:90: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:126: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:41: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:66: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:167: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:245: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:80: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:118: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:163: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:83: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:19: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:69: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:110: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:17: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:21: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:187: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:195: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:203: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:34: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:28: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:34: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:185: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<unknown>:59: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<unknown>:131: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<unknown>:382: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:62: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:72: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\B'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:66: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:115: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:45: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<unknown>:104: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:154: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:176: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:168: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:410: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:48: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:26: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:90: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<unknown>:127: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:264: SyntaxWarning: invalid escape sequence '\\B'\n",
      "<unknown>:293: SyntaxWarning: invalid escape sequence '\\B'\n",
      "<unknown>:396: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<unknown>:781: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<unknown>:813: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:45: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:22: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:81: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:35: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<unknown>:88: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:192: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:279: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:395: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:440: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:487: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:592: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:31: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<unknown>:118: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<unknown>:130: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<unknown>:58: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:84: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:101: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:131: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:150: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:196: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:220: SyntaxWarning: invalid escape sequence '\\B'\n",
      "<unknown>:245: SyntaxWarning: invalid escape sequence '\\m'\n",
      "2025-09-29 09:36:34,600 INFO: Found 1430 .py files (under size limit).\n",
      "2025-09-29 09:37:36,479 INFO: Found 53 .py files (under size limit).\n",
      "2025-09-29 09:37:40,377 INFO: Found 416 .py files (under size limit).\n",
      "2025-09-29 09:37:55,800 INFO: Found 20 .py files (under size limit).\n",
      "2025-09-29 09:37:56,784 INFO: Found 6 .py files (under size limit).\n",
      "<unknown>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:28: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<unknown>:29: SyntaxWarning: invalid escape sequence '\\['\n",
      "2025-09-29 09:37:57,358 INFO: Found 16 .py files (under size limit).\n",
      "2025-09-29 09:37:58,415 INFO: Found 28 .py files (under size limit).\n",
      "<unknown>:33: SyntaxWarning: invalid escape sequence '\\('\n",
      "<unknown>:47: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:148: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:215: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<unknown>:53: SyntaxWarning: invalid escape sequence '\\~'\n",
      "2025-09-29 09:38:00,848 INFO: Found 190 .py files (under size limit).\n",
      "2025-09-29 09:38:12,029 INFO: Found 1371 .py files (under size limit).\n",
      "2025-09-29 09:39:07,732 INFO: Found 31 .py files (under size limit).\n"
     ]
    }
   ],
   "source": [
    "output_jsonl = github_repos_dir / \"corpus.jsonl\"\n",
    "output_txt = github_repos_dir / \"corpus.txt\"\n",
    "\n",
    "for repo in repo_list:\n",
    "    repo_path = os.path.join(github_repos_dir, repo)\n",
    "    build_corpus(repo_path, output_jsonl, output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d3d379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<code> def clear_screen():\\n    os.system(\"cls\" if system() == \"Windows\" else \"clear\") </code>',\n",
       " '<code> def validate_input(ip, val_range):\\n    val_range = val_range or []\\n    try:\\n        ip = int(ip)\\n        if ip in val_range:\\n            return ip\\n    except Exception:\\n        return None\\n    return None </code>',\n",
       " '<code> class HackingTool(object):\\n    # About the HackingTool\\n    TITLE: str = \"\"  # used to show info in the menu\\n    DESCRIPTION: str = \"\"\\n\\n    INSTALL_COMMANDS: List[str] = []\\n    INSTALLATION_DIR: str = \"\"\\n\\n    UNINSTALL_COMMANDS: List[str] = []\\n\\n    RUN_COMMANDS: List[str] = []\\n\\n    OPTIONS: List[Tuple[str, Callable]] = []\\n\\n    PROJECT_URL: str = \"\"\\n\\n    def __init__(self, options=None, installable: bool = True, runnable: bool = True):\\n        options = options or []\\n        if isinstance(options, list):\\n            self.OPTIONS = []\\n            if installable:\\n                self.OPTIONS.append((\"Install\", self.install))\\n            if runnable:\\n                self.OPTIONS.append((\"Run\", self.run))\\n            self.OPTIONS.extend(options)\\n        else:\\n            raise Exception(\"options must be a list of (option_name, option_fn) tuples\")\\n\\n    def show_info(self):\\n        desc = self.DESCRIPTION\\n        if self.PROJECT_URL:\\n            desc += \"\\\\n\\\\t[*] \"\\n            desc += self.PROJECT_URL\\n        os.system(f\\'echo \"{desc}\"|boxes -d boy | lolcat\\')\\n\\n    def show_options(self, parent=None):\\n        clear_screen()\\n        self.show_info()\\n        for index, option in enumerate(self.OPTIONS):\\n            print(f\"[{index + 1}] {option[0]}\")\\n        if self.PROJECT_URL:\\n            print(f\"[{98}] Open project page\")\\n        print(f\"[{99}] Back to {parent.TITLE if parent is not None else \\'Exit\\'}\")\\n        option_index = input(\"Select an option : \").strip()\\n        try:\\n            option_index = int(option_index)\\n            if option_index - 1 in range(len(self.OPTIONS)):\\n                ret_code = self.OPTIONS[option_index - 1][1]()\\n                if ret_code != 99:\\n                    input(\"\\\\n\\\\nPress ENTER to continue:\").strip()\\n            elif option_index == 98:\\n                self.show_project_page()\\n            elif option_index == 99:\\n                if parent is None:\\n                    sys.exit()\\n                return 99\\n        except (TypeError, ValueError):\\n            print(\"Please enter a valid option\")\\n            input(\"\\\\n\\\\nPress ENTER to continue:\").strip()\\n        except Exception:\\n            print_exc()\\n            input(\"\\\\n\\\\nPress ENTER to continue:\").strip()\\n        return self.show_options(parent=parent)\\n\\n    def before_install(self):\\n        pass\\n\\n    def install(self):\\n        self.before_install()\\n        if isinstance(self.INSTALL_COMMANDS, (list, tuple)):\\n            for INSTALL_COMMAND in self.INSTALL_COMMANDS:\\n                os.system(INSTALL_COMMAND)\\n            self.after_install()\\n\\n    def after_install(self):\\n        print(\"Successfully installed!\")\\n\\n    def before_uninstall(self) -> bool:\\n        \"\"\"Ask for confirmation from the user and return\"\"\"\\n        return True\\n\\n    def uninstall(self):\\n        if self.before_uninstall():\\n            if isinstance(self.UNINSTALL_COMMANDS, (list, tuple)):\\n                for UNINSTALL_COMMAND in self.UNINSTALL_COMMANDS:\\n                    os.system(UNINSTALL_COMMAND)\\n            self.after_uninstall()\\n\\n    def after_uninstall(self):\\n        pass\\n\\n    def before_run(self):\\n        pass\\n\\n    def run(self):\\n        self.before_run()\\n        if isinstance(self.RUN_COMMANDS, (list, tuple)):\\n            for RUN_COMMAND in self.RUN_COMMANDS:\\n                os.system(RUN_COMMAND)\\n            self.after_run()\\n\\n    def after_run(self):\\n        pass\\n\\n    def is_installed(self, dir_to_check=None):\\n        print(\"Unimplemented: DO NOT USE\")\\n        return \"?\"\\n\\n    def show_project_page(self):\\n        webbrowser.open_new_tab(self.PROJECT_URL) </code>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_df = pd.read_json(output_jsonl, lines=True)\n",
    "\n",
    "repo_data_cleaned = [item for item in repo_df['text'].tolist()]\n",
    "\n",
    "repo_data_cleaned[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd767848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(text: str) -> List[str]:\n",
    "    \"\"\" \n",
    "    Segment text into sentences based on punctuation.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def segment_paragraphs(text: str):\n",
    "    \"\"\"\n",
    "    Segment text into paragraphs based on double newlines.\n",
    "    \"\"\"\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text.strip())\n",
    "    return [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "def chunk_with_tags(text, prefix=\"<wiki>\", suffix=\"</wiki>\", max_sentences=5):\n",
    "    sentences = segment_sentences(text)\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(sentences), max_sentences):\n",
    "        chunk = \" \".join(sentences[i:i+max_sentences]).strip()\n",
    "        if chunk:\n",
    "            chunks.append(f\"{prefix} {chunk} {suffix}\")\n",
    "            \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data_cleaned = [segment_sentences(item) for item in wiki_data_cleaned]\n",
    "news_data_cleaned = [segment_sentences(item) for item in news_data_cleaned]\n",
    "\n",
    "wiki_data_chunked = list(chain.from_iterable(\n",
    "    chunk_with_tags(\" \".join(item), prefix=\"<wiki>\", suffix=\"</wiki>\", max_sentences=5) \n",
    "    for item in wiki_data_cleaned\n",
    "))\n",
    "\n",
    "news_data_chunked = list(chain.from_iterable(\n",
    "    chunk_with_tags(\" \".join(item), prefix=\"<news>\", suffix=\"</news>\", max_sentences=5) \n",
    "    for item in news_data_cleaned\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae82c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<news> Title: Công an Hà Nội khuyến cáo người dân không tham gia một giải chạy do chưa đủ điều kiện pháp lý\\nSection Header: Để bảo đảm an toàn cho bản thân và tuân thủ các quy định của pháp luật, Công an Thành phố Hà Nội khuyến cáo người dân không tham gia Giải chạy \"Mỹ Đình Half Marathon 2025\" vào ngày 28/9/2025. Section Content: Giải chạy \"Mỹ Đình Half Marathon 2025\" dự kiến diễn ra vào ngày 28/9/2025 tại khu vực Sân vận động Quốc gia Mỹ Đình chưa đủ điều kiện pháp lý để tổ chức. Ảnh minh họa \\nSection Header: Giải chạy \"Mỹ Đình Half Marathon 2025\" chưa được chấp thuận về mặt chuyên môn và chưa được chấp thuận chủ trương tổ chức\\nSection Content: Công an thành phố Hà Nội thông tin, qua công tác nắm tình hình, phòng An ninh chính trị nội bộ Công an thành phố Hà Nội phát hiện giải chạy \"Mỹ Đình Half Marathon 2025\" dự kiến diễn ra vào ngày 28/9/2025 tại khu vực Sân vận động Quốc gia Mỹ Đình chưa đủ điều kiện pháp lý để tổ chức. Cụ thể đến thời điểm hiện tại, Công ty Cổ phần Di sản Văn hóa, Thể thao Việt Nam vẫn chưa được Sở Văn hóa Thể thao Hà Nội chấp thuận về mặt chuyên môn và chưa được Ủy ban nhân dân Thành phố Hà Nội chấp thuận chủ trương tổ chức. \\u200e\\u200ePhòng An ninh chính trị nội bộ đã phối hợp với công an phường Từ Liêm yêu cầu đơn vị tổ chức là công ty Cổ phần Di sản Văn hoá, Thể thao Việt Nam không được tổ chức giải chạy khi chưa đầy đủ giấy tờ pháp lý theo quy định. </news>',\n",
       " '<news> \\u200e\\u200eĐể bảo đảm an toàn cho bản thân và tuân thủ các quy định của pháp luật, Công an Thành phố Hà Nội khuyến cáo người dân không tham gia Giải chạy \"Mỹ Đình Half Marathon 2025\" vào ngày 28/9/2025. Đồng thời, khi tham gia giải chạy của các tổ chức, cá nhân phải tìm hiểu kỹ thông tin, chỉ nên tham gia khi giải chạy đã bảo đảm đầy đủ thủ tục pháp lý theo quy định. </news>',\n",
       " '<news> Title: Ngừng tiếp thu tàu bay tại một số Cảng hàng không do ảnh hưởng bão số 10 (bão Bualoi)\\nSection Header: Cục Hàng không Việt Nam vừa chỉ đạo phát thông báo tin tức hàng không về việc ngừng tiếp thu tàu bay tại các Cảng hàng không, sân bay nhằm chủ động ứng phó cơn bão số 10 (cơn bão Bualoi). Section Content: Cảng hàng không Thọ Xuân là một trong những Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10. Ảnh minh họa \\nSection Header: Các Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10\\nSection Content: Theo Cục Hàng không Việt Nam, các Cảng hàng không dự báo nằm trong vùng chịu ảnh hưởng trực tiếp của bão số 10 gồm : Cảng hàng không Thọ Xuân, Cảng hàng không Vinh, Cảng hàng không Đồng Hới. Riêng Cảng Hàng không quốc tế Phú Bài, Đà Nẵng dự kiến sẽ chịu tác động gió giật sớm do hoàn lưu bão gây ra. Các Cảng Hàng không quốc tế: Nội Bài, Vân Đồn, Cát Bi và Cảng hàng không Chu Lai chủ động cập nhật thông tin, đề phòng khi bão có diễn biến bất thường. </news>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data_chunked[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b437769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_txt(list_data, file_path):\n",
    "    \"\"\"\n",
    "    Save list of strings to a plain .txt file.\n",
    "    Each element in list_data is written on a new line.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in list_data:\n",
    "            f.write(item.strip() + \"\\n\")\n",
    "\n",
    "\n",
    "def save_to_jsonl(list_data, file_path):\n",
    "    \"\"\"\n",
    "    Save list of strings to a .jsonl file.\n",
    "    Each element in list_data is wrapped in {\"text\": ...}\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in list_data:\n",
    "            json_obj = {\"text\": item.strip()}\n",
    "            f.write(json.dumps(json_obj, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "save_to_txt(wiki_data_chunked, wiki_data_dir / \"wiki.txt\")\n",
    "save_to_txt(news_data_chunked, news_data_dir / \"news.txt\")\n",
    "\n",
    "save_to_jsonl(wiki_data_chunked, wiki_data_dir / \"wiki.jsonl\")\n",
    "save_to_jsonl(news_data_chunked, news_data_dir / \"news.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887dddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\data\\\\raw\\\\wiki\\\\wiki.txt', '..\\\\data\\\\raw\\\\news\\\\news.txt', '..\\\\data\\\\raw\\\\github_repos\\\\corpus.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/processed/tokenizer\\\\vocab.json',\n",
       " '../data/processed/tokenizer\\\\merges.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [\n",
    "    str(wiki_data_dir / \"wiki.txt\"),\n",
    "    str(news_data_dir / \"news.txt\"),\n",
    "    str(output_txt)\n",
    "]\n",
    "\n",
    "print(files)\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Train BPE\n",
    "tokenizer.train(\n",
    "    files=files,\n",
    "    vocab_size=50000,\n",
    "    min_frequency=3,\n",
    "    special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\", \"<wiki>\", \"<code>\", \"<news>\"]\n",
    ")\n",
    "\n",
    "# save tokenizer\n",
    "tokenizer.save_model(\"../data/processed/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd19c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tr', 'ÃŃ', 'Ġtuá»ĩ', 'ĠnhÃ¢n', 'Ġtáº¡o', 'ĠlÃł', 'Ġmá»Ļt', 'ĠlÄ©nh', 'Ġvá»±c', '...']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode(\"Trí tuệ nhân tạo là một lĩnh vực...\")\n",
    "print(enc.tokens)\n",
    "print(len(enc.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33510ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'f', 'Ġf', 'oo', '():', 'Ġreturn', 'Ġ4', '2']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode(\"def foo(): return 42\")\n",
    "print(enc.tokens)\n",
    "print(len(enc.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006d975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<code>', 'Ġdef', 'Ġf', 'oo', '():', 'Ġreturn', 'Ġ42', 'Ġ</', 'code', '>']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode(\"<code> def foo(): return 42 </code>\")\n",
    "print(enc.tokens)\n",
    "print(len(enc.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86331e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
